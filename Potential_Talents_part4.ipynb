{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b22c4196",
   "metadata": {},
   "source": [
    "## Potential Talents - Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2956a14e",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716b8abb",
   "metadata": {},
   "source": [
    "# Job Title Similarity using LLMs-as-Rankers\n",
    "\n",
    "### Objective\n",
    "Given a query, ask a small LLM to score **all 104 job titles at once** (0–100, one score per line, same order), then rank the scores to compare the **top-10** with other results (from embeddings + cosine or other LLMs results)\n",
    "\n",
    "### Constraints\n",
    "- Local GPU: **GTX 1080 Ti**.\n",
    "- **Deterministic** generation: `do_sample=False`, `num_beams=1`.\n",
    "\n",
    "### Models (initial)\n",
    "- **1:** `microsoft/phi-3-mini-4k-instruct` (4k context, small & GPU-friendly).\n",
    "- **2:** `google/gemma-2-2b-it` (8k context, very small).\n",
    "- **3:** `qwen2.5-3B-instruct` (32k context, ~3B params, list-style outputs).\n",
    "- (After some tests we will avoid FLAN-T5 here due to the ~512 token input limit.)\n",
    "\n",
    "### Method\n",
    "1) Load SBERT top-10 baseline (from Part 3).  \n",
    "2) Load a small **causal LM**.  \n",
    "3) Build a prompt that lists all **104** titles (numbered).  \n",
    "4) Generate **104 lines of integers**; parse → rank; print top-10; save top-10 CSV (`query,score,job_titles`).  \n",
    "5) Repeat for the 4 queries; later compute nDCG@10 and compare.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e935cd",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b387d87",
   "metadata": {},
   "source": [
    "### Step 0 - Imports, config, folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21ce1f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# core\n",
    "import os, json, math, re, random, time, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# HF\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2188f07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproducibility\n",
    "SEED = 23\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "# paths\n",
    "DATA_DIR = \"data\"\n",
    "OUT_DIR  = \"outputs\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "QUERIES = [\"data scientist\", \"machine learning engineer\", \"backend developer\", \"product manager\"]  # same queries from Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d545eb",
   "metadata": {},
   "source": [
    "### Step 1 - Load titles and make a clean field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d845f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_DIR, \"potential_talents.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85b98037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104,\n",
       " ['2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional',\n",
       "  'Native English Teacher at EPIK (English Program in Korea)',\n",
       "  'Aspiring Human Resources Professional',\n",
       "  'People Development Coordinator at Ryan',\n",
       "  'Advisory Board Member at Celal Bayar University'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = df[\"job_title\"].astype(str).tolist()\n",
    "len(titles), titles[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870c7ee5",
   "metadata": {},
   "source": [
    "### Step 2 - Load SBERT top-10 baseline (as-is, from the previous project part 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfb96aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            query     score                                         job_titles\n",
      "0  data scientist  0.595830  Information Systems Specialist and Programmer ...\n",
      "1  data scientist  0.494619                       Human Resources Professional\n",
      "2  data scientist  0.456588           Junior MES Engineer| Information Systems\n",
      "Queries in baseline: ['data scientist' 'machine learning engineer' 'backend developer'\n",
      " 'product manager']\n"
     ]
    }
   ],
   "source": [
    "# Load your SBERT baseline as produced in Part 3 (no changes to schema)\n",
    "BASELINE_TOP10_CSV = os.path.join(OUT_DIR, \"sbert_ranking_output.csv\")\n",
    "base = pd.read_csv(BASELINE_TOP10_CSV)\n",
    "\n",
    "print(base.head(3))\n",
    "print(\"Queries in baseline:\", base[\"query\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6546e899",
   "metadata": {},
   "source": [
    "### Step 3 - Pretty printer (same style as Part 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2643cbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ranking(query, rows_df, score_col=\"score\", title_col=\"job_titles\", top_k=10):\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    for _, r in rows_df.head(top_k).iterrows():\n",
    "        print(f\"   {r[score_col]: .3f}  {r[title_col]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8800280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: data scientist\n",
      "    0.596  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.495  Human Resources Professional\n",
      "    0.457  Junior MES Engineer| Information Systems\n",
      "    0.450  Aspiring Human Resources Specialist\n",
      "    0.449  Human Resources professional for the world leader in GIS software\n",
      "    0.441  HR Senior Specialist\n",
      "    0.433  Human Resources Generalist at ScottMadden, Inc.\n",
      "    0.416  Liberal Arts Major. Aspiring Human Resources Analyst.\n",
      "    0.410  Student\n",
      "    0.403  Human Resources Specialist at Luxottica\n",
      "\n",
      "Query: machine learning engineer\n",
      "    0.596  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.495  Human Resources Professional\n",
      "    0.457  Junior MES Engineer| Information Systems\n",
      "    0.450  Aspiring Human Resources Specialist\n",
      "    0.449  Human Resources professional for the world leader in GIS software\n",
      "    0.441  HR Senior Specialist\n",
      "    0.433  Human Resources Generalist at ScottMadden, Inc.\n",
      "    0.416  Liberal Arts Major. Aspiring Human Resources Analyst.\n",
      "    0.410  Student\n",
      "    0.403  Human Resources Specialist at Luxottica\n",
      "\n",
      "Query: backend developer\n",
      "    0.596  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.495  Human Resources Professional\n",
      "    0.457  Junior MES Engineer| Information Systems\n",
      "    0.450  Aspiring Human Resources Specialist\n",
      "    0.449  Human Resources professional for the world leader in GIS software\n",
      "    0.441  HR Senior Specialist\n",
      "    0.433  Human Resources Generalist at ScottMadden, Inc.\n",
      "    0.416  Liberal Arts Major. Aspiring Human Resources Analyst.\n",
      "    0.410  Student\n",
      "    0.403  Human Resources Specialist at Luxottica\n",
      "\n",
      "Query: product manager\n",
      "    0.596  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.495  Human Resources Professional\n",
      "    0.457  Junior MES Engineer| Information Systems\n",
      "    0.450  Aspiring Human Resources Specialist\n",
      "    0.449  Human Resources professional for the world leader in GIS software\n",
      "    0.441  HR Senior Specialist\n",
      "    0.433  Human Resources Generalist at ScottMadden, Inc.\n",
      "    0.416  Liberal Arts Major. Aspiring Human Resources Analyst.\n",
      "    0.410  Student\n",
      "    0.403  Human Resources Specialist at Luxottica\n"
     ]
    }
   ],
   "source": [
    "for query in QUERIES:\n",
    "    print_ranking(query, base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db80fed",
   "metadata": {},
   "source": [
    "### Step 4 - Load a small LLM (Phi-3-mini from Microsoft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27da14b",
   "metadata": {},
   "source": [
    "**Phi-3 Mini (Microsoft)**\n",
    "- **Release Date**: April 23, 2024.\n",
    "- **Architecture**: Decoder-only (autoregressive).\n",
    "- **Parameters**: ~3.8B.\n",
    "- **Layers**: 32 transformer blocks, 32 attention heads.\n",
    "- **Context Window**: 4k tokens.\n",
    "- **Tokenizer**: SentencePiece-like (subword BPE).\n",
    "- **Objective**: Next-token prediction, trained as a general causal LM.\n",
    "- **Training**: Mixture of web, code, math, scientific texts; instruction-tuned for dialogue.\n",
    "- **Efficiency**: Optimized for small GPUs (runs on 8–12GB VRAM), strong FP16/INT8 support.\n",
    "- **License**: MIT-style permissive.\n",
    "- **Notes**: Very lightweight, deterministic, good for structured tasks on consumer GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e5c1958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.6.0+cu124\n",
      "built with CUDA: 12.4\n",
      "cuda available: True\n",
      "gpu: NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "print(\"torch:\", torch.__version__)\n",
    "print(\"built with CUDA:\", torch.version.cuda)\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"gpu:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ef92698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84f2889c7294e11a51177395e29ef5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_ID = \"microsoft/phi-3-mini-4k-instruct\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
    "mdl = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    dtype=torch.float16 if torch.cuda.is_available() else None,\n",
    ").to(\"cuda\" if torch.cuda.is_available() else \"cpu\").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "394583c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a proper chat prompt\n",
    "msgs = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a calculator. Reply with digits only.\"},\n",
    "    {\"role\": \"user\",   \"content\": \"Return the number 7.\"}\n",
    "]\n",
    "prompt = tok.apply_chat_template(msgs, tokenize=False, add_generation_prompt=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ca4e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode & generate (greedy)\n",
    "inputs = tok(prompt, return_tensors=\"pt\").to(mdl.device)\n",
    "eos = [tok.eos_token_id]\n",
    "try:\n",
    "    eos.append(tok.convert_tokens_to_ids(\"<|end|>\"))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82e8d1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = mdl.generate(\n",
    "    **inputs,\n",
    "    do_sample=False,\n",
    "    num_beams=1,\n",
    "    max_new_tokens=3,\n",
    "    eos_token_id=eos,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27e410f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "out = tok.decode(gen[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True).strip()\n",
    "print(out)  # -> 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699f9861",
   "metadata": {},
   "source": [
    "### Step 5 — turn LLM into a job title ranker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e8837f",
   "metadata": {},
   "source": [
    "We will turn the LLM into a ranker by asking it to assign an integer score (0–100) to each raw job title for a given query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e07e1c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_all_chat_phi(query: str, titles: list[str]) -> str:\n",
    "    lines = \"\\n\".join(f\"{i+1}) {t}\" for i, t in enumerate(titles))\n",
    "    rubric = (\n",
    "        \"You are a recruiter scoring job-title similarity to the query.\\n\"\n",
    "        \"Rate each candidate with an integer 0–100 using the FULL scale:\\n\"\n",
    "        \" • 90–100 = exact/near-exact role match\\n\"\n",
    "        \" • 70–89  = same discipline or very similar role\\n\"\n",
    "        \" • 40–69  = related/adjacent\\n\"\n",
    "        \" • 10–39  = mostly unrelated\\n\"\n",
    "        \" • 0–9    = completely unrelated\\n\"\n",
    "        \"Use diverse scores; do NOT give 0 or 100 to many candidates.\\n\"\n",
    "        \"Ignore employer names, locations, programs.\\n\"\n",
    "        \"Output EXACTLY one integer per line, in the SAME ORDER as the candidates. No words, no punctuation.\"\n",
    "    )\n",
    "    # Non-extreme example\n",
    "    example = \"Example for 3 candidates:\\n82\\n41\\n7\"\n",
    "    user = f'Query: \"{query}\"\\n\\nCandidates:\\n{lines}\\n\\n{example}'\n",
    "    msgs = [{\"role\": \"system\", \"content\": rubric},\n",
    "            {\"role\": \"user\",   \"content\": user}]\n",
    "    return tok.apply_chat_template(msgs, tokenize=False, add_generation_prompt=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fd5fca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_scores_n(out: str, n: int) -> list[int]:\n",
    "    # prefer last int per non-empty line; fallback to last N ints in whole text\n",
    "    lines = [l.strip() for l in out.splitlines() if l.strip()]\n",
    "    scores = []\n",
    "    \n",
    "    for line in lines:\n",
    "        ints = re.findall(r\"-?\\d+\", line)\n",
    "        if ints:\n",
    "            scores.append(int(ints[-1]))\n",
    "        if len(scores) >= n:\n",
    "            break\n",
    "        \n",
    "    if len(scores) < n:\n",
    "        all_ints = [int(x) for x in re.findall(r\"-?\\d+\", out)]\n",
    "        scores = all_ints[-n:]\n",
    "        \n",
    "    scores = [max(0, min(100, int(s))) for s in scores]\n",
    "    \n",
    "    # if still short, add a padding\n",
    "    if len(scores) < n:  \n",
    "        scores += [0] * (n - len(scores))\n",
    "    return scores[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b170f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_all_titles_once(query: str,\n",
    "                          titles: list[str],\n",
    "                          max_new_tokens: int = 300,\n",
    "                          build_fn=None):\n",
    "    build_fn = build_fn or build_prompt_all_chat_phi\n",
    "    prompt = build_fn(query, titles)\n",
    "    print(\"Prompt tokens:\", len(tok(prompt)[\"input_ids\"]))\n",
    "    inputs = tok(prompt, return_tensors=\"pt\").to(mdl.device)\n",
    "    gen = mdl.generate(\n",
    "        **inputs,\n",
    "        do_sample=False,\n",
    "        num_beams=1,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        eos_token_id=[tok.eos_token_id],\n",
    "        min_new_tokens=min(len(titles), max_new_tokens-1),\n",
    "    )\n",
    "    out_text = tok.decode(gen[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True)\n",
    "    scores = parse_scores_n(out_text, len(titles))\n",
    "    df = pd.DataFrame({\"idx\": range(len(titles)), \"score\": scores})\n",
    "    df[\"job_titles\"] = [titles[i] for i in df[\"idx\"]]\n",
    "    df = df.sort_values(\"score\", ascending=False).reset_index(drop=True)\n",
    "    return df, out_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8ee9d3",
   "metadata": {},
   "source": [
    "Test **build_prompt_all_chat**, **parse_scores_n** and **score_all_tittles_once**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e1c94d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DEMO PROMPT (first 30 lines) ===\n",
      "<|system|>\n",
      "You are a recruiter scoring job-title similarity to the query.\n",
      "Rate each candidate with an integer 0–100 using the FULL scale:\n",
      " • 90–100 = exact/near-exact role match\n",
      " • 70–89  = same discipline or very similar role\n",
      " • 40–69  = related/adjacent\n",
      " • 10–39  = mostly unrelated\n",
      " • 0–9    = completely unrelated\n",
      "Use diverse scores; do NOT give 0 or 100 to many candidates.\n",
      "Ignore employer names, locations, programs.\n",
      "Output EXACTLY one integer per line, in the SAME ORDER as the candidates. No words, no punctuation.<|end|>\n",
      "<|user|>\n",
      "Query: \"data scientist\"\n",
      "\n",
      "Candidates:\n",
      "1) 2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "2) Native English Teacher at EPIK (English Program in Korea)\n",
      "3) Aspiring Human Resources Professional\n",
      "4) People Development Coordinator at Ryan\n",
      "5) Advisory Board Member at Celal Bayar University\n",
      "\n",
      "Example for 3 candidates:\n",
      "82\n",
      "41\n",
      "7<|end|>\n",
      "<|assistant|>\n",
      "Token count (subset): 279\n"
     ]
    }
   ],
   "source": [
    "test_query = \"data scientist\"\n",
    "\n",
    "# A Tiny subset to inspect everything\n",
    "subset = titles[:5]\n",
    "\n",
    "demo_prompt = build_prompt_all_chat_phi(test_query, subset)\n",
    "print(\"=== DEMO PROMPT (first 30 lines) ===\")\n",
    "print(\"\\n\".join(demo_prompt.splitlines()[:30]))\n",
    "print(\"Token count (subset):\", len(tok(demo_prompt)[\"input_ids\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0dd40f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt tokens: 279\n",
      "\n",
      "=== RAW MODEL OUTPUT (subset) ===\n",
      "0\n",
      "0\n",
      "7\n",
      "41\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df_sub, raw_sub = score_all_titles_once(test_query, subset, max_new_tokens=60)\n",
    "print(\"\\n=== RAW MODEL OUTPUT (subset) ===\")\n",
    "print(raw_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5738ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parsed scores (subset): [0, 0, 7, 41, 0]\n",
      "\n",
      "Paired (score, title) in ranked order:\n",
      " 41  People Development Coordinator at Ryan\n",
      "  7  Aspiring Human Resources Professional\n",
      "  0  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "  0  Native English Teacher at EPIK (English Program in Korea)\n",
      "  0  Advisory Board Member at Celal Bayar University\n"
     ]
    }
   ],
   "source": [
    "scores_sub = parse_scores_n(raw_sub, len(subset))\n",
    "print(\"\\nParsed scores (subset):\", scores_sub)\n",
    "print(\"\\nPaired (score, title) in ranked order:\")\n",
    "# the output DataFrame from `socre_all_titles_once`, df_sub, is sorted in not ascending order\n",
    "for _, r in df_sub.iterrows():\n",
    "    print(f\"{r['score']:>3}  {r['job_titles']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89bafef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Token count (full): 1928\n"
     ]
    }
   ],
   "source": [
    "# B) One full run (preview only; avoids flooding output)\n",
    "full_prompt = build_prompt_all_chat_phi(test_query, titles)\n",
    "print(\"\\nToken count (full):\", len(tok(full_prompt)[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2197f9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncation of long strings\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.width\", 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d261d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt tokens: 1928\n",
      "\n",
      "Full run: got 104 scores.\n",
      "Top-3 preview:\n",
      "   score                                                                                                job_titles\n",
      "0    100                                         Student at Humber College and Aspiring Human Resources Generalist\n",
      "1    100                                                           Advisory Board Member at Celal Bayar University\n",
      "2    100                                                                     Aspiring Human Resources Professional\n",
      "3     90                                                                       Aspiring Human Resources Specialist\n",
      "4     89                                         Student at Humber College and Aspiring Human Resources Generalist\n",
      "5     74                                                                     Aspiring Human Resources Professional\n",
      "6     72                                                 Native English Teacher at EPIK (English Program in Korea)\n",
      "7     70  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "8     70                                                                                      HR Senior Specialist\n",
      "9     69                                                                             Student at Chapman University\n"
     ]
    }
   ],
   "source": [
    "df_full, raw_full = score_all_titles_once(test_query, titles, max_new_tokens=300)\n",
    "print(\"\\nFull run: got\", len(df_full), \"scores.\")\n",
    "print(\"Top-3 preview:\")\n",
    "print(df_full.head(10)[[\"score\", \"job_titles\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ce5f589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ranking(query, rows_df, top_k=10):\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    for _, r in rows_df.head(top_k).iterrows():\n",
    "        print(f\"   {r['score']/100: .3f}  {r['job_titles']}\")\n",
    "\n",
    "def run_query_full(queries: list[str],\n",
    "                   model_tag: str = \"phi3_mini_4k\",\n",
    "                   build_prompt_fn=None):\n",
    "    out_dir = os.path.join(OUT_DIR, \"llm\"); os.makedirs(out_dir, exist_ok=True)\n",
    "    top10_blocks = []\n",
    "    for query in queries:\n",
    "        df_rank, raw = score_all_titles_once(query, titles, build_fn=build_prompt_fn)\n",
    "        print_ranking(query, df_rank, top_k=10)\n",
    "        df_q = df_rank.head(10)[[\"score\", \"job_titles\"]].copy()\n",
    "        df_q.insert(0, \"query\", query)\n",
    "        top10_blocks.append(df_q)\n",
    "    top10 = pd.concat(top10_blocks, ignore_index=True)\n",
    "    path = os.path.join(out_dir, f\"llm_top10__{model_tag}__all_queries.csv\")\n",
    "    top10.to_csv(path, index=False)\n",
    "    print(\"Saved:\", path)\n",
    "    return top10, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8de3570e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt tokens: 1928\n",
      "\n",
      "Query: data scientist\n",
      "    1.000  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    1.000  Advisory Board Member at Celal Bayar University\n",
      "    1.000  Aspiring Human Resources Professional\n",
      "    0.900  Aspiring Human Resources Specialist\n",
      "    0.890  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.740  Aspiring Human Resources Professional\n",
      "    0.720  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.700  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.700  HR Senior Specialist\n",
      "    0.690  Student at Chapman University\n",
      "Prompt tokens: 1928\n",
      "\n",
      "Query: machine learning engineer\n",
      "    1.000  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    1.000  Advisory Board Member at Celal Bayar University\n",
      "    1.000  Aspiring Human Resources Professional\n",
      "    0.900  Aspiring Human Resources Specialist\n",
      "    0.890  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.740  Aspiring Human Resources Professional\n",
      "    0.720  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.700  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.700  HR Senior Specialist\n",
      "    0.690  Student at Chapman University\n",
      "Prompt tokens: 1927\n",
      "\n",
      "Query: backend developer\n",
      "    1.000  Advisory Board Member at Celal Bayar University\n",
      "    0.750  Aspiring Human Resources Specialist\n",
      "    0.700  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.700  Aspiring Human Resources Professional\n",
      "    0.700  People Development Coordinator at Ryan\n",
      "    0.700  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.700  SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR\n",
      "    0.700  Seeking Human Resources HRIS and Generalist Positions\n",
      "    0.700  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.700  People Development Coordinator at Ryan\n",
      "Prompt tokens: 1927\n",
      "\n",
      "Query: product manager\n",
      "    1.000  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    1.000  Advisory Board Member at Celal Bayar University\n",
      "    1.000  Aspiring Human Resources Professional\n",
      "    0.900  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.900  Aspiring Human Resources Specialist\n",
      "    0.900  Aspiring Human Resources Professional\n",
      "    0.890  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.700  HR Senior Specialist\n",
      "    0.690  Student at Chapman University\n",
      "    0.410  Native English Teacher at EPIK (English Program in Korea)\n",
      "Saved: outputs\\llm\\llm_top10__phi3_mini_4k__all_queries.csv\n"
     ]
    }
   ],
   "source": [
    "top10_phi, path_phi = run_query_full(\n",
    "    QUERIES,\n",
    "    model_tag=\"phi3_mini_4k\",\n",
    "    build_prompt_fn=build_prompt_all_chat_phi\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86751029",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c030c12",
   "metadata": {},
   "source": [
    "### Step 6 - Experience with another small LLM: **Gemma-2-2b-it from Google**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89602a3",
   "metadata": {},
   "source": [
    "**Gemma-2-2B-IT (Google)**\n",
    "- **Release Date**: June 27, 2024 (Gemma 2 family launch).\n",
    "- **Architecture**: Decoder-only (autoregressive).\n",
    "- **Parameters**: ~2.6B.\n",
    "- **Layers**: ~26 transformer layers (with RoPE).\n",
    "- **Context Window**: 8k tokens.\n",
    "- **Tokenizer**: SentencePiece (same family as PaLM-2 / Gemini).\n",
    "- **Objective**: Next-token prediction with instruction-tuning.\n",
    "- **Training**: Web-scale datasets filtered for quality, multilingual corpora.\n",
    "- **Efficiency**: Ultra-compact, designed for edge devices; runs well on 6–8GB GPUs.\n",
    "- **License**: Apache 2.0 (permissive).\n",
    "- *Notes*: Very small but instruction-tuned, produces stable integer list outputs if well-prompted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75339a6d",
   "metadata": {},
   "source": [
    "Free some GPU allocated memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c681f9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d273108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_GPU_memory():\n",
    "    def print_vram(prefix=\"\"):\n",
    "        if not torch.cuda.is_available():\n",
    "            print(prefix + \"CUDA not available\")\n",
    "            return\n",
    "        torch.cuda.synchronize()\n",
    "        alloc = torch.cuda.memory_allocated() / (1024**2)      # MiB\n",
    "        reserv = torch.cuda.memory_reserved() / (1024**2)      # MiB\n",
    "        total = torch.cuda.get_device_properties(0).total_memory / (1024**2)\n",
    "        print(f\"\\n{prefix}allocated: {alloc:.1f} MiB | reserved: {reserv:.1f} MiB | total: {total:,.0f} MiB\")\n",
    "\n",
    "    # Print memory allocation before freeing it\n",
    "    print(\"Measure memory usage before and after freeing it\")\n",
    "    print_vram(\"Before:\\n\")\n",
    "\n",
    "    # move model to CPU + delete big refs\n",
    "    try: mdl.to(\"cpu\")\n",
    "    except: pass\n",
    "    # free memory\n",
    "    for name in (\"pipe\",\"mdl\",\"tok\",\"inputs\",\"gen\"):\n",
    "        if name in globals(): del globals()[name]\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()\n",
    "    print_vram(\"After:\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34982006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measure memory usage before and after freeing it\n",
      "\n",
      "Before:\n",
      "allocated: 7296.5 MiB | reserved: 8596.0 MiB | total: 11,264 MiB\n",
      "\n",
      "After:\n",
      "allocated: 8.1 MiB | reserved: 20.0 MiB | total: 11,264 MiB\n"
     ]
    }
   ],
   "source": [
    "free_GPU_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32ee0d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80fa110bfd2f4ca18fdff1e9530dc426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "MODEL_ID = \"google/gemma-2-2b-it\"\n",
    "HF_TOKEN = os.getenv(\"llm_gemma\")\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
    "mdl = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    dtype=torch.float16 if device.type==\"cuda\" else None,\n",
    "    token=HF_TOKEN\n",
    ").to(device).eval()\n",
    "\n",
    "if tok.pad_token_id is None:\n",
    "    tok.pad_token = tok.eos_token\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=mdl, tokenizer=tok, device=0 if device.type==\"cuda\" else -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d27f0eb",
   "metadata": {},
   "source": [
    "Define a newer **prompt builder** function with a one-shot prompt and being more specific with the matching job titles. Also it drops the `system role` options that we used with Phi-3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ccf6aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_prompt_all_chat_gemma(query: str, titles: list[str]) -> str:\n",
    "    lines = \"\\n\".join(f\"{i+1}) {t}\" for i, t in enumerate(titles))\n",
    "    rubric = (\n",
    "        \"You are a recruiter scoring job-title similarity to the query.\\n\"\n",
    "        \"Rate each candidate with an integer between zero and one hundred using the full scale.\\n\"\n",
    "        \"Use diverse scores; avoid giving many zeros or many hundreds.\\n\"\n",
    "        \"Ignore employer names, locations, and programs.\\n\"\n",
    "        \"Return EXACTLY one integer per line in the SAME ORDER as the candidates.\\n\"\n",
    "        \"No words, no punctuation, no numbering.\\n\"\n",
    "    )\n",
    "    user_text = f'Query: \"{query}\"\\n\\nCandidates:\\n{lines}\\n\\nSCORES:'\n",
    "    # Gemma’s template may not support a system role → fold rubric into the user turn\n",
    "    msgs = [{\"role\": \"user\", \"content\": rubric + \"\\n\\n\" + user_text}]\n",
    "    return tok.apply_chat_template(msgs, tokenize=False, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8ee904a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt tokens: 1583\n",
      "\n",
      "Query: data scientist\n",
      "    0.200  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.100  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.100  Aspiring Human Resources Professional\n",
      "    0.100  People Development Coordinator at Ryan\n",
      "    0.100  Advisory Board Member at Celal Bayar University\n",
      "    0.100  Aspiring Human Resources Specialist\n",
      "    0.100  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.100  HR Senior Specialist\n",
      "    0.100  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.100  Seeking Human Resources HRIS and Generalist Positions\n",
      "Prompt tokens: 1584\n",
      "\n",
      "Query: machine learning engineer\n",
      "    0.200  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.100  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.100  Aspiring Human Resources Professional\n",
      "    0.100  People Development Coordinator at Ryan\n",
      "    0.100  Advisory Board Member at Celal Bayar University\n",
      "    0.100  Aspiring Human Resources Specialist\n",
      "    0.100  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.100  HR Senior Specialist\n",
      "    0.100  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.100  Seeking Human Resources HRIS and Generalist Positions\n",
      "Prompt tokens: 1583\n",
      "\n",
      "Query: backend developer\n",
      "    0.200  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.100  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.100  Aspiring Human Resources Professional\n",
      "    0.100  People Development Coordinator at Ryan\n",
      "    0.100  Advisory Board Member at Celal Bayar University\n",
      "    0.100  Aspiring Human Resources Specialist\n",
      "    0.100  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.100  HR Senior Specialist\n",
      "    0.100  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.100  Seeking Human Resources HRIS and Generalist Positions\n",
      "Prompt tokens: 1583\n",
      "\n",
      "Query: product manager\n",
      "    0.300  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.250  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.250  People Development Coordinator at Ryan\n",
      "    0.250  Aspiring Human Resources Specialist\n",
      "    0.200  Aspiring Human Resources Professional\n",
      "    0.200  Advisory Board Member at Celal Bayar University\n",
      "    0.200  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.200  HR Senior Specialist\n",
      "    0.200  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.200  Seeking Human Resources HRIS and Generalist Positions\n",
      "Saved: outputs\\llm\\llm_top10__gemma-2-2b-it__all_queries.csv\n"
     ]
    }
   ],
   "source": [
    "top10_gemma, path_gemma = run_query_full(\n",
    "    QUERIES,\n",
    "    model_tag=\"gemma-2-2b-it\",\n",
    "    build_prompt_fn=build_prompt_all_chat_gemma\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faf58ee",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff2edcb",
   "metadata": {},
   "source": [
    "### Step 7 - Experience with another small LLM: **Qwen2.5-3B-Instruct from Qwen**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561f3a4d",
   "metadata": {},
   "source": [
    "**Qwen2.5-3B-Instruct (Alibaba / Qwen Team)**\n",
    "- **Release Date**: September 5, 2024 (Qwen2.5 family release).\n",
    "- **Architecture**: Decoder-only (autoregressive).\n",
    "- **Parameters**: ~2.7–3B.\n",
    "- **Layers**: 28 transformer layers, 32 attention heads.\n",
    "- **Context Window**: 32k tokens (longest among your three).\n",
    "- **Tokenizer**: Custom BPE with multilingual coverage.\n",
    "- **Objective**: Next-token prediction, instruction-tuned with ChatML formatting.\n",
    "- **Training**: Massive multilingual web + code datasets, plus safety/alignment finetuning.\n",
    "- **Efficiency**: Larger context needs more VRAM, but still runnable on 12GB with FP16/INT8.\n",
    "- **License**: Apache 2.0.\n",
    "- *Notes*: Very strong for structured outputs (list-style, JSON); context length makes it robust for 104-title scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a40cf0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measure memory usage before and after freeing it\n",
      "\n",
      "Before:\n",
      "allocated: 4995.6 MiB | reserved: 5710.0 MiB | total: 11,264 MiB\n",
      "\n",
      "After:\n",
      "allocated: 8.1 MiB | reserved: 20.0 MiB | total: 11,264 MiB\n"
     ]
    }
   ],
   "source": [
    "free_GPU_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "552fa1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc4e302e7fc4d969a0a75a3e404f54a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_ID = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
    "mdl = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    dtype=torch.float16 if torch.cuda.is_available() else None,\n",
    ").to(\"cuda\" if torch.cuda.is_available() else \"cpu\").eval()\n",
    "\n",
    "if tok.pad_token_id is None:\n",
    "    tok.pad_token = tok.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "079e660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qwen-specific prompt builder (ChatML-friendly, explicit N, hard stop)\n",
    "def build_prompt_all_chat_qwen(query: str, titles: list[str]) -> str:\n",
    "    n = len(titles)\n",
    "    lines = \"\\n\".join(f\"{i}) {t}\" for i, t in enumerate(titles, start=1))\n",
    "\n",
    "    rubric = (\n",
    "        \"You are a recruiter scoring job-title similarity to the query.\\n\"\n",
    "        \"Score each candidate with an integer 0–100 using the FULL scale:\\n\"\n",
    "        \"  90–100 = exact/near-exact role match\\n\"\n",
    "        \"  70–89  = same discipline or very similar role\\n\"\n",
    "        \"  40–69  = related/adjacent\\n\"\n",
    "        \"  20–39  = mostly unrelated\\n\"\n",
    "        \"  0–19   = completely unrelated\\n\"\n",
    "        \"Rules:\\n\"\n",
    "        \" - Prefer same functional domain as the query.\\n\"\n",
    "        \" - If the query is technical (data/ML/backend), HR/People titles are mostly unrelated.\\n\"\n",
    "        \" - Titles with 'Student' or 'Aspiring' get lower scores unless they explicitly match the role.\\n\"\n",
    "        f\"Output EXACTLY {n} integers, one per line, in the SAME ORDER as the candidates.\\n\"\n",
    "        \"No words, no commas, no numbering, no punctuation.\\n\"\n",
    "        f\"After the {n}th line, output the token <END> and stop.\"\n",
    "    )\n",
    "\n",
    "    # very small one-shot to demonstrate format (3 lines + <END>)\n",
    "    # keep it generic so it transfers across queries\n",
    "    example = (\n",
    "        \"Example (3 candidates):\\n\"\n",
    "        \"Candidates:\\n\"\n",
    "        \"1) Senior Data Scientist\\n\"\n",
    "        \"2) HR Coordinator\\n\"\n",
    "        \"3) Retail Cashier\\n\"\n",
    "        \"Expected output:\\n\"\n",
    "        \"95\\n\"\n",
    "        \"20\\n\"\n",
    "        \"0\\n\"\n",
    "        \"<END>\"\n",
    "    )\n",
    "\n",
    "    user_text = (\n",
    "        f\"{rubric}\\n\\n\"\n",
    "        f'Query: \"{query}\"\\n\\n'\n",
    "        f\"Candidates:\\n{lines}\\n\\n\"\n",
    "        f\"{example}\"\n",
    "    )\n",
    "\n",
    "    # Qwen supports system; if anything fails, fall back to user-only.\n",
    "    msgs_sys = [\n",
    "        {\"role\": \"system\", \"content\": \"You are precise and output only the requested numbers.\"},\n",
    "        {\"role\": \"user\",   \"content\": user_text},\n",
    "    ]\n",
    "    msgs_user = [{\"role\": \"user\", \"content\": user_text}]  # fallback\n",
    "\n",
    "    try:\n",
    "        return tok.apply_chat_template(msgs_sys, tokenize=False, add_generation_prompt=True)\n",
    "    except Exception:\n",
    "        return tok.apply_chat_template(msgs_user, tokenize=False, add_generation_prompt=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23b2a4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt tokens: 1774\n",
      "\n",
      "Query: data scientist\n",
      "    0.900  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.900  People Development Coordinator at Ryan\n",
      "    0.900  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.900  People Development Coordinator at Ryan\n",
      "    0.900  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.900  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.900  Human Resources Coordinator at InterContinental Buckhead Atlanta\n",
      "    0.900  Seeking Human Resources HRIS and Generalist Positions\n",
      "    0.900  People Development Coordinator at Ryan\n",
      "    0.900  Student at Humber College and Aspiring Human Resources Generalist\n",
      "Prompt tokens: 1775\n",
      "\n",
      "Query: machine learning engineer\n",
      "    0.900  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.400  People Development Coordinator at Ryan\n",
      "    0.000  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.000  Aspiring Human Resources Professional\n",
      "    0.000  Advisory Board Member at Celal Bayar University\n",
      "    0.000  Aspiring Human Resources Specialist\n",
      "    0.000  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.000  HR Senior Specialist\n",
      "    0.000  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.000  Seeking Human Resources HRIS and Generalist Positions\n",
      "Prompt tokens: 1774\n",
      "\n",
      "Query: backend developer\n",
      "    0.900  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.900  People Development Coordinator at Ryan\n",
      "    0.900  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.900  People Development Coordinator at Ryan\n",
      "    0.900  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.900  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.900  Human Resources Coordinator at InterContinental Buckhead Atlanta\n",
      "    0.900  Seeking Human Resources HRIS and Generalist Positions\n",
      "    0.900  People Development Coordinator at Ryan\n",
      "    0.900  Student at Humber College and Aspiring Human Resources Generalist\n",
      "Prompt tokens: 1774\n",
      "\n",
      "Query: product manager\n",
      "    0.900  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.900  People Development Coordinator at Ryan\n",
      "    0.900  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.900  People Development Coordinator at Ryan\n",
      "    0.900  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.900  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.900  Human Resources Coordinator at InterContinental Buckhead Atlanta\n",
      "    0.900  Seeking Human Resources HRIS and Generalist Positions\n",
      "    0.900  People Development Coordinator at Ryan\n",
      "    0.900  Student at Humber College and Aspiring Human Resources Generalist\n",
      "Saved: outputs\\llm\\llm_top10__qwen2.5-3b-instruct__all_queries.csv\n"
     ]
    }
   ],
   "source": [
    "top10_qwen, path_qwen = run_query_full(\n",
    "    QUERIES,\n",
    "    model_tag=\"qwen2.5-3b-instruct\",\n",
    "    build_prompt_fn=build_prompt_all_chat_qwen\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4f46ea",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b188ef",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39fba51",
   "metadata": {},
   "source": [
    "As a reference, this is the **output using ChatGPT5**:\n",
    "\n",
    "Top matches (title • score/100)\n",
    "- Business Intelligence and Analytics at Travelers • 0.78\n",
    "- Information Systems Specialist and Programmer with a love for data and organization. • 0.62\n",
    "- Junior MES Engineer | Information Systems • 0.56\n",
    "- Undergraduate Research Assistant at Styczynski Lab • 0.54\n",
    "- Liberal Arts Major. Aspiring Human Resources Analyst. • 0.42\n",
    "- Seeking Human Resources HRIS and Generalist Positions • 0.28\n",
    "- Human Resources Generalist at Loparex • 0.25\n",
    "- Human Resources Specialist at Luxottica • 0.23\n",
    "- HR Senior Specialist • 0.22\n",
    "- Human Resources Professional • 0.20\n",
    "\n",
    "\n",
    "I used the following **prompt** (same used with Phi-3 mini): \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bc266b",
   "metadata": {},
   "source": [
    "You are a recruiter scoring job-title similarity to the query Rate each candidate with an integer 0–100 using the FULL scale: • 90–100 = exact/near-exact role match • 70–89 = same discipline or very similar role • 40–69 = related/adjacent • 10–39 = mostly unrelated • 0–9 = completely unrelated Use diverse scores; do NOT give 0 or 100 to many candidates. Ignore employer names, locations, programs. Output EXACTLY one integer per line, in the SAME ORDER as the candidates. No words, no punctuation. Example for return for 3 candidates: 82 41 7 --- Query: \"data scientist\" Candidates: \"2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional Native English Teacher at EPIK (English Program in Korea) Aspiring Human Resources Professional People Development Coordinator at Ryan Advisory Board Member at Celal Bayar University Aspiring Human Resources Specialist Student at Humber College and Aspiring Human Resources Generalist HR Senior Specialist Student at Humber College and Aspiring Human Resources Generalist Seeking Human Resources HRIS and Generalist Positions Student at Chapman University SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR Human Resources Coordinator at InterContinental Buckhead Atlanta 2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional 2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional Native English Teacher at EPIK (English Program in Korea) Aspiring Human Resources Professional People Development Coordinator at Ryan 2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional Native English Teacher at EPIK (English Program in Korea) Aspiring Human Resources Professional People Development Coordinator at Ryan Advisory Board Member at Celal Bayar University Aspiring Human Resources Specialist Student at Humber College and Aspiring Human Resources Generalist HR Senior Specialist Aspiring Human Resources Management student seeking an internship Seeking Human Resources Opportunities Aspiring Human Resources Management student seeking an internship Seeking Human Resources Opportunities 2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional Native English Teacher at EPIK (English Program in Korea) Aspiring Human Resources Professional People Development Coordinator at Ryan Advisory Board Member at Celal Bayar University Aspiring Human Resources Specialist Student at Humber College and Aspiring Human Resources Generalist HR Senior Specialist Student at Humber College and Aspiring Human Resources Generalist Seeking Human Resources HRIS and Generalist Positions Student at Chapman University SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR Human Resources Coordinator at InterContinental Buckhead Atlanta 2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional Native English Teacher at EPIK (English Program in Korea) Aspiring Human Resources Professional People Development Coordinator at Ryan Advisory Board Member at Celal Bayar University Aspiring Human Resources Specialist Student at Humber College and Aspiring Human Resources Generalist HR Senior Specialist Student at Humber College and Aspiring Human Resources Generalist Seeking Human Resources HRIS and Generalist Positions Student at Chapman University SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR Human Resources Coordinator at InterContinental Buckhead Atlanta 2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional Aspiring Human Resources Professional People Development Coordinator at Ryan Aspiring Human Resources Specialist HR Senior Specialist Seeking Human Resources HRIS and Generalist Positions Student at Chapman University SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR Human Resources Coordinator at InterContinental Buckhead Atlanta Experienced Retail Manager and aspiring Human Resources Professional Human Resources, Staffing and Recruiting Professional Human Resources Specialist at Luxottica Director of Human Resources North America, Groupe Beneteau Retired Army National Guard Recruiter, office manager, seeking a position in Human Resources. Human Resources Generalist at ScottMadden, Inc. Business Management Major and Aspiring Human Resources Manager Aspiring Human Resources Manager, seeking internship in Human Resources. Human Resources Professional Nortia Staffing is seeking Human Resources, Payroll & Administrative Professionals!! (408) 709-2621 Aspiring Human Resources Professional | Passionate about helping to create an inclusive and engaging work environment \"Human Resources| Conflict Management| Policies & Procedures|Talent Management|Benefits & Compensation\" Human Resources Generalist at Schwan's Liberal Arts Major. Aspiring Human Resources Analyst. Junior MES Engineer| Information Systems Senior Human Resources Business Partner at Heil Environmental Aspiring Human Resources Professional | An energetic and Team-Focused Leader HR Manager at Endemol Shine North America Human Resources professional for the world leader in GIS software RRP Brand Portfolio Executive at JTI (Japan Tobacco International) Information Systems Specialist and Programmer with a love for data and organization. Bachelor of Science in Biology from Victoria University of Wellington Human Resources Management Major Director Human Resources at EY Undergraduate Research Assistant at Styczynski Lab Lead Official at Western Illinois University Seeking employment opportunities within Customer Service or Patient Care Admissions Representative at Community medical center long beach Seeking Human Resources Opportunities. Open to travel and relocation. Student at Westfield State University \"Student at Indiana University Kokomo - Business Management - Retail Manager at Delphi Hardware and Paint\" Aspiring Human Resources Professional Student Seeking Human Resources Position Aspiring Human Resources Manager | Graduating May 2020 | Seeking an Entry-Level Human Resources Position in St. Louis Human Resources Generalist at Loparex Business Intelligence and Analytics at Travelers Always set them up for Success Director Of Administration at Excellence Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511f7cb9",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcb4251",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45de73d",
   "metadata": {},
   "source": [
    "### Step 8 - Experience with Kimi K2 / Moonshot AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519ce568",
   "metadata": {},
   "source": [
    "**Kimi K2 (K2-0711)/ Moonshot AI**\n",
    "- **Release Date**: July 11, 2025.\n",
    "- **Architecture**: Mixture-of-Experts (MoE) Transformer with MLA (Multi-head Latent Attention)\n",
    "- **Parameters**: ~1T total, ~32B activated (MoE).\n",
    "- **Layers**: 61 total (including 1 dense layer); 64 attention heads; 384 experts; 8 selected experts per token; 1 shared expert.\n",
    "- **Context Window**: 256K tokens (longest among your three).\n",
    "- **Tokenizer**: Custom tokenizer; covab size 160K.\n",
    "- **Objective**: Language Modeling (causal/next-token) with multi-stage post-training focused on agentic capabilities (tool use, planning) using RL variants.\n",
    "- **Training**: Pre-trained on 15.T tokens with the MuonChip optimizer; post-training includes large-scale agentic data synthesis and RLVR + self-critique.\n",
    "- **Efficiency**: MoE with 32B active params; block-FP8 checkpointsl recommended engines include vLLM, SGLang, KTransformers, TensorRT-LLM\n",
    "- **License**: Modified MIT (code and weights)\n",
    "- *Notes*: OpenAI/Anthropic-compatible API available via platform.moonshot.ai; recommended temperature ~ 0.6 for Instruct variants; strong tool-calling support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fbab0f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measure memory usage before and after freeing it\n",
      "\n",
      "Before:\n",
      "allocated: 8.1 MiB | reserved: 20.0 MiB | total: 11,264 MiB\n",
      "\n",
      "After:\n",
      "allocated: 8.1 MiB | reserved: 20.0 MiB | total: 11,264 MiB\n"
     ]
    }
   ],
   "source": [
    "free_GPU_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1de0a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from typing import List, Tuple\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b709f5cc",
   "metadata": {},
   "source": [
    "For this model we will use the MOONSHOT API. Therefor, we will read the API KEY from the .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2ca16f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"MOONSHOT_API_KEY\")\n",
    "base_url = os.getenv(\"MOONSHOT_API_BASE\", \"https://api.moonshot.ai/v1\")\n",
    "if not api_key:\n",
    "    raise RuntimeError(\"MOONSHOT_API_KEY is not set. Check your .env or environment.\")\n",
    "\n",
    "client = OpenAI(api_key=api_key, base_url=base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "90bfbbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose model (check Moonshot platform for latest stable/previews)\n",
    "KIMI_MODEL_ID = os.getenv(\"KIMI_MODEL_ID\", \"kimi-k2-0905-preview\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f565ce4",
   "metadata": {},
   "source": [
    "##### Here we add a thin **Kimi (Moonshot)** adapter so the evaluation pipeline stays identical to previous local HF models: same rubric/prompt format, same strict parser (`parse_scores_n` → exactly **N** integers 0–100), same **ranking/CSV artifacts**, and **temperature=0** for determinism. \n",
    "\n",
    "##### The only change is the generation call (OpenAI-compatible Chat Completions API) wrapped by `score_all_titles_once_kimi` and `run_query_full_kimi`. This preserves apples-to-apples comparisons against Reference-A (ChatGPT-5) while letting swap models with just the prompt builder and the scorer entry point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "79dd7d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kimi prompt builder (simple, parser-friendly, same rubric)\n",
    "def build_scoring_prompt_kimi(query: str, candidates: list[str]) -> str:\n",
    "    n = len(candidates)\n",
    "    header = (\n",
    "        \"You are a recruiter scoring job-title similarity to the query\\n\"\n",
    "        \"Rate each candidate with an integer 0–100 using the FULL scale:\\n\"\n",
    "        \"• 90–100 = exact/near-exact role match\\n\"\n",
    "        \"• 70–89  = same discipline or very similar role\\n\"\n",
    "        \"• 40–69  = related/adjacent\\n\"\n",
    "        \"• 10–39  = mostly unrelated\\n\"\n",
    "        \"• 0–9    = completely unrelated\\n\"\n",
    "        \"Use diverse scores; do NOT give 0 or 100 to many candidates.\\n\"\n",
    "        \"Ignore employer names, locations, programs.\\n\"\n",
    "        f\"Output EXACTLY {n} integers, one per line, in the SAME ORDER as the candidates.\\n\"\n",
    "        \"Integers ONLY (no decimals, no percentages, no words, no punctuation).\\n\\n\"\n",
    "        \"Example for 3 candidates:\\n82\\n41\\n7\\n\"\n",
    "        \"---\\n\"\n",
    "    )\n",
    "    return header + f'Query: \"{query}\"\\nCandidates:\\n' + \"\\n\".join(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3f17ac22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kimi scorer (adapter with same return shape as your local scorer)\n",
    "def score_all_titles_once_kimi(query: str,\n",
    "                               titles: list[str],\n",
    "                               max_new_tokens: int = 1200,\n",
    "                               build_fn=build_scoring_prompt_kimi):\n",
    "    prompt = build_fn(query, titles)\n",
    "    resp = client.chat.completions.create(\n",
    "        model=KIMI_MODEL_ID,         \n",
    "        temperature=0.1,\n",
    "        top_p=1.0,\n",
    "        frequency_penalty=0.2,\n",
    "        max_tokens=max_new_tokens,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "    # debug code\n",
    "    # raw = resp.choices[0].message.content or \"\"\n",
    "    # lines = [ln for ln in raw.splitlines() if ln.strip()]\n",
    "    # print(\"parsed_ints:\", sum(ln.strip().isdigit() for ln in lines))\n",
    "    # print(\"unique_ints:\", len({int(ln.strip()) for ln in lines if ln.strip().isdigit()}))\n",
    "\n",
    "    out_text = resp.choices[0].message.content or \"\"\n",
    "    scores = parse_scores_n(out_text, len(titles))   # reuse the original parser\n",
    "    df = pd.DataFrame({\"idx\": range(len(titles)), \"score\": scores})\n",
    "    df[\"job_titles\"] = [titles[i] for i in df[\"idx\"]]\n",
    "    df = df.sort_values(\"score\", ascending=False).reset_index(drop=True)\n",
    "    return df, out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e142dfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper runner mirroring the run_query_full original function\n",
    "def run_query_full_kimi(queries: list[str],\n",
    "                        model_tag: str = \"kimi-k2-0905\",\n",
    "                        build_prompt_fn=build_scoring_prompt_kimi):\n",
    "    out_dir = os.path.join(OUT_DIR, \"llm\"); os.makedirs(out_dir, exist_ok=True)\n",
    "    top10_blocks = []\n",
    "    for query in queries:\n",
    "        df_rank, raw = score_all_titles_once_kimi(query, titles, build_fn=build_prompt_fn)\n",
    "        print_ranking(query, df_rank, top_k=10)   # <- reuse pretty-printer\n",
    "        df_q = df_rank.head(10)[[\"score\", \"job_titles\"]].copy()\n",
    "        df_q.insert(0, \"query\", query)\n",
    "        top10_blocks.append(df_q)\n",
    "    top10 = pd.concat(top10_blocks, ignore_index=True)\n",
    "    path = os.path.join(out_dir, f\"llm_top10__{model_tag}__all_queries.csv\")\n",
    "    top10.to_csv(path, index=False)\n",
    "    print(\"Saved:\", path)\n",
    "    return top10, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a80ff3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: data scientist\n",
      "    0.070  Student at Chapman University\n",
      "    0.060  Seeking Human Resources HRIS and Generalist Positions\n",
      "    0.050  HR Senior Specialist\n",
      "    0.040  Advisory Board Member at Celal Bayar University\n",
      "    0.040  Advisory Board Member at Celal Bayar University\n",
      "    0.040  SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR\n",
      "    0.040  People Development Coordinator at Ryan\n",
      "    0.030  People Development Coordinator at Ryan\n",
      "    0.030  Aspiring Human Resources Management student seeking an internship\n",
      "    0.030  Aspiring Human Resources Specialist\n",
      "\n",
      "Query: machine learning engineer\n",
      "    0.090  Human Resources, Staffing and Recruiting Professional\n",
      "    0.080  Experienced Retail Manager and aspiring Human Resources Professional\n",
      "    0.080  Business Management Major and Aspiring Human Resources Manager\n",
      "    0.080  Director of Human Resources North America, Groupe Beneteau\n",
      "    0.070  Human Resources Specialist at Luxottica\n",
      "    0.070  Human Resources Coordinator at InterContinental Buckhead Atlanta\n",
      "    0.070  Human Resources Generalist at ScottMadden, Inc.\n",
      "    0.060  SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR\n",
      "    0.060  Aspiring Human Resources Professional\n",
      "    0.060  Retired Army National Guard Recruiter, office manager,  seeking a position in Human Resources.\n",
      "\n",
      "Query: backend developer\n",
      "    0.150  Nortia Staffing is seeking Human Resources, Payroll & Administrative Professionals!!  (408) 709-2621\n",
      "    0.150  Lead Official at Western Illinois University\n",
      "    0.140  Undergraduate Research Assistant at Styczynski Lab\n",
      "    0.130  Director Human Resources  at EY\n",
      "    0.120  Human Resources Management Major\n",
      "    0.120  Junior MES Engineer| Information Systems\n",
      "    0.110  Bachelor of Science in Biology from Victoria University of Wellington\n",
      "    0.100  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.090  RRP Brand Portfolio Executive at JTI (Japan Tobacco International)\n",
      "    0.080  Human Resources professional for the world leader in GIS software\n",
      "\n",
      "Query: product manager\n",
      "    0.260  Student at Chapman University\n",
      "    0.250  Human Resources Coordinator at InterContinental Buckhead Atlanta\n",
      "    0.240  People Development Coordinator at Ryan\n",
      "    0.230  Seeking Human Resources HRIS and Generalist Positions\n",
      "    0.220  Seeking Human Resources HRIS and Generalist Positions\n",
      "    0.210  Aspiring Human Resources Specialist\n",
      "    0.200  SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR\n",
      "    0.190  Aspiring Human Resources Professional\n",
      "    0.180  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.170  HR Senior Specialist\n",
      "Saved: outputs\\llm\\llm_top10__kimi-k2-0905-preview__all_queries.csv\n"
     ]
    }
   ],
   "source": [
    "top10_kimi, path_kimi = run_query_full_kimi(\n",
    "    QUERIES,\n",
    "    model_tag=\"kimi-k2-0905-preview\",\n",
    "    build_prompt_fn=build_scoring_prompt_kimi\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f4905b",
   "metadata": {},
   "source": [
    "### Step 9 - Experience with LLaMA / Meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2702356e",
   "metadata": {},
   "source": [
    "**LLaMA 3.1 / Meta AI**\n",
    "- **Release Date**: July 23, 2024.\n",
    "- **Architecture**: Autoregressive (decoder-only) Transformer with Grouped-Query Attention (GQA).\n",
    "- **Parameters**: ~8B, ~70B and ~405B variants.\n",
    "- **Layers**: \n",
    "        - 8B: 32 transformer layers, 32 attention heads, 8 KV heads, hidden size 4096, intermediate size 14336.\n",
    "        - 70B: 80 transformer layers, 64 attention heads.\n",
    "- **Context Window**: 128K tokens (all 3.1 sizes).\n",
    "- **Tokenizer**: New Llama 3 tokenizer (SentencePiece/BPE) with 128,256 vocab size (vs. 32K in Llama 2).\n",
    "- **Objective**: Next-token prediction; instruction models aligned with superviced fine-tuning (SFT) and RLHF.\n",
    "- **Training**: Pretrained on ~15T+ tokens; knowledge cutoff December 2023; multilingual coverage (8 supported languages)\n",
    "- **Efficiency**: GQA for scalable inference; strong ecosystem support in Transformers (FlashAttention 2, 4-bit, quitization via bitsandbytes)\n",
    "- **License**: Llama 3.1 Community License.\n",
    "- *Notes*: Official chat template / tool-use formats provided; use Transformers >= 4.43 with Llama 3.1 prompt format for best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e1fa4d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measure memory usage before and after freeing it\n",
      "\n",
      "Before:\n",
      "allocated: 8.1 MiB | reserved: 20.0 MiB | total: 11,264 MiB\n",
      "\n",
      "After:\n",
      "allocated: 8.1 MiB | reserved: 20.0 MiB | total: 11,264 MiB\n"
     ]
    }
   ],
   "source": [
    "free_GPU_memory()  # your helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "246ee62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4183fbcaa6754e3c9542644cbb9f4950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76d953867de4016a7dd36bb96a7e6f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "712c91b2d2034664899d9b91acd4d732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678e7c2b077243988b47dec1b46acdbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dcc791cedaa4bf8a4d9cc086497c229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b8e9ce5ca2d47ddbcdbfc41cf5e7332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dbef29e44f74d2598dd5f3621064aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c58dee3c372422fb59e3821741b07a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a5b5400f81d4b249fef8a608edf51d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee70846b57b14723a0a51f5b327ccf2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ea86ce90fa14a5087e1b1b2a65dad5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "MODEL_ID = os.getenv(\"LLAMA_MODEL_ID\", \"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True, token=os.getenv(\"HF_TOKEN\"))\n",
    "mdl = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    dtype=torch.float16 if torch.cuda.is_available() else None,\n",
    "    low_cpu_mem_usage=True,\n",
    "    token=os.getenv(\"HF_TOKEN\"),\n",
    ").to(\"cuda\" if torch.cuda.is_available() else \"cpu\").eval()\n",
    "\n",
    "if tok.pad_token_id is None:\n",
    "    tok.pad_token = tok.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "72271351",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LLaMA prompt builder (same simple rubric + 3-line example) --------------\n",
    "def build_prompt_all_chat_llama(query: str, titles: list[str]) -> str:\n",
    "    n = len(titles)\n",
    "    rubric = (\n",
    "        \"You are a recruiter scoring job-title similarity to the query\\n\"\n",
    "        \"Rate each candidate with an integer 0–100 using the FULL scale:\\n\"\n",
    "        \"• 90–100 = exact/near-exact role match\\n\"\n",
    "        \"• 70–89  = same discipline or very similar role\\n\"\n",
    "        \"• 40–69  = related/adjacent\\n\"\n",
    "        \"• 10–39  = mostly unrelated\\n\"\n",
    "        \"• 0–9    = completely unrelated\\n\"\n",
    "        \"Use diverse scores; do NOT give 0 or 100 to many candidates.\\n\"\n",
    "        \"Ignore employer names, locations, programs.\\n\"\n",
    "        f\"Output EXACTLY {n} integers, one per line, in the SAME ORDER as the candidates.\\n\"\n",
    "        \"Integers ONLY (no decimals, no words, no punctuation).\\n\\n\"\n",
    "        \"Example for 3 candidates:\\n82\\n41\\n7\\n\"\n",
    "        \"---\\n\"\n",
    "        f'Query: \"{query}\"\\n'\n",
    "        \"Candidates:\\n\"\n",
    "        + \"\\n\".join(titles)\n",
    "    )\n",
    "    # Use LLaMA's chat template for better instruction-following\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are precise and output only the requested integers.\"},\n",
    "        {\"role\": \"user\", \"content\": rubric},\n",
    "    ]\n",
    "    try:\n",
    "        return tok.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    except Exception:\n",
    "        # Fallback: return plain text if template not available\n",
    "        return rubric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4ea32088",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tok' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[97]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#  Run following the previous terms\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m top10_llama, path_llama = \u001b[43mrun_query_full\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mQUERIES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_tag\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mllama-3-8b-instruct\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbuild_prompt_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbuild_prompt_all_chat_llama\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mrun_query_full\u001b[39m\u001b[34m(queries, model_tag, build_prompt_fn)\u001b[39m\n\u001b[32m     10\u001b[39m top10_blocks = []\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m queries:\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     df_rank, raw = \u001b[43mscore_all_titles_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuild_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbuild_prompt_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     print_ranking(query, df_rank, top_k=\u001b[32m10\u001b[39m)\n\u001b[32m     14\u001b[39m     df_q = df_rank.head(\u001b[32m10\u001b[39m)[[\u001b[33m\"\u001b[39m\u001b[33mscore\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mjob_titles\u001b[39m\u001b[33m\"\u001b[39m]].copy()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mscore_all_titles_once\u001b[39m\u001b[34m(query, titles, max_new_tokens, build_fn)\u001b[39m\n\u001b[32m      5\u001b[39m build_fn = build_fn \u001b[38;5;129;01mor\u001b[39;00m build_prompt_all_chat_phi\n\u001b[32m      6\u001b[39m prompt = build_fn(query, titles)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPrompt tokens:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mtok\u001b[49m(prompt)[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m]))\n\u001b[32m      8\u001b[39m inputs = tok(prompt, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m).to(mdl.device)\n\u001b[32m      9\u001b[39m gen = mdl.generate(\n\u001b[32m     10\u001b[39m     **inputs,\n\u001b[32m     11\u001b[39m     do_sample=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     min_new_tokens=\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(titles), max_new_tokens-\u001b[32m1\u001b[39m),\n\u001b[32m     16\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'tok' is not defined"
     ]
    }
   ],
   "source": [
    "#  Run following the previous terms\n",
    "top10_llama, path_llama = run_query_full(\n",
    "    QUERIES,\n",
    "    model_tag=\"llama-3-8b-instruct\",\n",
    "    build_prompt_fn=build_prompt_all_chat_llama,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19470c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pot_Tals_LLM_Env",
   "language": "python",
   "name": "pot-tals_llm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
