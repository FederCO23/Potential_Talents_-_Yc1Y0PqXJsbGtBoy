{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b22c4196",
   "metadata": {},
   "source": [
    "## Potential Talents - Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2956a14e",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716b8abb",
   "metadata": {},
   "source": [
    "# Job Title Similarity using LLMs-as-Rankers\n",
    "\n",
    "### Objective\n",
    "Given a query, ask a small LLM to score **all 104 job titles at once** (0–100, one score per line, same order), then rank the scores to compare the **top-10** with other results (from embeddings + cosine or other LLMs results)\n",
    "\n",
    "### Constraints\n",
    "- Local GPU: **GTX 1080 Ti**.\n",
    "- **Deterministic** generation: `do_sample=False`, `num_beams=1`.\n",
    "\n",
    "### Models (initial)\n",
    "- **1:** `microsoft/phi-3-mini-4k-instruct` (4k context, small & GPU-friendly).\n",
    "- **2:** `google/gemma-2-2b-it` (8k context, very small).\n",
    "- **3:** `qwen2.5-3B-instruct` (32k context, ~3B params, list-style outputs).\n",
    "- (After some tests we will avoid FLAN-T5 here due to the ~512 token input limit.)\n",
    "\n",
    "### Method\n",
    "1) Load SBERT top-10 baseline (from Part 3).  \n",
    "2) Load a small **causal LM**.  \n",
    "3) Build a prompt that lists all **104** titles (numbered).  \n",
    "4) Generate **104 lines of integers**; parse → rank; print top-10; save top-10 CSV (`query,score,job_titles`).  \n",
    "5) Repeat for the 4 queries; later compute nDCG@10 and compare.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e935cd",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b387d87",
   "metadata": {},
   "source": [
    "### Step 0 - Imports, config, folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21ce1f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# core\n",
    "import os, json, math, re, random, time, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# HF\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2188f07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproducibility\n",
    "SEED = 23\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "# paths\n",
    "DATA_DIR = \"data\"\n",
    "OUT_DIR  = \"outputs\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "QUERIES = [\"data scientist\", \"machine learning engineer\", \"backend developer\", \"product manager\"]  # same queries from Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d545eb",
   "metadata": {},
   "source": [
    "### Step 1 - Load titles and make a clean field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d845f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_DIR, \"potential_talents.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85b98037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104,\n",
       " ['2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional',\n",
       "  'Native English Teacher at EPIK (English Program in Korea)',\n",
       "  'Aspiring Human Resources Professional',\n",
       "  'People Development Coordinator at Ryan',\n",
       "  'Advisory Board Member at Celal Bayar University'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = df[\"job_title\"].astype(str).tolist()\n",
    "len(titles), titles[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870c7ee5",
   "metadata": {},
   "source": [
    "### Step 2 - Load SBERT top-10 baseline (as-is, from the previous project part 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfb96aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            query     score                                         job_titles\n",
      "0  data scientist  0.595830  Information Systems Specialist and Programmer ...\n",
      "1  data scientist  0.494619                       Human Resources Professional\n",
      "2  data scientist  0.456588           Junior MES Engineer| Information Systems\n",
      "Queries in baseline: ['data scientist' 'machine learning engineer' 'backend developer'\n",
      " 'product manager']\n"
     ]
    }
   ],
   "source": [
    "# Load your SBERT baseline as produced in Part 3 (no changes to schema)\n",
    "BASELINE_TOP10_CSV = os.path.join(OUT_DIR, \"sbert_ranking_output.csv\")\n",
    "base = pd.read_csv(BASELINE_TOP10_CSV)\n",
    "\n",
    "print(base.head(3))\n",
    "print(\"Queries in baseline:\", base[\"query\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6546e899",
   "metadata": {},
   "source": [
    "### Step 3 - Pretty printer (same style as Part 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2643cbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ranking(query, rows_df, score_col=\"score\", title_col=\"job_titles\", top_k=10):\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    for _, r in rows_df.head(top_k).iterrows():\n",
    "        print(f\"   {r[score_col]: .3f}  {r[title_col]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8800280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: data scientist\n",
      "    0.596  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.495  Human Resources Professional\n",
      "    0.457  Junior MES Engineer| Information Systems\n",
      "    0.450  Aspiring Human Resources Specialist\n",
      "    0.449  Human Resources professional for the world leader in GIS software\n",
      "    0.441  HR Senior Specialist\n",
      "    0.433  Human Resources Generalist at ScottMadden, Inc.\n",
      "    0.416  Liberal Arts Major. Aspiring Human Resources Analyst.\n",
      "    0.410  Student\n",
      "    0.403  Human Resources Specialist at Luxottica\n",
      "\n",
      "Query: machine learning engineer\n",
      "    0.596  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.495  Human Resources Professional\n",
      "    0.457  Junior MES Engineer| Information Systems\n",
      "    0.450  Aspiring Human Resources Specialist\n",
      "    0.449  Human Resources professional for the world leader in GIS software\n",
      "    0.441  HR Senior Specialist\n",
      "    0.433  Human Resources Generalist at ScottMadden, Inc.\n",
      "    0.416  Liberal Arts Major. Aspiring Human Resources Analyst.\n",
      "    0.410  Student\n",
      "    0.403  Human Resources Specialist at Luxottica\n",
      "\n",
      "Query: backend developer\n",
      "    0.596  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.495  Human Resources Professional\n",
      "    0.457  Junior MES Engineer| Information Systems\n",
      "    0.450  Aspiring Human Resources Specialist\n",
      "    0.449  Human Resources professional for the world leader in GIS software\n",
      "    0.441  HR Senior Specialist\n",
      "    0.433  Human Resources Generalist at ScottMadden, Inc.\n",
      "    0.416  Liberal Arts Major. Aspiring Human Resources Analyst.\n",
      "    0.410  Student\n",
      "    0.403  Human Resources Specialist at Luxottica\n",
      "\n",
      "Query: product manager\n",
      "    0.596  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.495  Human Resources Professional\n",
      "    0.457  Junior MES Engineer| Information Systems\n",
      "    0.450  Aspiring Human Resources Specialist\n",
      "    0.449  Human Resources professional for the world leader in GIS software\n",
      "    0.441  HR Senior Specialist\n",
      "    0.433  Human Resources Generalist at ScottMadden, Inc.\n",
      "    0.416  Liberal Arts Major. Aspiring Human Resources Analyst.\n",
      "    0.410  Student\n",
      "    0.403  Human Resources Specialist at Luxottica\n"
     ]
    }
   ],
   "source": [
    "for query in QUERIES:\n",
    "    print_ranking(query, base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e15710",
   "metadata": {},
   "source": [
    "### Step 4 - Experience with <img src=\"./sup_imgs/phi-3-mini.png\" width=\"225\" style=\"vertical-align: middle;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27da14b",
   "metadata": {},
   "source": [
    "**Phi-3 Mini (Microsoft)**\n",
    "- **Release Date**: April 23, 2024.\n",
    "- **Architecture**: Decoder-only (autoregressive).\n",
    "- **Parameters**: ~3.8B.\n",
    "- **Layers**: 32 transformer blocks, 32 attention heads.\n",
    "- **Context Window**: 4k tokens.\n",
    "- **Tokenizer**: SentencePiece-like (subword BPE).\n",
    "- **Objective**: Next-token prediction, trained as a general causal LM.\n",
    "- **Training**: Mixture of web, code, math, scientific texts; instruction-tuned for dialogue.\n",
    "- **Efficiency**: Optimized for small GPUs (runs on 8–12GB VRAM), strong FP16/INT8 support.\n",
    "- **License**: MIT-style permissive.\n",
    "- **Notes**: Very lightweight, deterministic, good for structured tasks on consumer GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e5c1958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.6.0+cu124\n",
      "built with CUDA: 12.4\n",
      "cuda available: True\n",
      "gpu: NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "print(\"torch:\", torch.__version__)\n",
    "print(\"built with CUDA:\", torch.version.cuda)\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"gpu:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ef92698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a508ae279bb9464b8a759c40c2ecb611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_ID = \"microsoft/phi-3-mini-4k-instruct\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
    "mdl = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    dtype=torch.float16 if torch.cuda.is_available() else None,\n",
    ").to(\"cuda\" if torch.cuda.is_available() else \"cpu\").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "394583c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a proper chat prompt\n",
    "msgs = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a calculator. Reply with digits only.\"},\n",
    "    {\"role\": \"user\",   \"content\": \"Return the number 7.\"}\n",
    "]\n",
    "prompt = tok.apply_chat_template(msgs, tokenize=False, add_generation_prompt=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ca4e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode & generate (greedy)\n",
    "inputs = tok(prompt, return_tensors=\"pt\").to(mdl.device)\n",
    "eos = [tok.eos_token_id]\n",
    "try:\n",
    "    eos.append(tok.convert_tokens_to_ids(\"<|end|>\"))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82e8d1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = mdl.generate(\n",
    "    **inputs,\n",
    "    do_sample=False,\n",
    "    num_beams=1,\n",
    "    max_new_tokens=3,\n",
    "    eos_token_id=eos,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27e410f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "out = tok.decode(gen[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True).strip()\n",
    "print(out)  # -> 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699f9861",
   "metadata": {},
   "source": [
    "### Step 5 — turn LLM into a job title ranker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e8837f",
   "metadata": {},
   "source": [
    "We will turn the LLM into a ranker by asking it to assign an integer score (0–100) to each raw job title for a given query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e07e1c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_all_chat_phi(query: str, titles: list[str]) -> str:\n",
    "    lines = \"\\n\".join(f\"{i+1}) {t}\" for i, t in enumerate(titles))\n",
    "    rubric = (\n",
    "        \"You are a recruiter scoring job-title similarity to the query.\\n\"\n",
    "        \"Rate each candidate with an integer 0–100 using the FULL scale:\\n\"\n",
    "        \" • 90–100 = exact/near-exact role match\\n\"\n",
    "        \" • 70–89  = same discipline or very similar role\\n\"\n",
    "        \" • 40–69  = related/adjacent\\n\"\n",
    "        \" • 10–39  = mostly unrelated\\n\"\n",
    "        \" • 0–9    = completely unrelated\\n\"\n",
    "        \"Use diverse scores; do NOT give 0 or 100 to many candidates.\\n\"\n",
    "        \"Ignore employer names, locations, programs.\\n\"\n",
    "        \"Output EXACTLY one integer per line, in the SAME ORDER as the candidates. No words, no punctuation.\"\n",
    "    )\n",
    "    # Non-extreme example\n",
    "    example = \"Example for 3 candidates:\\n82\\n41\\n7\"\n",
    "    user = f'Query: \"{query}\"\\n\\nCandidates:\\n{lines}\\n\\n{example}'\n",
    "    msgs = [{\"role\": \"system\", \"content\": rubric},\n",
    "            {\"role\": \"user\",   \"content\": user}]\n",
    "    return tok.apply_chat_template(msgs, tokenize=False, add_generation_prompt=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fd5fca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_scores_n(out: str, n: int) -> list[int]:\n",
    "    # prefer last int per non-empty line; fallback to last N ints in whole text\n",
    "    lines = [l.strip() for l in out.splitlines() if l.strip()]\n",
    "    scores = []\n",
    "    \n",
    "    for line in lines:\n",
    "        ints = re.findall(r\"-?\\d+\", line)\n",
    "        if ints:\n",
    "            scores.append(int(ints[-1]))\n",
    "        if len(scores) >= n:\n",
    "            break\n",
    "        \n",
    "    if len(scores) < n:\n",
    "        all_ints = [int(x) for x in re.findall(r\"-?\\d+\", out)]\n",
    "        scores = all_ints[-n:]\n",
    "        \n",
    "    scores = [max(0, min(100, int(s))) for s in scores]\n",
    "    \n",
    "    # if still short, add a padding\n",
    "    if len(scores) < n:  \n",
    "        scores += [0] * (n - len(scores))\n",
    "    return scores[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b170f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_all_titles_once(query: str,\n",
    "                          titles: list[str],\n",
    "                          max_new_tokens: int = 300,\n",
    "                          build_fn=None):\n",
    "    build_fn = build_fn or build_prompt_all_chat_phi\n",
    "    prompt = build_fn(query, titles)\n",
    "    print(\"Prompt tokens:\", len(tok(prompt)[\"input_ids\"]))\n",
    "    inputs = tok(prompt, return_tensors=\"pt\").to(mdl.device)\n",
    "    gen = mdl.generate(\n",
    "        **inputs,\n",
    "        do_sample=False,\n",
    "        num_beams=1,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        eos_token_id=[tok.eos_token_id],\n",
    "        min_new_tokens=min(len(titles), max_new_tokens-1),\n",
    "    )\n",
    "    out_text = tok.decode(gen[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True)\n",
    "    scores = parse_scores_n(out_text, len(titles))\n",
    "    df = pd.DataFrame({\"idx\": range(len(titles)), \"score\": scores})\n",
    "    df[\"job_titles\"] = [titles[i] for i in df[\"idx\"]]\n",
    "    df = df.sort_values(\"score\", ascending=False).reset_index(drop=True)\n",
    "    return df, out_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8ee9d3",
   "metadata": {},
   "source": [
    "Test **build_prompt_all_chat**, **parse_scores_n** and **score_all_tittles_once**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e1c94d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DEMO PROMPT (first 30 lines) ===\n",
      "<|system|>\n",
      "You are a recruiter scoring job-title similarity to the query.\n",
      "Rate each candidate with an integer 0–100 using the FULL scale:\n",
      " • 90–100 = exact/near-exact role match\n",
      " • 70–89  = same discipline or very similar role\n",
      " • 40–69  = related/adjacent\n",
      " • 10–39  = mostly unrelated\n",
      " • 0–9    = completely unrelated\n",
      "Use diverse scores; do NOT give 0 or 100 to many candidates.\n",
      "Ignore employer names, locations, programs.\n",
      "Output EXACTLY one integer per line, in the SAME ORDER as the candidates. No words, no punctuation.<|end|>\n",
      "<|user|>\n",
      "Query: \"data scientist\"\n",
      "\n",
      "Candidates:\n",
      "1) 2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "2) Native English Teacher at EPIK (English Program in Korea)\n",
      "3) Aspiring Human Resources Professional\n",
      "4) People Development Coordinator at Ryan\n",
      "5) Advisory Board Member at Celal Bayar University\n",
      "\n",
      "Example for 3 candidates:\n",
      "82\n",
      "41\n",
      "7<|end|>\n",
      "<|assistant|>\n",
      "Token count (subset): 279\n"
     ]
    }
   ],
   "source": [
    "test_query = \"data scientist\"\n",
    "\n",
    "# A Tiny subset to inspect everything\n",
    "subset = titles[:5]\n",
    "\n",
    "demo_prompt = build_prompt_all_chat_phi(test_query, subset)\n",
    "print(\"=== DEMO PROMPT (first 30 lines) ===\")\n",
    "print(\"\\n\".join(demo_prompt.splitlines()[:30]))\n",
    "print(\"Token count (subset):\", len(tok(demo_prompt)[\"input_ids\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0dd40f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt tokens: 279\n",
      "\n",
      "=== RAW MODEL OUTPUT (subset) ===\n",
      "0\n",
      "0\n",
      "7\n",
      "41\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df_sub, raw_sub = score_all_titles_once(test_query, subset, max_new_tokens=60)\n",
    "print(\"\\n=== RAW MODEL OUTPUT (subset) ===\")\n",
    "print(raw_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5738ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parsed scores (subset): [0, 0, 7, 41, 0]\n",
      "\n",
      "Paired (score, title) in ranked order:\n",
      " 41  People Development Coordinator at Ryan\n",
      "  7  Aspiring Human Resources Professional\n",
      "  0  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "  0  Native English Teacher at EPIK (English Program in Korea)\n",
      "  0  Advisory Board Member at Celal Bayar University\n"
     ]
    }
   ],
   "source": [
    "scores_sub = parse_scores_n(raw_sub, len(subset))\n",
    "print(\"\\nParsed scores (subset):\", scores_sub)\n",
    "print(\"\\nPaired (score, title) in ranked order:\")\n",
    "# the output DataFrame from `socre_all_titles_once`, df_sub, is sorted in not ascending order\n",
    "for _, r in df_sub.iterrows():\n",
    "    print(f\"{r['score']:>3}  {r['job_titles']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89bafef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Token count (full): 1928\n"
     ]
    }
   ],
   "source": [
    "# B) One full run (preview only; avoids flooding output)\n",
    "full_prompt = build_prompt_all_chat_phi(test_query, titles)\n",
    "print(\"\\nToken count (full):\", len(tok(full_prompt)[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2197f9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncation of long strings\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.width\", 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d261d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt tokens: 1928\n",
      "\n",
      "Full run: got 104 scores.\n",
      "Top-3 preview:\n",
      "   score                                                                                                job_titles\n",
      "0    100                                         Student at Humber College and Aspiring Human Resources Generalist\n",
      "1    100                                                           Advisory Board Member at Celal Bayar University\n",
      "2    100                                                                     Aspiring Human Resources Professional\n",
      "3     90                                                                       Aspiring Human Resources Specialist\n",
      "4     89                                         Student at Humber College and Aspiring Human Resources Generalist\n",
      "5     74                                                                     Aspiring Human Resources Professional\n",
      "6     72                                                 Native English Teacher at EPIK (English Program in Korea)\n",
      "7     70  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "8     70                                                                                      HR Senior Specialist\n",
      "9     69                                                                             Student at Chapman University\n"
     ]
    }
   ],
   "source": [
    "df_full, raw_full = score_all_titles_once(test_query, titles, max_new_tokens=300)\n",
    "print(\"\\nFull run: got\", len(df_full), \"scores.\")\n",
    "print(\"Top-3 preview:\")\n",
    "print(df_full.head(10)[[\"score\", \"job_titles\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ce5f589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ranking(query, rows_df, top_k=10):\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    for _, r in rows_df.head(top_k).iterrows():\n",
    "        print(f\"   {r['score']/100: .3f}  {r['job_titles']}\")\n",
    "\n",
    "def run_query_full(queries: list[str],\n",
    "                   model_tag: str = \"phi3_mini_4k\",\n",
    "                   build_prompt_fn=None):\n",
    "    out_dir = os.path.join(OUT_DIR, \"llm\"); os.makedirs(out_dir, exist_ok=True)\n",
    "    top10_blocks = []\n",
    "    for query in queries:\n",
    "        df_rank, raw = score_all_titles_once(query, titles, build_fn=build_prompt_fn)\n",
    "        print_ranking(query, df_rank, top_k=10)\n",
    "        df_q = df_rank.head(10)[[\"score\", \"job_titles\"]].copy()\n",
    "        df_q.insert(0, \"query\", query)\n",
    "        top10_blocks.append(df_q)\n",
    "    top10 = pd.concat(top10_blocks, ignore_index=True)\n",
    "    path = os.path.join(out_dir, f\"llm_top10__{model_tag}__all_queries.csv\")\n",
    "    top10.to_csv(path, index=False)\n",
    "    print(\"Saved:\", path)\n",
    "    return top10, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8de3570e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt tokens: 1928\n",
      "\n",
      "Query: data scientist\n",
      "    1.000  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    1.000  Advisory Board Member at Celal Bayar University\n",
      "    1.000  Aspiring Human Resources Professional\n",
      "    0.900  Aspiring Human Resources Specialist\n",
      "    0.890  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.740  Aspiring Human Resources Professional\n",
      "    0.720  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.700  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.700  HR Senior Specialist\n",
      "    0.690  Student at Chapman University\n",
      "Prompt tokens: 1928\n",
      "\n",
      "Query: machine learning engineer\n",
      "    1.000  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    1.000  Advisory Board Member at Celal Bayar University\n",
      "    1.000  Aspiring Human Resources Professional\n",
      "    0.900  Aspiring Human Resources Specialist\n",
      "    0.890  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.740  Aspiring Human Resources Professional\n",
      "    0.720  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.700  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.700  HR Senior Specialist\n",
      "    0.690  Student at Chapman University\n",
      "Prompt tokens: 1927\n",
      "\n",
      "Query: backend developer\n",
      "    1.000  Advisory Board Member at Celal Bayar University\n",
      "    0.750  Aspiring Human Resources Specialist\n",
      "    0.700  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.700  Aspiring Human Resources Professional\n",
      "    0.700  People Development Coordinator at Ryan\n",
      "    0.700  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.700  SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR\n",
      "    0.700  Seeking Human Resources HRIS and Generalist Positions\n",
      "    0.700  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.700  People Development Coordinator at Ryan\n",
      "Prompt tokens: 1927\n",
      "\n",
      "Query: product manager\n",
      "    1.000  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    1.000  Advisory Board Member at Celal Bayar University\n",
      "    1.000  Aspiring Human Resources Professional\n",
      "    0.900  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.900  Aspiring Human Resources Specialist\n",
      "    0.900  Aspiring Human Resources Professional\n",
      "    0.890  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.700  HR Senior Specialist\n",
      "    0.690  Student at Chapman University\n",
      "    0.410  Native English Teacher at EPIK (English Program in Korea)\n",
      "Saved: outputs\\llm\\llm_top10__phi3_mini_4k__listwise__all_queries.csv\n"
     ]
    }
   ],
   "source": [
    "top10_phi, path_phi = run_query_full(\n",
    "    QUERIES,\n",
    "    model_tag=\"phi3_mini_4k__listwise\",\n",
    "    build_prompt_fn=build_prompt_all_chat_phi\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86751029",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbc3436",
   "metadata": {},
   "source": [
    "### Step 6 - Experience with Gemma-2-2b-it   <img src=\"./sup_imgs/gemma2.webp\" width=\"225\" style=\"vertical-align: middle;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89602a3",
   "metadata": {},
   "source": [
    "**Gemma-2-2B-IT (Google)**\n",
    "- **Release Date**: June 27, 2024 (Gemma 2 family launch).\n",
    "- **Architecture**: Decoder-only (autoregressive).\n",
    "- **Parameters**: ~2.6B.\n",
    "- **Layers**: ~26 transformer layers (with RoPE).\n",
    "- **Context Window**: 8k tokens.\n",
    "- **Tokenizer**: SentencePiece (same family as PaLM-2 / Gemini).\n",
    "- **Objective**: Next-token prediction with instruction-tuning.\n",
    "- **Training**: Web-scale datasets filtered for quality, multilingual corpora.\n",
    "- **Efficiency**: Ultra-compact, designed for edge devices; runs well on 6–8GB GPUs.\n",
    "- **License**: Apache 2.0 (permissive).\n",
    "- *Notes*: Very small but instruction-tuned, produces stable integer list outputs if well-prompted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75339a6d",
   "metadata": {},
   "source": [
    "Free the GPU's allocated memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c681f9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d273108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_GPU_memory():\n",
    "    def print_vram(prefix=\"\"):\n",
    "        if not torch.cuda.is_available():\n",
    "            print(prefix + \"CUDA not available\")\n",
    "            return\n",
    "        torch.cuda.synchronize()\n",
    "        alloc = torch.cuda.memory_allocated() / (1024**2)      # MiB\n",
    "        reserv = torch.cuda.memory_reserved() / (1024**2)      # MiB\n",
    "        total = torch.cuda.get_device_properties(0).total_memory / (1024**2)\n",
    "        print(f\"\\n{prefix}allocated: {alloc:.1f} MiB | reserved: {reserv:.1f} MiB | total: {total:,.0f} MiB\")\n",
    "\n",
    "    # Print memory allocation before freeing it\n",
    "    print(\"Measure memory usage before and after freeing it\")\n",
    "    print_vram(\"Before:\\n\")\n",
    "\n",
    "    # move model to CPU + delete big refs\n",
    "    try: mdl.to(\"cpu\")\n",
    "    except: pass\n",
    "    # free memory\n",
    "    for name in (\"pipe\",\"mdl\",\"tok\",\"inputs\",\"gen\"):\n",
    "        if name in globals(): del globals()[name]\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()\n",
    "    print_vram(\"After:\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34982006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measure memory usage before and after freeing it\n",
      "\n",
      "Before:\n",
      "allocated: 7296.5 MiB | reserved: 8596.0 MiB | total: 11,264 MiB\n",
      "\n",
      "After:\n",
      "allocated: 8.1 MiB | reserved: 20.0 MiB | total: 11,264 MiB\n"
     ]
    }
   ],
   "source": [
    "free_GPU_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32ee0d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a69b2999974b22992a388513fbd2c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "MODEL_ID = \"google/gemma-2-2b-it\"\n",
    "HF_TOKEN = os.getenv(\"llm_gemma\")\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
    "mdl = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    dtype=torch.float16 if device.type==\"cuda\" else None,\n",
    "    token=HF_TOKEN\n",
    ").to(device).eval()\n",
    "\n",
    "if tok.pad_token_id is None:\n",
    "    tok.pad_token = tok.eos_token\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=mdl, tokenizer=tok, device=0 if device.type==\"cuda\" else -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d27f0eb",
   "metadata": {},
   "source": [
    "Define a newer **prompt builder** function with a one-shot prompt and being more specific with the matching job titles. Also it drops the `system role` options that we used with Phi-3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ccf6aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_prompt_all_chat_gemma(query: str, titles: list[str]) -> str:\n",
    "    lines = \"\\n\".join(f\"{i+1}) {t}\" for i, t in enumerate(titles))\n",
    "    rubric = (\n",
    "        \"You are a recruiter scoring job-title similarity to the query.\\n\"\n",
    "        \"Rate each candidate with an integer between zero and one hundred using the full scale.\\n\"\n",
    "        \"Use diverse scores; avoid giving many zeros or many hundreds.\\n\"\n",
    "        \"Ignore employer names, locations, and programs.\\n\"\n",
    "        \"Return EXACTLY one integer per line in the SAME ORDER as the candidates.\\n\"\n",
    "        \"No words, no punctuation, no numbering.\\n\"\n",
    "    )\n",
    "    user_text = f'Query: \"{query}\"\\n\\nCandidates:\\n{lines}\\n\\nSCORES:'\n",
    "    # Gemma’s template may not support a system role → fold rubric into the user turn\n",
    "    msgs = [{\"role\": \"user\", \"content\": rubric + \"\\n\\n\" + user_text}]\n",
    "    return tok.apply_chat_template(msgs, tokenize=False, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8ee904a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt tokens: 1583\n",
      "\n",
      "Query: data scientist\n",
      "    0.200  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.100  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.100  Aspiring Human Resources Professional\n",
      "    0.100  People Development Coordinator at Ryan\n",
      "    0.100  Advisory Board Member at Celal Bayar University\n",
      "    0.100  Aspiring Human Resources Specialist\n",
      "    0.100  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.100  HR Senior Specialist\n",
      "    0.100  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.100  Seeking Human Resources HRIS and Generalist Positions\n",
      "Prompt tokens: 1584\n",
      "\n",
      "Query: machine learning engineer\n",
      "    0.200  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.100  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.100  Aspiring Human Resources Professional\n",
      "    0.100  People Development Coordinator at Ryan\n",
      "    0.100  Advisory Board Member at Celal Bayar University\n",
      "    0.100  Aspiring Human Resources Specialist\n",
      "    0.100  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.100  HR Senior Specialist\n",
      "    0.100  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.100  Seeking Human Resources HRIS and Generalist Positions\n",
      "Prompt tokens: 1583\n",
      "\n",
      "Query: backend developer\n",
      "    0.200  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.100  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.100  Aspiring Human Resources Professional\n",
      "    0.100  People Development Coordinator at Ryan\n",
      "    0.100  Advisory Board Member at Celal Bayar University\n",
      "    0.100  Aspiring Human Resources Specialist\n",
      "    0.100  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.100  HR Senior Specialist\n",
      "    0.100  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.100  Seeking Human Resources HRIS and Generalist Positions\n",
      "Prompt tokens: 1583\n",
      "\n",
      "Query: product manager\n",
      "    0.300  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.250  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.250  People Development Coordinator at Ryan\n",
      "    0.250  Aspiring Human Resources Specialist\n",
      "    0.200  Aspiring Human Resources Professional\n",
      "    0.200  Advisory Board Member at Celal Bayar University\n",
      "    0.200  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.200  HR Senior Specialist\n",
      "    0.200  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.200  Seeking Human Resources HRIS and Generalist Positions\n",
      "Saved: outputs\\llm\\llm_top10__gemma-2-2b-it__listwise__all_queries.csv\n"
     ]
    }
   ],
   "source": [
    "top10_gemma, path_gemma = run_query_full(\n",
    "    QUERIES,\n",
    "    model_tag=\"gemma-2-2b-it__listwise\",\n",
    "    build_prompt_fn=build_prompt_all_chat_gemma\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faf58ee",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc2dd09",
   "metadata": {},
   "source": [
    "### Step 7 - Experience with Qwen2.5-3B-Instruct from <img src=\"./sup_imgs/Qwen_Logo.svg.png\" width=\"175\" style=\"vertical-align: middle;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561f3a4d",
   "metadata": {},
   "source": [
    "**Qwen2.5-3B-Instruct (Alibaba / Qwen Team)**\n",
    "- **Release Date**: September 5, 2024 (Qwen2.5 family release).\n",
    "- **Architecture**: Decoder-only (autoregressive).\n",
    "- **Parameters**: ~2.7–3B.\n",
    "- **Layers**: 28 transformer layers, 32 attention heads.\n",
    "- **Context Window**: 32k tokens (longest among your three).\n",
    "- **Tokenizer**: Custom BPE with multilingual coverage.\n",
    "- **Objective**: Next-token prediction, instruction-tuned with ChatML formatting.\n",
    "- **Training**: Massive multilingual web + code datasets, plus safety/alignment finetuning.\n",
    "- **Efficiency**: Larger context needs more VRAM, but still runnable on 12GB with FP16/INT8.\n",
    "- **License**: Apache 2.0.\n",
    "- *Notes*: Very strong for structured outputs (list-style, JSON); context length makes it robust for 104-title scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a40cf0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measure memory usage before and after freeing it\n",
      "\n",
      "Before:\n",
      "allocated: 4995.6 MiB | reserved: 5710.0 MiB | total: 11,264 MiB\n",
      "\n",
      "After:\n",
      "allocated: 8.1 MiB | reserved: 20.0 MiB | total: 11,264 MiB\n"
     ]
    }
   ],
   "source": [
    "free_GPU_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "552fa1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf94d44a5b94638b7b155225117f1c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_ID = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
    "mdl = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    dtype=torch.float16 if torch.cuda.is_available() else None,\n",
    ").to(\"cuda\" if torch.cuda.is_available() else \"cpu\").eval()\n",
    "\n",
    "if tok.pad_token_id is None:\n",
    "    tok.pad_token = tok.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "079e660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qwen-specific prompt builder (ChatML-friendly, explicit N, hard stop)\n",
    "def build_prompt_all_chat_qwen(query: str, titles: list[str]) -> str:\n",
    "    n = len(titles)\n",
    "    lines = \"\\n\".join(f\"{i}) {t}\" for i, t in enumerate(titles, start=1))\n",
    "\n",
    "    rubric = (\n",
    "        \"You are a recruiter scoring job-title similarity to the query.\\n\"\n",
    "        \"Score each candidate with an integer 0–100 using the FULL scale:\\n\"\n",
    "        \"  90–100 = exact/near-exact role match\\n\"\n",
    "        \"  70–89  = same discipline or very similar role\\n\"\n",
    "        \"  40–69  = related/adjacent\\n\"\n",
    "        \"  20–39  = mostly unrelated\\n\"\n",
    "        \"  0–19   = completely unrelated\\n\"\n",
    "        \"Rules:\\n\"\n",
    "        \" - Prefer same functional domain as the query.\\n\"\n",
    "        \" - If the query is technical (data/ML/backend), HR/People titles are mostly unrelated.\\n\"\n",
    "        \" - Titles with 'Student' or 'Aspiring' get lower scores unless they explicitly match the role.\\n\"\n",
    "        f\"Output EXACTLY {n} integers, one per line, in the SAME ORDER as the candidates.\\n\"\n",
    "        \"No words, no commas, no numbering, no punctuation.\\n\"\n",
    "        f\"After the {n}th line, output the token <END> and stop.\"\n",
    "    )\n",
    "\n",
    "    # very small one-shot to demonstrate format (3 lines + <END>)\n",
    "    # keep it generic so it transfers across queries\n",
    "    example = (\n",
    "        \"Example (3 candidates):\\n\"\n",
    "        \"Candidates:\\n\"\n",
    "        \"1) Senior Data Scientist\\n\"\n",
    "        \"2) HR Coordinator\\n\"\n",
    "        \"3) Retail Cashier\\n\"\n",
    "        \"Expected output:\\n\"\n",
    "        \"95\\n\"\n",
    "        \"20\\n\"\n",
    "        \"0\\n\"\n",
    "        \"<END>\"\n",
    "    )\n",
    "\n",
    "    user_text = (\n",
    "        f\"{rubric}\\n\\n\"\n",
    "        f'Query: \"{query}\"\\n\\n'\n",
    "        f\"Candidates:\\n{lines}\\n\\n\"\n",
    "        f\"{example}\"\n",
    "    )\n",
    "\n",
    "    # Qwen supports system; if anything fails, fall back to user-only.\n",
    "    msgs_sys = [\n",
    "        {\"role\": \"system\", \"content\": \"You are precise and output only the requested numbers.\"},\n",
    "        {\"role\": \"user\",   \"content\": user_text},\n",
    "    ]\n",
    "    msgs_user = [{\"role\": \"user\", \"content\": user_text}]  # fallback\n",
    "\n",
    "    try:\n",
    "        return tok.apply_chat_template(msgs_sys, tokenize=False, add_generation_prompt=True)\n",
    "    except Exception:\n",
    "        return tok.apply_chat_template(msgs_user, tokenize=False, add_generation_prompt=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23b2a4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt tokens: 1774\n",
      "\n",
      "Query: data scientist\n",
      "    0.900  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.900  People Development Coordinator at Ryan\n",
      "    0.900  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.900  People Development Coordinator at Ryan\n",
      "    0.900  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.900  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.900  Human Resources Coordinator at InterContinental Buckhead Atlanta\n",
      "    0.900  Seeking Human Resources HRIS and Generalist Positions\n",
      "    0.900  People Development Coordinator at Ryan\n",
      "    0.900  Student at Humber College and Aspiring Human Resources Generalist\n",
      "Prompt tokens: 1775\n",
      "\n",
      "Query: machine learning engineer\n",
      "    0.900  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.400  People Development Coordinator at Ryan\n",
      "    0.000  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.000  Aspiring Human Resources Professional\n",
      "    0.000  Advisory Board Member at Celal Bayar University\n",
      "    0.000  Aspiring Human Resources Specialist\n",
      "    0.000  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.000  HR Senior Specialist\n",
      "    0.000  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.000  Seeking Human Resources HRIS and Generalist Positions\n",
      "Prompt tokens: 1774\n",
      "\n",
      "Query: backend developer\n",
      "    0.900  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.900  People Development Coordinator at Ryan\n",
      "    0.900  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.900  People Development Coordinator at Ryan\n",
      "    0.900  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.900  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.900  Human Resources Coordinator at InterContinental Buckhead Atlanta\n",
      "    0.900  Seeking Human Resources HRIS and Generalist Positions\n",
      "    0.900  People Development Coordinator at Ryan\n",
      "    0.900  Student at Humber College and Aspiring Human Resources Generalist\n",
      "Prompt tokens: 1774\n",
      "\n",
      "Query: product manager\n",
      "    0.900  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.900  People Development Coordinator at Ryan\n",
      "    0.900  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.900  People Development Coordinator at Ryan\n",
      "    0.900  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.900  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.900  Human Resources Coordinator at InterContinental Buckhead Atlanta\n",
      "    0.900  Seeking Human Resources HRIS and Generalist Positions\n",
      "    0.900  People Development Coordinator at Ryan\n",
      "    0.900  Student at Humber College and Aspiring Human Resources Generalist\n",
      "Saved: outputs\\llm\\llm_top10__qwen2.5-3b-instruct__listwise__all_queries.csv\n"
     ]
    }
   ],
   "source": [
    "top10_qwen, path_qwen = run_query_full(\n",
    "    QUERIES,\n",
    "    model_tag=\"qwen2.5-3b-instruct__listwise\",\n",
    "    build_prompt_fn=build_prompt_all_chat_qwen\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4f46ea",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b188ef",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511f7cb9",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcb4251",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a02d1b",
   "metadata": {},
   "source": [
    "### Step 8 - Experience with Kimi K2 from <img src=\"./sup_imgs/moonshot_AI.png\" width=\"175\" style=\"vertical-align: middle;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519ce568",
   "metadata": {},
   "source": [
    "**Kimi K2 (K2-0711)/ Moonshot AI**\n",
    "- **Release Date**: July 11, 2025.\n",
    "- **Architecture**: Mixture-of-Experts (MoE) Transformer with MLA (Multi-head Latent Attention)\n",
    "- **Parameters**: ~1T total, ~32B activated (MoE).\n",
    "- **Layers**: 61 total (including 1 dense layer); 64 attention heads; 384 experts; 8 selected experts per token; 1 shared expert.\n",
    "- **Context Window**: 256K tokens (longest among your three).\n",
    "- **Tokenizer**: Custom tokenizer; covab size 160K.\n",
    "- **Objective**: Language Modeling (causal/next-token) with multi-stage post-training focused on agentic capabilities (tool use, planning) using RL variants.\n",
    "- **Training**: Pre-trained on 15.T tokens with the MuonChip optimizer; post-training includes large-scale agentic data synthesis and RLVR + self-critique.\n",
    "- **Efficiency**: MoE with 32B active params; block-FP8 checkpointsl recommended engines include vLLM, SGLang, KTransformers, TensorRT-LLM\n",
    "- **License**: Modified MIT (code and weights)\n",
    "- *Notes*: OpenAI/Anthropic-compatible API available via platform.moonshot.ai; recommended temperature ~ 0.6 for Instruct variants; strong tool-calling support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fbab0f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measure memory usage before and after freeing it\n",
      "\n",
      "Before:\n",
      "allocated: 6002.6 MiB | reserved: 6798.0 MiB | total: 11,264 MiB\n",
      "\n",
      "After:\n",
      "allocated: 8.1 MiB | reserved: 20.0 MiB | total: 11,264 MiB\n"
     ]
    }
   ],
   "source": [
    "free_GPU_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1de0a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from typing import List, Tuple\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b709f5cc",
   "metadata": {},
   "source": [
    "For this model we will use the MOONSHOT API. Therefor, we will read the API KEY from the .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ca16f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"MOONSHOT_API_KEY\")\n",
    "base_url = os.getenv(\"MOONSHOT_API_BASE\", \"https://api.moonshot.ai/v1\")\n",
    "if not api_key:\n",
    "    raise RuntimeError(\"MOONSHOT_API_KEY is not set. Check your .env or environment.\")\n",
    "\n",
    "client = OpenAI(api_key=api_key, base_url=base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90bfbbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose model (check Moonshot platform for latest stable/previews)\n",
    "KIMI_MODEL_ID = os.getenv(\"KIMI_MODEL_ID\", \"kimi-k2-0905-preview\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f565ce4",
   "metadata": {},
   "source": [
    "##### Here we add a thin **Kimi (Moonshot)** adapter so the evaluation pipeline stays identical to previous local HF models: same rubric/prompt format, same strict parser (`parse_scores_n` → exactly **N** integers 0–100), same **ranking/CSV artifacts**, and **temperature=0** for determinism. \n",
    "\n",
    "##### The only change is the generation call (OpenAI-compatible Chat Completions API) wrapped by `score_all_titles_once_kimi` and `run_query_full_kimi`. This preserves apples-to-apples comparisons against Reference-A (ChatGPT-5) while letting swap models with just the prompt builder and the scorer entry point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "79dd7d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kimi prompt builder (simple, parser-friendly, same rubric)\n",
    "def build_scoring_prompt_kimi(query: str, candidates: list[str]) -> str:\n",
    "    n = len(candidates)\n",
    "    header = (\n",
    "        \"You are a recruiter scoring job-title similarity to the query\\n\"\n",
    "        \"Rate each candidate with an integer 0–100 using the FULL scale:\\n\"\n",
    "        \"• 90–100 = exact/near-exact role match\\n\"\n",
    "        \"• 70–89  = same discipline or very similar role\\n\"\n",
    "        \"• 40–69  = related/adjacent\\n\"\n",
    "        \"• 10–39  = mostly unrelated\\n\"\n",
    "        \"• 0–9    = completely unrelated\\n\"\n",
    "        \"Use diverse scores; do NOT give 0 or 100 to many candidates.\\n\"\n",
    "        \"Ignore employer names, locations, programs.\\n\"\n",
    "        f\"Output EXACTLY {n} integers, one per line, in the SAME ORDER as the candidates.\\n\"\n",
    "        \"Integers ONLY (no decimals, no percentages, no words, no punctuation).\\n\\n\"\n",
    "        \"Example for 3 candidates:\\n82\\n41\\n7\\n\"\n",
    "        \"---\\n\"\n",
    "    )\n",
    "    return header + f'Query: \"{query}\"\\nCandidates:\\n' + \"\\n\".join(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3f17ac22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kimi scorer (adapter with same return shape as your local scorer)\n",
    "def score_all_titles_once_kimi(query: str,\n",
    "                               titles: list[str],\n",
    "                               max_new_tokens: int = 1200,\n",
    "                               build_fn=build_scoring_prompt_kimi):\n",
    "    prompt = build_fn(query, titles)\n",
    "    resp = client.chat.completions.create(\n",
    "        model=KIMI_MODEL_ID,         \n",
    "        temperature=0.1,\n",
    "        top_p=1.0,\n",
    "        frequency_penalty=0.2,\n",
    "        max_tokens=max_new_tokens,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "    # debug code\n",
    "    # raw = resp.choices[0].message.content or \"\"\n",
    "    # lines = [ln for ln in raw.splitlines() if ln.strip()]\n",
    "    # print(\"parsed_ints:\", sum(ln.strip().isdigit() for ln in lines))\n",
    "    # print(\"unique_ints:\", len({int(ln.strip()) for ln in lines if ln.strip().isdigit()}))\n",
    "\n",
    "    out_text = resp.choices[0].message.content or \"\"\n",
    "    scores = parse_scores_n(out_text, len(titles))   # reuse the original parser\n",
    "    df = pd.DataFrame({\"idx\": range(len(titles)), \"score\": scores})\n",
    "    df[\"job_titles\"] = [titles[i] for i in df[\"idx\"]]\n",
    "    df = df.sort_values(\"score\", ascending=False).reset_index(drop=True)\n",
    "    return df, out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e142dfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper runner mirroring the run_query_full original function\n",
    "def run_query_full_kimi(queries: list[str],\n",
    "                        model_tag: str = \"kimi-k2-0905\",\n",
    "                        build_prompt_fn=build_scoring_prompt_kimi):\n",
    "    out_dir = os.path.join(OUT_DIR, \"llm\"); os.makedirs(out_dir, exist_ok=True)\n",
    "    top10_blocks = []\n",
    "    for query in queries:\n",
    "        df_rank, raw = score_all_titles_once_kimi(query, titles, build_fn=build_prompt_fn)\n",
    "        print_ranking(query, df_rank, top_k=10)   # <- reuse pretty-printer\n",
    "        df_q = df_rank.head(10)[[\"score\", \"job_titles\"]].copy()\n",
    "        df_q.insert(0, \"query\", query)\n",
    "        top10_blocks.append(df_q)\n",
    "    top10 = pd.concat(top10_blocks, ignore_index=True)\n",
    "    path = os.path.join(out_dir, f\"llm_top10__{model_tag}__all_queries.csv\")\n",
    "    top10.to_csv(path, index=False)\n",
    "    print(\"Saved:\", path)\n",
    "    return top10, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a80ff3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: data scientist\n",
      "    0.280  Human Resources Professional\n",
      "    0.270  Aspiring Human Resources Manager, seeking internship in Human Resources.\n",
      "    0.260  Business Management Major and Aspiring Human Resources Manager\n",
      "    0.250  Human Resources Generalist at ScottMadden, Inc.\n",
      "    0.240  Retired Army National Guard Recruiter, office manager,  seeking a position in Human Resources.\n",
      "    0.230  Director of Human Resources North America, Groupe Beneteau\n",
      "    0.220  Human Resources Specialist at Luxottica\n",
      "    0.210  Human Resources, Staffing and Recruiting Professional\n",
      "    0.200  Experienced Retail Manager and aspiring Human Resources Professional\n",
      "    0.190  Human Resources Coordinator at InterContinental Buckhead Atlanta\n",
      "\n",
      "Query: machine learning engineer\n",
      "    0.080  SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR\n",
      "    0.080  Human Resources, Staffing and Recruiting Professional\n",
      "    0.070  Human Resources Professional\n",
      "    0.070  Retired Army National Guard Recruiter, office manager,  seeking a position in Human Resources.\n",
      "    0.070  Business Management Major and Aspiring Human Resources Manager\n",
      "    0.070  Student at Chapman University\n",
      "    0.070  Experienced Retail Manager and aspiring Human Resources Professional\n",
      "    0.070  Human Resources Specialist at Luxottica\n",
      "    0.070  Aspiring Human Resources Professional | Passionate about helping to create an inclusive and engaging work environment\n",
      "    0.060  Advisory Board Member at Celal Bayar University\n",
      "\n",
      "Query: backend developer\n",
      "    0.130  Seeking Human Resources HRIS and Generalist Positions\n",
      "    0.120  HR Senior Specialist\n",
      "    0.110  Aspiring Human Resources Specialist\n",
      "    0.100  People Development Coordinator at Ryan\n",
      "    0.090  Aspiring Human Resources Professional\n",
      "    0.080  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.070  Human Resources Coordinator at InterContinental Buckhead Atlanta\n",
      "    0.060  SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR\n",
      "    0.050  Student at Chapman University\n",
      "    0.040  Native English Teacher at EPIK (English Program in Korea)\n",
      "\n",
      "Query: product manager\n",
      "    0.300  Human Resources, Staffing and Recruiting Professional\n",
      "    0.290  Experienced Retail Manager and aspiring Human Resources Professional\n",
      "    0.280  Human Resources Coordinator at InterContinental Buckhead Atlanta\n",
      "    0.270  SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR\n",
      "    0.260  Student at Chapman University\n",
      "    0.250  Seeking Human Resources HRIS and Generalist Positions\n",
      "    0.240  HR Senior Specialist\n",
      "    0.230  Aspiring Human Resources Specialist\n",
      "    0.220  People Development Coordinator at Ryan\n",
      "    0.210  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "Saved: outputs\\llm\\llm_top10__kimi-k2-0905-preview__listwise__all_queries.csv\n"
     ]
    }
   ],
   "source": [
    "top10_kimi, path_kimi = run_query_full_kimi(\n",
    "    QUERIES,\n",
    "    model_tag=\"kimi-k2-0905-preview__listwise\",\n",
    "    build_prompt_fn=build_scoring_prompt_kimi\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45320d2",
   "metadata": {},
   "source": [
    "### Step 9 - Experience with <img src=\"./sup_imgs/LLaMA3.png\" alt=\"DeepSeek Logo\" width=\"175\" style=\"vertical-align: middle;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2702356e",
   "metadata": {},
   "source": [
    "**LLaMA 3.2 3B Instruct / Meta AI**\n",
    "- **Release Date**: September 25, 2024.\n",
    "- **Architecture**: Autoregressive (decoder-only) Transformer with Grouped-Query Attention (GQA) and RoPE  .\n",
    "- **Parameters**: ~3.21B\n",
    "- **Layers**: 28 transformer layers, 24 attention heads, 8 KV heads, hidden size 3072 (per model configs) \n",
    "- **Context Window**: 128K tokens\n",
    "- **Tokenizer**: Llama-3 tokenizer (BPE) with 128,256 vocab size (vs. 32K in Llama 2).\n",
    "- **Objective**: Causal next-token LM; instruction models aligned for dialogue/agentic tasks.\n",
    "- **Training**: Pretrained on up to ~9T+ tokens; for 1B/3B, destillation from Llama 3.1 8B/70B was used; knowledge cutoff Dec 2023.\n",
    "- **Efficiency**: Designed for edge/on-device and small-GPU use; keeps the long 128 K context for large candidate lists.\n",
    "- **License**: Llama 3.2 Community License.\n",
    "- *Notes*: Use recent Transformers with the official Llama 3.x chat template for best adherence to constrained outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1fa4d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measure memory usage before and after freeing it\n",
      "\n",
      "Before:\n",
      "allocated: 8.1 MiB | reserved: 20.0 MiB | total: 11,264 MiB\n",
      "\n",
      "After:\n",
      "allocated: 8.1 MiB | reserved: 20.0 MiB | total: 11,264 MiB\n"
     ]
    }
   ],
   "source": [
    "free_GPU_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0efe74",
   "metadata": {},
   "source": [
    "#### **\\\\!/** Note on running LLaMA locally (Windows, VRAM, and speed)\n",
    "\n",
    "I first tried `Llama 3.1 8B Instruct` in FP16/BF16 on Windows. With my GPU (~11 GB VRAM), the model didn’t fit, so device_map=\"auto\" offloaded layers to CPU.\n",
    "Result: **generation became very slow** (one run sat for ~28 minutes) because most of the compute happened on the CPU instead of the GPU.\n",
    "\n",
    "I also considered 4-bit quantization to fit 8B, but on Windows the **`bitsandbytes`** wheel isn’t reliably available/officially supported. It’s easier on Linux, but I’m avoiding that detour for now.\n",
    "\n",
    "Decision: switch to **`LLaMA 3 (3.2) 3B Instruct`**, which fits comfortably in ~11 GB and runs on the GPU at normal speed (no offload)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "246ee62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b194612ae524a189e5725e444596557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model: 3B Instruct (works well on ~11 GB VRAM)\n",
    "MODEL_ID = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_ID, token=os.getenv(\"HF_TOKEN\"), use_fast=True)\n",
    "\n",
    "mdl = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    dtype=torch.bfloat16 if torch.cuda.is_available() else None,  # or torch.float16\n",
    "    device_map=\"auto\",\n",
    "    token=os.getenv(\"HF_TOKEN\"),\n",
    "    #attn_implementation=\"flash_attention_2\",  # let Transformers pick SDPA/eager automatically\n",
    ").eval()\n",
    "\n",
    "if tok.pad_token_id is None:\n",
    "    tok.pad_token = tok.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "72271351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLaMA prompt builder (same simple rubric + 3-line example)\n",
    "def build_prompt_all_chat_llama(query: str, titles: list[str]) -> str:\n",
    "    n = len(titles)\n",
    "    rubric = (\n",
    "        \"You are a recruiter scoring job-title similarity to the query.\\n\"\n",
    "        \"Rate each candidate with an integer 0–100 using the FULL scale:\\n\"\n",
    "        \"• 90–100 = exact/near-exact • 70–89 = very similar • 40–69 = related\\n\"\n",
    "        \"• 10–39 = mostly unrelated • 0–9 = unrelated\\n\"\n",
    "        f\"Output EXACTLY {n} integers, one per line, in the SAME ORDER as the candidates.\\n\"\n",
    "        \"Integers ONLY (no decimals, no words, no punctuation). Use the full range; avoid identical scores.\\n\\n\"\n",
    "        f'Query: \"{query}\"\\n'\n",
    "        \"Candidates:\\n\" + \"\\n\".join(titles)\n",
    "    )\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are precise and output only the requested integers.\"},\n",
    "        {\"role\": \"user\", \"content\": rubric},\n",
    "    ]\n",
    "    try:\n",
    "        return tok.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    except Exception:\n",
    "        return rubric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc42160",
   "metadata": {},
   "source": [
    "#### The rationale for introducing the new pairwise scoring functions:\n",
    "\n",
    "With small local models (e.g., LLaMA-3.2-3B on ~11 GB VRAM), the original *listwise prompt*,“scoring all 104 titles at once”, is brittle. The model must hold a long rubric plus 100+ candidates and emit exactly 104 integers in order. In practice this led to early stopping, example-echoing, flat/identical scores across queries, and heavy parser padding with zeros.\n",
    "\n",
    "**The new design scores one title at a time**: one compact prompt per (query, title) returning a single integer (0–100). This drastically lowers the cognitive and formatting burden, so the 3B model gives stable, query-dependent scores with greedy decoding. A simple one-int parser replaces the fragile N-line parser, and the final ranking comes from sorting the 104 individual scores.\n",
    "\n",
    "To **balance quality vs. cost**, we’ll use a hybrid approach:\n",
    "• For local small LMs → pairwise (robust, accurate on the available hardware).\n",
    "• For hosted/strong LMs (DeepSeek R1, ChatGPT-class, Kimi K2, etc.) → **listwise** (one shot per query is cheaper and fast, and these models follow the rubric well).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90d6b4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Single-candidate prompt (zero-shot, integers only)\n",
    "def build_prompt_single_llama(query: str, title: str) -> str:\n",
    "    n = 1\n",
    "    instr = (\n",
    "        \"You are a recruiter scoring job-title similarity to the query.\\n\"\n",
    "        \"Return EXACTLY one integer 0–100.\\n\"\n",
    "        \"Scale:\\n\"\n",
    "        \" • 90–100 = exact/near-exact\\n\"\n",
    "        \" • 70–89  = very similar\\n\"\n",
    "        \" • 40–69  = related/adjacent\\n\"\n",
    "        \" • 10–39  = mostly unrelated\\n\"\n",
    "        \" • 0–9    = unrelated\\n\"\n",
    "        \"Return the integer ONLY (no words, no punctuation, no decimals).\"\n",
    "    )\n",
    "    user = f'Query: \"{query}\"\\nCandidate:\\n{title}'\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": instr},\n",
    "        {\"role\": \"user\",   \"content\": user},\n",
    "    ]\n",
    "    try:\n",
    "        return tok.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    except Exception:\n",
    "        return instr + \"\\n\\n\" + user\n",
    "\n",
    "# 2) Parse exactly one integer\n",
    "def parse_one_int(text: str) -> int:\n",
    "    import re\n",
    "    m = re.findall(r\"-?\\d+\", text)\n",
    "    if not m: \n",
    "        return 0\n",
    "    x = int(m[-1])\n",
    "    return max(0, min(100, x))\n",
    "\n",
    "# 3) Pairwise scorer that preserves your downstream format\n",
    "def score_titles_llama_pairwise(query: str, all_titles: list[str], max_new_tokens: int = 8):\n",
    "    rows = []\n",
    "    for i, title in enumerate(all_titles):\n",
    "        prompt = build_prompt_single_llama(query, title)\n",
    "        inputs = tok(prompt, return_tensors=\"pt\").to(mdl.device)\n",
    "        out_ids = mdl.generate(\n",
    "            **inputs,\n",
    "            do_sample=False,\n",
    "            num_beams=1,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            pad_token_id=tok.eos_token_id,\n",
    "            use_cache=True,\n",
    "        )\n",
    "        out_txt = tok.decode(out_ids[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True)\n",
    "        score = parse_one_int(out_txt)\n",
    "        rows.append({\"idx\": i, \"score\": score, \"job_titles\": title})\n",
    "\n",
    "    df = pd.DataFrame(rows).sort_values(\"score\", ascending=False).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# Runner that matches your existing CSV artifact shape\n",
    "def run_query_full_llama_pairwise(queries: list[str], model_tag: str = \"llama-3.2-3b-instruct-pairwise\"):\n",
    "    out_dir = os.path.join(OUT_DIR, \"llm\"); os.makedirs(out_dir, exist_ok=True)\n",
    "    top10_blocks = []\n",
    "    for q in queries:\n",
    "        df_rank = score_titles_llama_pairwise(q, titles)\n",
    "        print_ranking(q, df_rank, top_k=10)\n",
    "        df_q = df_rank.head(10)[[\"score\", \"job_titles\"]].copy()\n",
    "        df_q.insert(0, \"query\", q)\n",
    "        top10_blocks.append(df_q)\n",
    "    top10 = pd.concat(top10_blocks, ignore_index=True)\n",
    "    path = os.path.join(out_dir, f\"llm_top10__{model_tag}__all_queries.csv\")\n",
    "    top10.to_csv(path, index=False)\n",
    "    print(\"Saved:\", path)\n",
    "    return top10, path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b826a9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: data scientist\n",
      "    0.700  Business Intelligence and Analytics at Travelers\n",
      "    0.390  Junior MES Engineer| Information Systems\n",
      "    0.300  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.300  Human Resources|\n",
      "Conflict Management|\n",
      "Policies & Procedures|Talent Management|Benefits & Compensation\n",
      "    0.100  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.100  Aspiring Human Resources Professional\n",
      "    0.100  People Development Coordinator at Ryan\n",
      "    0.100  Aspiring Human Resources Specialist\n",
      "    0.100  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.100  People Development Coordinator at Ryan\n",
      "\n",
      "Query: machine learning engineer\n",
      "    0.400  Junior MES Engineer| Information Systems\n",
      "    0.390  Business Intelligence and Analytics at Travelers\n",
      "    0.300  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.100  Seeking Human Resources HRIS and Generalist Positions\n",
      "    0.100  Student at Chapman University\n",
      "    0.100  SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR\n",
      "    0.100  Student at Chapman University\n",
      "    0.100  Seeking Human Resources HRIS and Generalist Positions\n",
      "    0.100  Student at Chapman University\n",
      "    0.100  SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR\n",
      "\n",
      "Query: backend developer\n",
      "    0.400  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.390  Junior MES Engineer| Information Systems\n",
      "    0.390  Business Intelligence and Analytics at Travelers\n",
      "    0.300  Human Resources|\n",
      "Conflict Management|\n",
      "Policies & Procedures|Talent Management|Benefits & Compensation\n",
      "    0.100  People Development Coordinator at Ryan\n",
      "    0.100  HR Senior Specialist\n",
      "    0.100  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.100  Aspiring Human Resources Specialist\n",
      "    0.100  People Development Coordinator at Ryan\n",
      "    0.100  Aspiring Human Resources Specialist\n",
      "\n",
      "Query: product manager\n",
      "    0.700  RRP Brand Portfolio Executive at JTI (Japan Tobacco International)\n",
      "    0.700  Business Intelligence and Analytics at Travelers\n",
      "    0.600  Human Resources|\n",
      "Conflict Management|\n",
      "Policies & Procedures|Talent Management|Benefits & Compensation\n",
      "    0.400  SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR\n",
      "    0.400  SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR\n",
      "    0.400  SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR\n",
      "    0.400  SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR\n",
      "    0.400  Student at Indiana University Kokomo - Business Management - \n",
      "Retail Manager at Delphi Hardware and Paint\n",
      "    0.390  Experienced Retail Manager and aspiring Human Resources Professional\n",
      "    0.390  Director Of Administration at Excellence Logging\n",
      "Saved: outputs\\llm\\llm_top10__llama-3.2-3b-instruct-pairwise__all_queries.csv\n"
     ]
    }
   ],
   "source": [
    "top10_llama, path_llama = run_query_full_llama_pairwise(\n",
    "    QUERIES,\n",
    "    model_tag=\"llama-3.2-3b-instruct-pairwise\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce9b76e",
   "metadata": {},
   "source": [
    "### Step 10 - Experience with DeepSeek Chat API <img src=\"./sup_imgs/DeepSeek_logo.svg.png\" alt=\"DeepSeek Logo\" width=\"208\" style=\"vertical-align: middle;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796dab05",
   "metadata": {},
   "source": [
    "**DeepSeek V3.1 dual mode (reasoning and chat)  / DeepSeek**\n",
    "\n",
    "- For this project we used the `chat` mode.\n",
    "- **Release Date**: August, 2025.\n",
    "- **Architecture**: Autoregressive (decoder-only) Transformer, instruction-tuned for dialogue and tool-use.\n",
    "- **Parameters**: Not public\n",
    "- **Layers**: Not public        \n",
    "- **Context Window**: Defined by the active backend model and shown in the API docs/dashboard; plan for large but finite limits (tens of thousands of tokens, exact value depends on the current deployment).\n",
    "- **Tokenizer**: Proprietary tokenizer exposed through an OpenAI-compatible API interface (token counting/usage returned by the API).\n",
    "- **Objective**: Next-token prediction with instruction-tuning; optimized for helpful, harmless, and concise chat completions.\n",
    "- **Training**: Large-scale mixed corpora (web, code, multilingual) plus post-training alignment; exact datasets and recipe not publicly detailed.\n",
    "- **Efficiency**: Fully hosted—no local VRAM needed. Use streaming for long responses and keep temperature=0 for deterministic, parser-friendly outputs; control cost via prompt length/top-k prefiltering.\n",
    "- **License**: Access governed by DeepSeek API Terms of Use (hosted model; weights not distributed).\n",
    "- *Notes*: Works well with OpenAI-style Chat Completions clients. This model is the one powering the current DeepSeek Chat experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ef0bb035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measure memory usage before and after freeing it\n",
      "\n",
      "Before:\n",
      "allocated: 6136.0 MiB | reserved: 6182.0 MiB | total: 11,264 MiB\n",
      "\n",
      "After:\n",
      "allocated: 8.1 MiB | reserved: 20.0 MiB | total: 11,264 MiB\n"
     ]
    }
   ],
   "source": [
    "free_GPU_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2299ec6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load env + build client\n",
    "load_dotenv()\n",
    "DS_API_KEY  = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "DS_API_BASE = os.getenv(\"DEEPSEEK_API_BASE\")\n",
    "\n",
    "if not DS_API_KEY:\n",
    "    raise RuntimeError(\"DEEPSEEK_API_KEY is not set. Add it to your .env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2db2066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_ds = OpenAI(api_key=DS_API_KEY, base_url=DS_API_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e9a0c61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deepseek-chat', 'deepseek-reasoner']\n"
     ]
    }
   ],
   "source": [
    "models = [m.id for m in client_ds.models.list().data]\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7c573b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures as cf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a12563",
   "metadata": {},
   "source": [
    "`concurrent.futures` is a built-in Python 3 module for simple parallelism.\n",
    "It gives us an easy API (submit, map) to run many tasks concurrently and gather results as they finish."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d918e61a",
   "metadata": {},
   "source": [
    "The following section defines the three main functions we will use when working with OpenAI-compatible APIs, including DeepSeek, Grok, and ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "70db34b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # OpenAI 1.x names\n",
    "    from openai import RateLimitError, APITimeoutError, APIConnectionError, APIStatusError\n",
    "except Exception:\n",
    "    RateLimitError = APITimeoutError = APIConnectionError = APIStatusError = Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f69785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_single_ds(query: str, title: str) -> list[dict]:\n",
    "    rubric = (\n",
    "        \"You are a recruiter scoring job-title similarity to the query.\\n\"\n",
    "        \"Return EXACTLY one integer 0–100 on a single line.\\n\"\n",
    "        \"Digits only. No words. No punctuation. No explanation.\\n\"\n",
    "        \"\\n\"\n",
    "        \"Scale:\\n\"\n",
    "        \"  90–100 = exact/near-exact role match\\n\"\n",
    "        \"  70–89  = very similar, same discipline\\n\"\n",
    "        \"  40–69  = related/adjacent\\n\"\n",
    "        \"  10–39  = mostly unrelated\\n\"\n",
    "        \"  0–9    = unrelated or not a real job title\\n\"\n",
    "        \"\\n\"\n",
    "        \"Guidelines:\\n\"\n",
    "        \"  • For technical queries (data scientist, machine learning engineer, backend developer),\\n\"\n",
    "        \"    HR/People/Recruiting/Education roles are 0–10.\\n\"\n",
    "        \"  • If it looks like a slogan/sentence/company/org (not a job title), score 0–10.\\n\"\n",
    "        \"  • If title includes Student/Intern/Aspiring, subtract ~20 (min 0) unless it directly matches the role.\\n\"\n",
    "        \"  • Use the full scale. Do NOT default to 5; use 0 when clearly unrelated.\\n\"\n",
    "        \"\\n\"\n",
    "        \"Examples:\\n\"\n",
    "        \"  Query: \\\"data scientist\\\"         | Candidate: Senior Data Scientist           → 95\\n\"\n",
    "        \"  Query: \\\"data scientist\\\"         | Candidate: Undergraduate Research Assistant → 55\\n\"\n",
    "        \"  Query: \\\"data scientist\\\"         | Candidate: HR Coordinator                  → 0\\n\"\n",
    "        \"  Query: \\\"backend developer\\\"      | Candidate: Junior Backend Engineer         → 85\\n\"\n",
    "        \"  Query: \\\"product manager\\\"        | Candidate: Technical Product Manager       → 90\\n\"\n",
    "        \"  Query: \\\"product manager\\\"        | Candidate: Retail Store Manager            → 35\\n\"\n",
    "    )\n",
    "    user = f'Query: \"{query}\"\\nCandidate: {title}\\nScore:'\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": rubric},\n",
    "        {\"role\": \"user\", \"content\": user},\n",
    "    ]\n",
    "\t\n",
    "build_prompt_single_pairwise = build_prompt_single_ds\n",
    "_parse_one_int = parse_one_int\n",
    "\n",
    "# Generic pairwise scorer for ANY OpenAI-compatible client\n",
    "def score_titles_pairwise_openai_like(\n",
    "    query: str,\n",
    "    all_titles: list[str],\n",
    "    *,\n",
    "    client,\n",
    "    model: str,\n",
    "    build_prompt_fn=build_prompt_single_pairwise,\n",
    "    max_new_tokens: int = 4,      \n",
    "    temperature: float = 0.0,     # ↓ deterministic & cheaper sampling\n",
    "    top_p: float = 1.0,\n",
    "    concurrency: int = 2,         # keep low to respect TPM\n",
    "    debug_first_n: int = 0,\n",
    "    _pace_seconds: float = 0.05    # tiny stagger to avoid bursts\n",
    "):\n",
    "    def _call_with_retries(messages):\n",
    "        for attempt in range(6):\n",
    "            try:\n",
    "                return client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    messages=messages,\n",
    "                    temperature=temperature,\n",
    "                    top_p=top_p,\n",
    "                    max_tokens=max_new_tokens,\n",
    "                )\n",
    "            except (RateLimitError, APITimeoutError, APIConnectionError, APIStatusError) as e:\n",
    "                # Parse \"try again in 489ms\" if present; else exponential backoff\n",
    "                m = re.search(r\"try again in\\s+(\\d+)ms\", str(e), re.I)\n",
    "                wait = (int(m.group(1))/1000.0) if m else (0.5 * (2 ** attempt))\n",
    "                time.sleep(min(wait + random.uniform(0, 0.2), 8.0))\n",
    "\n",
    "    def _score_one(i_title):\n",
    "        i, title = i_title\n",
    "        msgs = build_prompt_fn(query, title)\n",
    "        resp = _call_with_retries(msgs)\n",
    "        raw = (resp.choices[0].message.content or \"\").strip()\n",
    "        score = _parse_one_int(raw)\n",
    "        if i < debug_first_n:\n",
    "            print(f\"\\n[debug] idx={i}\\nPROMPT:\\n{msgs}\\nRAW:\\n{raw}\\nPARSED={score}\\n\")\n",
    "        # tiny pacing to smooth bursts across threads\n",
    "        if _pace_seconds:\n",
    "            time.sleep(_pace_seconds)\n",
    "        return {\"idx\": i, \"score\": score, \"job_titles\": title}\n",
    "\n",
    "    rows = []\n",
    "    items = list(enumerate(all_titles))\n",
    "    with cf.ThreadPoolExecutor(max_workers=min(concurrency, len(items))) as ex:\n",
    "        for row in ex.map(_score_one, items):\n",
    "            rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows).sort_values(\"score\", ascending=False).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Generic runner that writes the same CSV artifact\n",
    "def run_query_full_pairwise_openai_like(\n",
    "    queries: list[str],\n",
    "    *,\n",
    "    client,\n",
    "    model: str,\n",
    "    model_tag: str,\n",
    "    top_k: int = 10,\n",
    "    concurrency: int = 6,\n",
    "    debug_first_n: int = 3\n",
    "):\n",
    "    out_dir = os.path.join(OUT_DIR, \"llm\"); os.makedirs(out_dir, exist_ok=True)\n",
    "    top10_blocks = []\n",
    "    for q in queries:\n",
    "        df_rank = score_titles_pairwise_openai_like(\n",
    "            q, titles,\n",
    "            client=client,\n",
    "            model=model,\n",
    "            build_prompt_fn=build_prompt_single_pairwise,\n",
    "            concurrency=concurrency,\n",
    "            debug_first_n=debug_first_n\n",
    "        )\n",
    "        print_ranking(q, df_rank, top_k=top_k)  # <- the existing pretty-printer\n",
    "        df_q = df_rank.head(top_k)[[\"score\", \"job_titles\"]].copy()\n",
    "        df_q.insert(0, \"query\", q)\n",
    "        top10_blocks.append(df_q)\n",
    "\n",
    "    top10 = pd.concat(top10_blocks, ignore_index=True)\n",
    "    path = os.path.join(out_dir, f\"llm_top10__{model_tag}__pairwise__all_queries.csv\")\n",
    "    top10.to_csv(path, index=False)\n",
    "    print(\"Saved:\", path)\n",
    "    return top10, path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d8bf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: data scientist\n",
      "    0.700  Business Intelligence and Analytics at Travelers\n",
      "    0.550  Undergraduate Research Assistant at Styczynski Lab\n",
      "    0.300  Junior MES Engineer| Information Systems\n",
      "    0.100  Student\n",
      "    0.000  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.000  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.000  Aspiring Human Resources Professional\n",
      "    0.000  People Development Coordinator at Ryan\n",
      "    0.000  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.000  Seeking Human Resources HRIS and Generalist Positions\n",
      "\n",
      "Query: machine learning engineer\n",
      "    0.550  Undergraduate Research Assistant at Styczynski Lab\n",
      "    0.400  Junior MES Engineer| Information Systems\n",
      "    0.400  Business Intelligence and Analytics at Travelers\n",
      "    0.100  Student\n",
      "    0.000  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.000  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.000  Aspiring Human Resources Professional\n",
      "    0.000  People Development Coordinator at Ryan\n",
      "    0.000  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.000  Seeking Human Resources HRIS and Generalist Positions\n",
      "\n",
      "Query: backend developer\n",
      "    0.700  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.550  Undergraduate Research Assistant at Styczynski Lab\n",
      "    0.400  Junior MES Engineer| Information Systems\n",
      "    0.100  Student\n",
      "    0.100  Business Intelligence and Analytics at Travelers\n",
      "    0.000  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.000  Aspiring Human Resources Professional\n",
      "    0.000  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.000  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.000  Seeking Human Resources HRIS and Generalist Positions\n",
      "\n",
      "Query: product manager\n",
      "    0.400  RRP Brand Portfolio Executive at JTI (Japan Tobacco International)\n",
      "    0.400  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.400  Business Intelligence and Analytics at Travelers\n",
      "    0.400  Undergraduate Research Assistant at Styczynski Lab\n",
      "    0.350  Student at Indiana University Kokomo - Business Management - \n",
      "Retail Manager at Delphi Hardware and Paint\n",
      "    0.200  Junior MES Engineer| Information Systems\n",
      "    0.100  Aspiring Human Resources Specialist\n",
      "    0.100  Advisory Board Member at Celal Bayar University\n",
      "    0.100  Aspiring Human Resources Specialist\n",
      "    0.100  Advisory Board Member at Celal Bayar University\n",
      "Saved: outputs\\llm\\llm_top10__deepseek-chat__pairwise__pairwise__all_queries.csv\n"
     ]
    }
   ],
   "source": [
    "top10_grok_pairwise, path_grok_pairwise = run_query_full_pairwise_openai_like(\n",
    "    QUERIES,\n",
    "    client=client_ds,               \n",
    "    model=\"deepseek-chat\",              \n",
    "    model_tag=\"deepseek-chat__pairwise\",\n",
    "    concurrency=6,\n",
    "    debug_first_n=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0763c628",
   "metadata": {},
   "source": [
    "### Step 11 - Experience with GROK from xAI <img src=\"./sup_imgs/Grok-feb-2025-logo.svg.png\" width=\"208\" style=\"vertical-align: middle;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fc815b",
   "metadata": {},
   "source": [
    "**DeepSeek V3.1 dual mode (reasoning and chat)  / DeepSeek**\n",
    "\n",
    "- For this project we used the `chat` mode.\n",
    "- **Release Date**: August, 2025.\n",
    "- **Architecture**: Autoregressive (decoder-only) Transformer, instruction-tuned for dialogue and tool-use.\n",
    "- **Parameters**: Not public\n",
    "- **Layers**: Not public        \n",
    "- **Context Window**: Defined by the active backend model and shown in the API docs/dashboard; plan for large but finite limits (tens of thousands of tokens, exact value depends on the current deployment).\n",
    "- **Tokenizer**: Proprietary tokenizer exposed through an OpenAI-compatible API interface (token counting/usage returned by the API).\n",
    "- **Objective**: Next-token prediction with instruction-tuning; optimized for helpful, harmless, and concise chat completions.\n",
    "- **Training**: Large-scale mixed corpora (web, code, multilingual) plus post-training alignment; exact datasets and recipe not publicly detailed.\n",
    "- **Efficiency**: Fully hosted—no local VRAM needed. Use streaming for long responses and keep temperature=0 for deterministic, parser-friendly outputs; control cost via prompt length/top-k prefiltering.\n",
    "- **License**: Access governed by DeepSeek API Terms of Use (hosted model; weights not distributed).\n",
    "- *Notes*: Works well with OpenAI-style Chat Completions clients. This model is the one powering the current DeepSeek Chat experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "46120d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load env + build client\n",
    "load_dotenv()\n",
    "XAI_API_KEY  = os.getenv(\"XAI_API_KEY\")\n",
    "XAI_API_BASE = os.getenv(\"XAI_API_BASE\")\n",
    "\n",
    "if not DS_API_KEY:\n",
    "    raise RuntimeError(\"XAI_API_KEY is not set. Add it to your .env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0324adba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "client_grok = OpenAI(\n",
    "    api_key=XAI_API_KEY,\n",
    "    base_url=XAI_API_BASE\n",
    ")\n",
    "\n",
    "resp = client_grok.chat.completions.create(\n",
    "    model=\"grok-4-fast-reasoning\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Return the number 4.\"}],\n",
    "    max_tokens=8,\n",
    "    temperature=0,\n",
    ")\n",
    "print(resp.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4d8f4b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROK_MODEL_ID = os.getenv(\"GROK_MODEL_ID\", \"grok-4-fast-reasoning\")  # or \"grok-4o\", \"grok-4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f0640806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: data scientist\n",
      "    0.750  Business Intelligence and Analytics at Travelers\n",
      "    0.600  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.550  Undergraduate Research Assistant at Styczynski Lab\n",
      "    0.450  Junior MES Engineer| Information Systems\n",
      "    0.050  Student at Chapman University\n",
      "    0.000  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.000  Aspiring Human Resources Professional\n",
      "    0.000  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.000  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.000  Seeking Human Resources HRIS and Generalist Positions\n",
      "\n",
      "Query: machine learning engineer\n",
      "    0.550  Business Intelligence and Analytics at Travelers\n",
      "    0.550  Undergraduate Research Assistant at Styczynski Lab\n",
      "    0.450  Junior MES Engineer| Information Systems\n",
      "    0.450  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.050  Advisory Board Member at Celal Bayar University\n",
      "    0.000  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.000  Aspiring Human Resources Professional\n",
      "    0.000  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.000  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.000  Seeking Human Resources HRIS and Generalist Positions\n",
      "\n",
      "Query: backend developer\n",
      "    0.700  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.550  Junior MES Engineer| Information Systems\n",
      "    0.450  Business Intelligence and Analytics at Travelers\n",
      "    0.200  Undergraduate Research Assistant at Styczynski Lab\n",
      "    0.000  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.000  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.000  Aspiring Human Resources Professional\n",
      "    0.000  People Development Coordinator at Ryan\n",
      "    0.000  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.000  Seeking Human Resources HRIS and Generalist Positions\n",
      "\n",
      "Query: product manager\n",
      "    0.650  RRP Brand Portfolio Executive at JTI (Japan Tobacco International)\n",
      "    0.500  Business Intelligence and Analytics at Travelers\n",
      "    0.400  Director Of Administration at Excellence Logging\n",
      "    0.250  Experienced Retail Manager and aspiring Human Resources Professional\n",
      "    0.250  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.200  Junior MES Engineer| Information Systems\n",
      "    0.200  Undergraduate Research Assistant at Styczynski Lab\n",
      "    0.150  Admissions Representative at Community medical center long beach\n",
      "    0.150  Student at Indiana University Kokomo - Business Management - \n",
      "Retail Manager at Delphi Hardware and Paint\n",
      "    0.100  Native English Teacher at EPIK (English Program in Korea)\n",
      "Saved: outputs\\llm\\llm_top10__grok-4-fast__pairwise__all_queries.csv\n"
     ]
    }
   ],
   "source": [
    "top10_grok_pairwise, path_grok_pairwise = run_query_full_pairwise_openai_like(\n",
    "    QUERIES,\n",
    "    client=client_grok,               \n",
    "    model=GROK_MODEL_ID,              \n",
    "    model_tag=\"grok-4-fast\",\n",
    "    concurrency=6,\n",
    "    debug_first_n=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf529ec3",
   "metadata": {},
   "source": [
    "### Step 12 - Experience with ChatGPT / OpenAI <img src=\"./sup_imgs/ChatGPT-Logo.svg.webp\" width=\"75\" style=\"vertical-align: middle;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a532d4fb",
   "metadata": {},
   "source": [
    "**ChatGPT-4o (Omni) / OpenAI**\n",
    "\n",
    "- **Release Date**: May, 2024.\n",
    "- **Architecture**: Multimodal autoregressive (decoder-only) Transformer, instruction-tuned for text, vision and audio; optimized for dialogue and tool use.\n",
    "- **Parameters**: Not disclosed\n",
    "- **Layers**: Not disclosed\n",
    "- **Context Window**: Up to 128k tokens (depends on deployement tier; see API docs/dashboard)\n",
    "- **Tokenizer**: Proprietary OpenAI tokenizer (token usage/counts returned by the API)\n",
    "- **Objective**: Next-token prediction with instruction tuning; optimized for safe, useful, and concise multimodal outputs.\n",
    "- **Training**: Large-scale, multimodal corpora (text, code, images, audio) combined with alignment/post-training; exact datasets and recipe not publicly detailed.\n",
    "- **Efficiency**: Fully hosted. No local VRAM required. Supports real-time streaming across medalities. Deterministic behavior can be encouraged with\n",
    "`temperature=0`. Costs can be managed via context length and batching.\n",
    "- **License**: Access governed by OpenAI API Terms of Use (hosted model; weights not publicly available)\n",
    "- *Notes*: Serves as the default GPT-4 tier in the ChatGPT product. Designed for seamless use with OpenAI-style Chat Completions and multimodal endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8a24a3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load env + build client\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY  = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_MODEL_ID = \"gpt-4o\"  # set \"gpt-5\" here if you have access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "879d95e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "client_oa = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"), max_retries=3)  # no base_url needed for OpenAI\n",
    "\n",
    "resp = client_oa.chat.completions.create(\n",
    "    model=OPENAI_MODEL_ID,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Reply with digits only.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Return the number 7.\"}\n",
    "    ],\n",
    "    temperature=0.0,\n",
    "    max_tokens=5,\n",
    ")\n",
    "print(resp.choices[0].message.content)  # -> 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "06c66ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, random, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "95b2229b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[debug] idx=0\n",
      "PROMPT:\n",
      "[{'role': 'system', 'content': 'You are a recruiter scoring job-title similarity to the query.\\nReturn EXACTLY one integer 0–100 on a single line.\\nDigits only. No words. No punctuation. No explanation.\\n\\nScale:\\n  90–100 = exact/near-exact role match\\n  70–89  = very similar, same discipline\\n  40–69  = related/adjacent\\n  10–39  = mostly unrelated\\n  0–9    = unrelated or not a real job title\\n\\nGuidelines:\\n  • For technical queries (data scientist, machine learning engineer, backend developer),\\n    HR/People/Recruiting/Education roles are 0–10.\\n  • If it looks like a slogan/sentence/company/org (not a job title), score 0–10.\\n  • If title includes Student/Intern/Aspiring, subtract ~20 (min 0) unless it directly matches the role.\\n  • Use the full scale. Do NOT default to 5; use 0 when clearly unrelated.\\n\\nExamples:\\n  Query: \"data scientist\"         | Candidate: Senior Data Scientist           → 95\\n  Query: \"data scientist\"         | Candidate: Undergraduate Research Assistant → 55\\n  Query: \"data scientist\"         | Candidate: HR Coordinator                  → 0\\n  Query: \"backend developer\"      | Candidate: Junior Backend Engineer         → 85\\n  Query: \"product manager\"        | Candidate: Technical Product Manager       → 90\\n  Query: \"product manager\"        | Candidate: Retail Store Manager            → 35\\n'}, {'role': 'user', 'content': 'Query: \"data scientist\"\\nCandidate: 2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\\nScore:'}]\n",
      "RAW:\n",
      "10\n",
      "PARSED=10\n",
      "\n",
      "\n",
      "Query: data scientist\n",
      "    0.600  Business Intelligence and Analytics at Travelers\n",
      "    0.550  Undergraduate Research Assistant at Styczynski Lab\n",
      "    0.400  Junior MES Engineer| Information Systems\n",
      "    0.400  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.100  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.100  Advisory Board Member at Celal Bayar University\n",
      "    0.100  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.100  Student at Chapman University\n",
      "    0.100  Student at Chapman University\n",
      "    0.100  Student at Chapman University\n",
      "\n",
      "[debug] idx=0\n",
      "PROMPT:\n",
      "[{'role': 'system', 'content': 'You are a recruiter scoring job-title similarity to the query.\\nReturn EXACTLY one integer 0–100 on a single line.\\nDigits only. No words. No punctuation. No explanation.\\n\\nScale:\\n  90–100 = exact/near-exact role match\\n  70–89  = very similar, same discipline\\n  40–69  = related/adjacent\\n  10–39  = mostly unrelated\\n  0–9    = unrelated or not a real job title\\n\\nGuidelines:\\n  • For technical queries (data scientist, machine learning engineer, backend developer),\\n    HR/People/Recruiting/Education roles are 0–10.\\n  • If it looks like a slogan/sentence/company/org (not a job title), score 0–10.\\n  • If title includes Student/Intern/Aspiring, subtract ~20 (min 0) unless it directly matches the role.\\n  • Use the full scale. Do NOT default to 5; use 0 when clearly unrelated.\\n\\nExamples:\\n  Query: \"data scientist\"         | Candidate: Senior Data Scientist           → 95\\n  Query: \"data scientist\"         | Candidate: Undergraduate Research Assistant → 55\\n  Query: \"data scientist\"         | Candidate: HR Coordinator                  → 0\\n  Query: \"backend developer\"      | Candidate: Junior Backend Engineer         → 85\\n  Query: \"product manager\"        | Candidate: Technical Product Manager       → 90\\n  Query: \"product manager\"        | Candidate: Retail Store Manager            → 35\\n'}, {'role': 'user', 'content': 'Query: \"machine learning engineer\"\\nCandidate: 2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\\nScore:'}]\n",
      "RAW:\n",
      "0\n",
      "PARSED=0\n",
      "\n",
      "\n",
      "Query: machine learning engineer\n",
      "    0.550  Undergraduate Research Assistant at Styczynski Lab\n",
      "    0.400  Business Intelligence and Analytics at Travelers\n",
      "    0.400  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.400  Junior MES Engineer| Information Systems\n",
      "    0.100  Student at Chapman University\n",
      "    0.100  Student at Chapman University\n",
      "    0.100  Advisory Board Member at Celal Bayar University\n",
      "    0.100  Student at Chapman University\n",
      "    0.100  Student at Chapman University\n",
      "    0.100  Student at Westfield State University\n",
      "\n",
      "[debug] idx=0\n",
      "PROMPT:\n",
      "[{'role': 'system', 'content': 'You are a recruiter scoring job-title similarity to the query.\\nReturn EXACTLY one integer 0–100 on a single line.\\nDigits only. No words. No punctuation. No explanation.\\n\\nScale:\\n  90–100 = exact/near-exact role match\\n  70–89  = very similar, same discipline\\n  40–69  = related/adjacent\\n  10–39  = mostly unrelated\\n  0–9    = unrelated or not a real job title\\n\\nGuidelines:\\n  • For technical queries (data scientist, machine learning engineer, backend developer),\\n    HR/People/Recruiting/Education roles are 0–10.\\n  • If it looks like a slogan/sentence/company/org (not a job title), score 0–10.\\n  • If title includes Student/Intern/Aspiring, subtract ~20 (min 0) unless it directly matches the role.\\n  • Use the full scale. Do NOT default to 5; use 0 when clearly unrelated.\\n\\nExamples:\\n  Query: \"data scientist\"         | Candidate: Senior Data Scientist           → 95\\n  Query: \"data scientist\"         | Candidate: Undergraduate Research Assistant → 55\\n  Query: \"data scientist\"         | Candidate: HR Coordinator                  → 0\\n  Query: \"backend developer\"      | Candidate: Junior Backend Engineer         → 85\\n  Query: \"product manager\"        | Candidate: Technical Product Manager       → 90\\n  Query: \"product manager\"        | Candidate: Retail Store Manager            → 35\\n'}, {'role': 'user', 'content': 'Query: \"backend developer\"\\nCandidate: 2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\\nScore:'}]\n",
      "RAW:\n",
      "0\n",
      "PARSED=0\n",
      "\n",
      "\n",
      "Query: backend developer\n",
      "    0.400  Junior MES Engineer| Information Systems\n",
      "    0.400  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.400  Business Intelligence and Analytics at Travelers\n",
      "    0.400  Undergraduate Research Assistant at Styczynski Lab\n",
      "    0.100  Student at Chapman University\n",
      "    0.100  Experienced Retail Manager and aspiring Human Resources Professional\n",
      "    0.100  Student at Chapman University\n",
      "    0.100  Student at Chapman University\n",
      "    0.100  Student at Indiana University Kokomo - Business Management - \n",
      "Retail Manager at Delphi Hardware and Paint\n",
      "    0.100  Student at Westfield State University\n",
      "\n",
      "[debug] idx=0\n",
      "PROMPT:\n",
      "[{'role': 'system', 'content': 'You are a recruiter scoring job-title similarity to the query.\\nReturn EXACTLY one integer 0–100 on a single line.\\nDigits only. No words. No punctuation. No explanation.\\n\\nScale:\\n  90–100 = exact/near-exact role match\\n  70–89  = very similar, same discipline\\n  40–69  = related/adjacent\\n  10–39  = mostly unrelated\\n  0–9    = unrelated or not a real job title\\n\\nGuidelines:\\n  • For technical queries (data scientist, machine learning engineer, backend developer),\\n    HR/People/Recruiting/Education roles are 0–10.\\n  • If it looks like a slogan/sentence/company/org (not a job title), score 0–10.\\n  • If title includes Student/Intern/Aspiring, subtract ~20 (min 0) unless it directly matches the role.\\n  • Use the full scale. Do NOT default to 5; use 0 when clearly unrelated.\\n\\nExamples:\\n  Query: \"data scientist\"         | Candidate: Senior Data Scientist           → 95\\n  Query: \"data scientist\"         | Candidate: Undergraduate Research Assistant → 55\\n  Query: \"data scientist\"         | Candidate: HR Coordinator                  → 0\\n  Query: \"backend developer\"      | Candidate: Junior Backend Engineer         → 85\\n  Query: \"product manager\"        | Candidate: Technical Product Manager       → 90\\n  Query: \"product manager\"        | Candidate: Retail Store Manager            → 35\\n'}, {'role': 'user', 'content': 'Query: \"product manager\"\\nCandidate: 2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\\nScore:'}]\n",
      "RAW:\n",
      "10\n",
      "PARSED=10\n",
      "\n",
      "\n",
      "Query: product manager\n",
      "    0.600  Business Intelligence and Analytics at Travelers\n",
      "    0.400  Undergraduate Research Assistant at Styczynski Lab\n",
      "    0.400  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.400  Junior MES Engineer| Information Systems\n",
      "    0.350  Student at Indiana University Kokomo - Business Management - \n",
      "Retail Manager at Delphi Hardware and Paint\n",
      "    0.300  RRP Brand Portfolio Executive at JTI (Japan Tobacco International)\n",
      "    0.200  Director Of Administration at Excellence Logging\n",
      "    0.200  Experienced Retail Manager and aspiring Human Resources Professional\n",
      "    0.100  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.100  Advisory Board Member at Celal Bayar University\n",
      "Saved: outputs\\llm\\llm_top10__gpt-4o__pairwise__pairwise__all_queries.csv\n"
     ]
    }
   ],
   "source": [
    "top10_grok_pairwise, path_grok_pairwise = run_query_full_pairwise_openai_like(\n",
    "    QUERIES,\n",
    "    client=client_oa,\n",
    "    model=OPENAI_MODEL_ID,\n",
    "    model_tag=\"gpt-4o__pairwise\",\n",
    "    concurrency=2,\n",
    "    debug_first_n=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8353b291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9739661a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "247d977e",
   "metadata": {},
   "source": [
    "As a reference, this is the **output using ChatGPT5**:\n",
    "\n",
    "Top matches (title • score/100)\n",
    "- Business Intelligence and Analytics at Travelers • 0.78\n",
    "- Information Systems Specialist and Programmer with a love for data and organization. • 0.62\n",
    "- Junior MES Engineer | Information Systems • 0.56\n",
    "- Undergraduate Research Assistant at Styczynski Lab • 0.54\n",
    "- Liberal Arts Major. Aspiring Human Resources Analyst. • 0.42\n",
    "- Seeking Human Resources HRIS and Generalist Positions • 0.28\n",
    "- Human Resources Generalist at Loparex • 0.25\n",
    "- Human Resources Specialist at Luxottica • 0.23\n",
    "- HR Senior Specialist • 0.22\n",
    "- Human Resources Professional • 0.20\n",
    "\n",
    "\n",
    "I used the following **prompt** (same used with Phi-3 mini): \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4f1d9b",
   "metadata": {},
   "source": [
    "You are a recruiter scoring job-title similarity to the query Rate each candidate with an integer 0–100 using the FULL scale: • 90–100 = exact/near-exact role match • 70–89 = same discipline or very similar role • 40–69 = related/adjacent • 10–39 = mostly unrelated • 0–9 = completely unrelated Use diverse scores; do NOT give 0 or 100 to many candidates. Ignore employer names, locations, programs. Output EXACTLY one integer per line, in the SAME ORDER as the candidates. No words, no punctuation. Example for return for 3 candidates: 82 41 7 --- Query: \"data scientist\" Candidates: \"2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional Native English Teacher at EPIK (English Program in Korea) Aspiring Human Resources Professional People Development Coordinator at Ryan Advisory Board Member at Celal Bayar University Aspiring Human Resources Specialist Student at Humber College and Aspiring Human Resources Generalist HR Senior Specialist Student at Humber College and Aspiring Human Resources Generalist Seeking Human Resources HRIS and Generalist Positions Student at Chapman University SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR Human Resources Coordinator at InterContinental Buckhead Atlanta 2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional 2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional Native English Teacher at EPIK (English Program in Korea) Aspiring Human Resources Professional People Development Coordinator at Ryan 2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional Native English Teacher at EPIK (English Program in Korea) Aspiring Human Resources Professional People Development Coordinator at Ryan Advisory Board Member at Celal Bayar University Aspiring Human Resources Specialist Student at Humber College and Aspiring Human Resources Generalist HR Senior Specialist Aspiring Human Resources Management student seeking an internship Seeking Human Resources Opportunities Aspiring Human Resources Management student seeking an internship Seeking Human Resources Opportunities 2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional Native English Teacher at EPIK (English Program in Korea) Aspiring Human Resources Professional People Development Coordinator at Ryan Advisory Board Member at Celal Bayar University Aspiring Human Resources Specialist Student at Humber College and Aspiring Human Resources Generalist HR Senior Specialist Student at Humber College and Aspiring Human Resources Generalist Seeking Human Resources HRIS and Generalist Positions Student at Chapman University SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR Human Resources Coordinator at InterContinental Buckhead Atlanta 2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional Native English Teacher at EPIK (English Program in Korea) Aspiring Human Resources Professional People Development Coordinator at Ryan Advisory Board Member at Celal Bayar University Aspiring Human Resources Specialist Student at Humber College and Aspiring Human Resources Generalist HR Senior Specialist Student at Humber College and Aspiring Human Resources Generalist Seeking Human Resources HRIS and Generalist Positions Student at Chapman University SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR Human Resources Coordinator at InterContinental Buckhead Atlanta 2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional Aspiring Human Resources Professional People Development Coordinator at Ryan Aspiring Human Resources Specialist HR Senior Specialist Seeking Human Resources HRIS and Generalist Positions Student at Chapman University SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR Human Resources Coordinator at InterContinental Buckhead Atlanta Experienced Retail Manager and aspiring Human Resources Professional Human Resources, Staffing and Recruiting Professional Human Resources Specialist at Luxottica Director of Human Resources North America, Groupe Beneteau Retired Army National Guard Recruiter, office manager, seeking a position in Human Resources. Human Resources Generalist at ScottMadden, Inc. Business Management Major and Aspiring Human Resources Manager Aspiring Human Resources Manager, seeking internship in Human Resources. Human Resources Professional Nortia Staffing is seeking Human Resources, Payroll & Administrative Professionals!! (408) 709-2621 Aspiring Human Resources Professional | Passionate about helping to create an inclusive and engaging work environment \"Human Resources| Conflict Management| Policies & Procedures|Talent Management|Benefits & Compensation\" Human Resources Generalist at Schwan's Liberal Arts Major. Aspiring Human Resources Analyst. Junior MES Engineer| Information Systems Senior Human Resources Business Partner at Heil Environmental Aspiring Human Resources Professional | An energetic and Team-Focused Leader HR Manager at Endemol Shine North America Human Resources professional for the world leader in GIS software RRP Brand Portfolio Executive at JTI (Japan Tobacco International) Information Systems Specialist and Programmer with a love for data and organization. Bachelor of Science in Biology from Victoria University of Wellington Human Resources Management Major Director Human Resources at EY Undergraduate Research Assistant at Styczynski Lab Lead Official at Western Illinois University Seeking employment opportunities within Customer Service or Patient Care Admissions Representative at Community medical center long beach Seeking Human Resources Opportunities. Open to travel and relocation. Student at Westfield State University \"Student at Indiana University Kokomo - Business Management - Retail Manager at Delphi Hardware and Paint\" Aspiring Human Resources Professional Student Seeking Human Resources Position Aspiring Human Resources Manager | Graduating May 2020 | Seeking an Entry-Level Human Resources Position in St. Louis Human Resources Generalist at Loparex Business Intelligence and Analytics at Travelers Always set them up for Success Director Of Administration at Excellence Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310748e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39d18be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43c4740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30632c58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4402f9ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a482346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9351bac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5930e4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e98e30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##&## go to the bottom !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783b025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_single_ds(query: str, title: str) -> list[dict]:\n",
    "    rubric = (\n",
    "        \"You are a recruiter scoring job-title similarity to the query.\\n\"\n",
    "        \"Return EXACTLY one integer 0–100 on a single line.\\n\"\n",
    "        \"Digits only. No words. No punctuation. No explanation.\\n\"\n",
    "        \"\\n\"\n",
    "        \"Scale:\\n\"\n",
    "        \"  90–100 = exact/near-exact role match\\n\"\n",
    "        \"  70–89  = very similar, same discipline\\n\"\n",
    "        \"  40–69  = related/adjacent\\n\"\n",
    "        \"  10–39  = mostly unrelated\\n\"\n",
    "        \"  0–9    = unrelated or not a real job title\\n\"\n",
    "        \"\\n\"\n",
    "        \"Guidelines:\\n\"\n",
    "        \"  • For technical queries (data scientist, machine learning engineer, backend developer),\\n\"\n",
    "        \"    HR/People/Recruiting/Education roles are 0–10.\\n\"\n",
    "        \"  • If it looks like a slogan/sentence/company/org (not a job title), score 0–10.\\n\"\n",
    "        \"  • If title includes Student/Intern/Aspiring, subtract ~20 (min 0) unless it directly matches the role.\\n\"\n",
    "        \"  • Use the full scale. Do NOT default to 5; use 0 when clearly unrelated.\\n\"\n",
    "        \"\\n\"\n",
    "        \"Examples:\\n\"\n",
    "        \"  Query: \\\"data scientist\\\"         | Candidate: Senior Data Scientist           → 95\\n\"\n",
    "        \"  Query: \\\"data scientist\\\"         | Candidate: Undergraduate Research Assistant → 55\\n\"\n",
    "        \"  Query: \\\"data scientist\\\"         | Candidate: HR Coordinator                  → 0\\n\"\n",
    "        \"  Query: \\\"backend developer\\\"      | Candidate: Junior Backend Engineer         → 85\\n\"\n",
    "        \"  Query: \\\"product manager\\\"        | Candidate: Technical Product Manager       → 90\\n\"\n",
    "        \"  Query: \\\"product manager\\\"        | Candidate: Retail Store Manager            → 35\\n\"\n",
    "    )\n",
    "    user = f'Query: \"{query}\"\\nCandidate: {title}\\nScore:'\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": rubric},\n",
    "        {\"role\": \"user\", \"content\": user},\n",
    "    ]\n",
    "\n",
    "\n",
    "def score_titles_deepseek_pairwise(query: str,\n",
    "                                   all_titles: list[str],\n",
    "                                   model: str = \"deepseek-chat\",\n",
    "                                   max_new_tokens: int = 6,\n",
    "                                   temperature: float = 0.3,   # bumped from 0.2\n",
    "                                   top_p: float = 0.9,\n",
    "                                   concurrency: int = 6,\n",
    "                                   debug: bool = False):\n",
    "    import concurrent.futures as cf\n",
    "    import pandas as pd, re\n",
    "\n",
    "    def parse_one_int(text: str) -> int:\n",
    "        m = re.findall(r\"-?\\d+\", text)\n",
    "        if not m: return 0\n",
    "        return max(0, min(100, int(m[-1])))\n",
    "\n",
    "    def _score_one(i_title):\n",
    "        i, title = i_title\n",
    "        msgs = build_prompt_single_ds(query, title)\n",
    "        resp = client_ds.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=msgs,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            max_tokens=max_new_tokens,\n",
    "        )\n",
    "        raw = resp.choices[0].message.content or \"\"\n",
    "        score = parse_one_int(raw)\n",
    "        if debug and i < 3:\n",
    "            print(f\"\\n[debug] idx={i}\\nPROMPT:\\n{msgs}\\nRAW:\\n{raw}\\nPARSED={score}\\n\")\n",
    "        return {\"idx\": i, \"score\": score, \"job_titles\": title}\n",
    "\n",
    "    rows = []\n",
    "    with cf.ThreadPoolExecutor(max_workers=min(concurrency, len(all_titles))) as ex:\n",
    "        for row in ex.map(_score_one, list(enumerate(all_titles))):\n",
    "            rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows).sort_values(\"score\", ascending=False).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# --- Runner identical to your pattern ---------------------------------------\n",
    "def run_query_full_deepseek_pairwise(queries: list[str],\n",
    "                                     model_tag: str = \"deepseek-chat__pairwise\",\n",
    "                                     concurrency: int = 6,\n",
    "                                     debug: bool = False):\n",
    "    import os, pandas as pd\n",
    "    out_dir = os.path.join(OUT_DIR, \"llm\"); os.makedirs(out_dir, exist_ok=True)\n",
    "    top10_blocks = []\n",
    "    for q in queries:\n",
    "        df_rank = score_titles_deepseek_pairwise(q, titles, concurrency=concurrency, debug=debug)\n",
    "        print_ranking(q, df_rank, top_k=10)  # reuse your pretty-printer\n",
    "        df_q = df_rank.head(10)[[\"score\", \"job_titles\"]].copy()\n",
    "        df_q.insert(0, \"query\", q)\n",
    "        top10_blocks.append(df_q)\n",
    "    top10 = pd.concat(top10_blocks, ignore_index=True)\n",
    "    path = os.path.join(out_dir, f\"llm_top10__{model_tag}__all_queries.csv\")\n",
    "    top10.to_csv(path, index=False); print(\"Saved:\", path)\n",
    "    return top10, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a82800",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_ds_pair, path_ds_pair = run_query_full_deepseek_pairwise(\n",
    "    QUERIES,\n",
    "    model_tag=\"deepseek-chat__pairwise\",\n",
    "    concurrency=6,   # tune for your rate limit\n",
    "    debug=True       \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc8938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_view = pd.read_csv(\"outputs/llm/llm_top10__deepseek-chat__pairwise__all_queries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3387a47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_view.head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4a0c58",
   "metadata": {},
   "source": [
    "### Step 11 - Experience with GROK / xAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b2ff58",
   "metadata": {},
   "source": [
    "**DeepSeek V3.1 dual mode (reasoning and chat)  / DeepSeek**\n",
    "\n",
    "- For this project we used the `chat` mode.\n",
    "- **Release Date**: August, 2025.\n",
    "- **Architecture**: Autoregressive (decoder-only) Transformer, instruction-tuned for dialogue and tool-use.\n",
    "- **Parameters**: Not public\n",
    "- **Layers**: Not public        \n",
    "- **Context Window**: Defined by the active backend model and shown in the API docs/dashboard; plan for large but finite limits (tens of thousands of tokens, exact value depends on the current deployment).\n",
    "- **Tokenizer**: Proprietary tokenizer exposed through an OpenAI-compatible API interface (token counting/usage returned by the API).\n",
    "- **Objective**: Next-token prediction with instruction-tuning; optimized for helpful, harmless, and concise chat completions.\n",
    "- **Training**: Large-scale mixed corpora (web, code, multilingual) plus post-training alignment; exact datasets and recipe not publicly detailed.\n",
    "- **Efficiency**: Fully hosted—no local VRAM needed. Use streaming for long responses and keep temperature=0 for deterministic, parser-friendly outputs; control cost via prompt length/top-k prefiltering.\n",
    "- **License**: Access governed by DeepSeek API Terms of Use (hosted model; weights not distributed).\n",
    "- *Notes*: Works well with OpenAI-style Chat Completions clients. This model is the one powering the current DeepSeek Chat experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0060ac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load env + build client\n",
    "load_dotenv()\n",
    "XAI_API_KEY  = os.getenv(\"XAI_API_KEY\")\n",
    "XAI_API_BASE = os.getenv(\"XAI_API_BASE\")\n",
    "\n",
    "if not DS_API_KEY:\n",
    "    raise RuntimeError(\"XAI_API_KEY is not set. Add it to your .env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "48463f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "client_grok = OpenAI(\n",
    "    api_key=XAI_API_KEY,\n",
    "    base_url=XAI_API_BASE\n",
    ")\n",
    "\n",
    "resp = client_grok.chat.completions.create(\n",
    "    model=\"grok-4-fast-reasoning\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Return the number 4.\"}],\n",
    "    max_tokens=8,\n",
    "    temperature=0,\n",
    ")\n",
    "print(resp.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "33a6cc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROK_MODEL_ID = os.getenv(\"GROK_MODEL_ID\", \"grok-4-fast-reasoning\")  # or \"grok-4o\", \"grok-4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b43f9cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures as cf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634aea41",
   "metadata": {},
   "source": [
    "`concurrent.futures` is a built-in Python 3 module for simple parallelism.\n",
    "It gives us an easy API (submit, map) to run many tasks concurrently and gather results as they finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6b4bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 0) Reuse the existing DeepSeek prompt + parser (no changes) ##\n",
    "# Keep using the same prompt:\n",
    "#   build_prompt_single_pairwise(query, title)      # <- current function\n",
    "# And the same one-int parser:\n",
    "#   _parse_one_int(text)                            # <- current function\n",
    "\n",
    "# Alias the function prompt builder function names:\n",
    "build_prompt_single_pairwise = build_prompt_single_ds\n",
    "_parse_one_int = parse_one_int\n",
    "\n",
    "# Generic pairwise scorer for ANY OpenAI-compatible client\n",
    "def score_titles_pairwise_openai_like(\n",
    "    query: str,\n",
    "    all_titles: list[str],\n",
    "    *,\n",
    "    client,                     # <- pass the specific client: client_ds or client_grok or others\n",
    "    model: str,                 # <- \"deepseek-chat\" or GROK_MODEL_ID or others\n",
    "    build_prompt_fn=build_prompt_single_pairwise,\n",
    "    max_new_tokens: int = 6,\n",
    "    temperature: float = 0.3,\n",
    "    top_p: float = 0.9,\n",
    "    concurrency: int = 6,\n",
    "    debug_first_n: int = 3\n",
    "):\n",
    "    def _score_one(i_title):\n",
    "        i, title = i_title\n",
    "        msgs = build_prompt_fn(query, title)\n",
    "        resp = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=msgs,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            max_tokens=max_new_tokens,\n",
    "        )\n",
    "        raw = (resp.choices[0].message.content or \"\").strip()\n",
    "        score = _parse_one_int(raw)\n",
    "        if i < debug_first_n:\n",
    "            print(f\"\\n[debug] idx={i}\\nPROMPT:\\n{msgs}\\nRAW:\\n{raw}\\nPARSED={score}\\n\")\n",
    "        return {\"idx\": i, \"score\": score, \"job_titles\": title}\n",
    "\n",
    "    rows = []\n",
    "    with cf.ThreadPoolExecutor(max_workers=min(concurrency, len(all_titles))) as ex:\n",
    "        for row in ex.map(_score_one, list(enumerate(all_titles))):\n",
    "            rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows).sort_values(\"score\", ascending=False).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# Generic runner that writes the same CSV artifact\n",
    "\n",
    "def run_query_full_pairwise_openai_like(\n",
    "    queries: list[str],\n",
    "    *,\n",
    "    client,\n",
    "    model: str,\n",
    "    model_tag: str,\n",
    "    top_k: int = 10,\n",
    "    concurrency: int = 6,\n",
    "    debug_first_n: int = 3\n",
    "):\n",
    "    out_dir = os.path.join(OUT_DIR, \"llm\"); os.makedirs(out_dir, exist_ok=True)\n",
    "    top10_blocks = []\n",
    "    for q in queries:\n",
    "        df_rank = score_titles_pairwise_openai_like(\n",
    "            q, titles,\n",
    "            client=client,\n",
    "            model=model,\n",
    "            build_prompt_fn=build_prompt_single_pairwise,\n",
    "            concurrency=concurrency,\n",
    "            debug_first_n=debug_first_n\n",
    "        )\n",
    "        print_ranking(q, df_rank, top_k=top_k)  # <- the existing pretty-printer\n",
    "        df_q = df_rank.head(top_k)[[\"score\", \"job_titles\"]].copy()\n",
    "        df_q.insert(0, \"query\", q)\n",
    "        top10_blocks.append(df_q)\n",
    "\n",
    "    top10 = pd.concat(top10_blocks, ignore_index=True)\n",
    "    path = os.path.join(out_dir, f\"llm_top10__{model_tag}__pairwise__all_queries.csv\")\n",
    "    top10.to_csv(path, index=False)\n",
    "    print(\"Saved:\", path)\n",
    "    return top10, path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345bd62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_grok_pairwise, path_grok_pairwise = run_query_full_pairwise_openai_like(\n",
    "    QUERIES,\n",
    "    client=client_grok,               \n",
    "    model=GROK_MODEL_ID,              \n",
    "    model_tag=\"grok-4-fast\",\n",
    "    debug_first_n=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdb7629",
   "metadata": {},
   "source": [
    "### Step 12 - Experience with ChatGPT / OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdc5909",
   "metadata": {},
   "source": [
    "**DeepSeek V3.1 dual mode (reasoning and chat)  / DeepSeek**\n",
    "\n",
    "- For this project we used the `chat` mode.\n",
    "- **Release Date**: August, 2025.\n",
    "- **Architecture**: Autoregressive (decoder-only) Transformer, instruction-tuned for dialogue and tool-use.\n",
    "- **Parameters**: Not public\n",
    "- **Layers**: Not public        \n",
    "- **Context Window**: Defined by the active backend model and shown in the API docs/dashboard; plan for large but finite limits (tens of thousands of tokens, exact value depends on the current deployment).\n",
    "- **Tokenizer**: Proprietary tokenizer exposed through an OpenAI-compatible API interface (token counting/usage returned by the API).\n",
    "- **Objective**: Next-token prediction with instruction-tuning; optimized for helpful, harmless, and concise chat completions.\n",
    "- **Training**: Large-scale mixed corpora (web, code, multilingual) plus post-training alignment; exact datasets and recipe not publicly detailed.\n",
    "- **Efficiency**: Fully hosted—no local VRAM needed. Use streaming for long responses and keep temperature=0 for deterministic, parser-friendly outputs; control cost via prompt length/top-k prefiltering.\n",
    "- **License**: Access governed by DeepSeek API Terms of Use (hosted model; weights not distributed).\n",
    "- *Notes*: Works well with OpenAI-style Chat Completions clients. This model is the one powering the current DeepSeek Chat experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e37e9284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load env + build client\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY  = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_MODEL_ID = \"gpt-4o\"  # set \"gpt-5\" here if you have access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "10f69408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "client_oa = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"), max_retries=3)  # no base_url needed for OpenAI\n",
    "\n",
    "resp = client_oa.chat.completions.create(\n",
    "    model=OPENAI_MODEL_ID,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Reply with digits only.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Return the number 7.\"}\n",
    "    ],\n",
    "    temperature=0.0,\n",
    "    max_tokens=5,\n",
    ")\n",
    "print(resp.choices[0].message.content)  # -> 7\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd6f1ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, random, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "48092072",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_prompt_single_pairwise' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m      5\u001b[39m     RateLimitError = APITimeoutError = APIConnectionError = APIStatusError = \u001b[38;5;167;01mException\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mscore_titles_pairwise_openai_like\u001b[39m(\n\u001b[32m      8\u001b[39m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m      9\u001b[39m     all_titles: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m     10\u001b[39m     *,\n\u001b[32m     11\u001b[39m     client,\n\u001b[32m     12\u001b[39m     model: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     build_prompt_fn=\u001b[43mbuild_prompt_single_pairwise\u001b[49m,\n\u001b[32m     14\u001b[39m     max_new_tokens: \u001b[38;5;28mint\u001b[39m = \u001b[32m4\u001b[39m,      \u001b[38;5;66;03m# ↓ smaller; we only need one int\u001b[39;00m\n\u001b[32m     15\u001b[39m     temperature: \u001b[38;5;28mfloat\u001b[39m = \u001b[32m0.0\u001b[39m,     \u001b[38;5;66;03m# ↓ deterministic & cheaper sampling\u001b[39;00m\n\u001b[32m     16\u001b[39m     top_p: \u001b[38;5;28mfloat\u001b[39m = \u001b[32m1.0\u001b[39m,\n\u001b[32m     17\u001b[39m     concurrency: \u001b[38;5;28mint\u001b[39m = \u001b[32m2\u001b[39m,         \u001b[38;5;66;03m# keep low to respect TPM\u001b[39;00m\n\u001b[32m     18\u001b[39m     debug_first_n: \u001b[38;5;28mint\u001b[39m = \u001b[32m0\u001b[39m,\n\u001b[32m     19\u001b[39m     _pace_seconds: \u001b[38;5;28mfloat\u001b[39m = \u001b[32m0.05\u001b[39m    \u001b[38;5;66;03m# tiny stagger to avoid bursts\u001b[39;00m\n\u001b[32m     20\u001b[39m ):\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call_with_retries\u001b[39m(messages):\n\u001b[32m     22\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m6\u001b[39m):\n",
      "\u001b[31mNameError\u001b[39m: name 'build_prompt_single_pairwise' is not defined"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # OpenAI 1.x names\n",
    "    from openai import RateLimitError, APITimeoutError, APIConnectionError, APIStatusError\n",
    "except Exception:\n",
    "    RateLimitError = APITimeoutError = APIConnectionError = APIStatusError = Exception\n",
    "\n",
    "def score_titles_pairwise_openai_like(\n",
    "    query: str,\n",
    "    all_titles: list[str],\n",
    "    *,\n",
    "    client,\n",
    "    model: str,\n",
    "    build_prompt_fn=build_prompt_single_pairwise,\n",
    "    max_new_tokens: int = 4,      # ↓ smaller; we only need one int\n",
    "    temperature: float = 0.0,     # ↓ deterministic & cheaper sampling\n",
    "    top_p: float = 1.0,\n",
    "    concurrency: int = 2,         # keep low to respect TPM\n",
    "    debug_first_n: int = 0,\n",
    "    _pace_seconds: float = 0.05    # tiny stagger to avoid bursts\n",
    "):\n",
    "    def _call_with_retries(messages):\n",
    "        for attempt in range(6):\n",
    "            try:\n",
    "                return client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    messages=messages,\n",
    "                    temperature=temperature,\n",
    "                    top_p=top_p,\n",
    "                    max_tokens=max_new_tokens,\n",
    "                )\n",
    "            except (RateLimitError, APITimeoutError, APIConnectionError, APIStatusError) as e:\n",
    "                # Parse \"try again in 489ms\" if present; else exponential backoff\n",
    "                m = re.search(r\"try again in\\s+(\\d+)ms\", str(e), re.I)\n",
    "                wait = (int(m.group(1))/1000.0) if m else (0.5 * (2 ** attempt))\n",
    "                time.sleep(min(wait + random.uniform(0, 0.2), 8.0))\n",
    "\n",
    "    def _score_one(i_title):\n",
    "        i, title = i_title\n",
    "        msgs = build_prompt_fn(query, title)\n",
    "        resp = _call_with_retries(msgs)\n",
    "        raw = (resp.choices[0].message.content or \"\").strip()\n",
    "        score = _parse_one_int(raw)\n",
    "        if i < debug_first_n:\n",
    "            print(f\"\\n[debug] idx={i}\\nPROMPT:\\n{msgs}\\nRAW:\\n{raw}\\nPARSED={score}\\n\")\n",
    "        # tiny pacing to smooth bursts across threads\n",
    "        if _pace_seconds:\n",
    "            time.sleep(_pace_seconds)\n",
    "        return {\"idx\": i, \"score\": score, \"job_titles\": title}\n",
    "\n",
    "    rows = []\n",
    "    items = list(enumerate(all_titles))\n",
    "    with cf.ThreadPoolExecutor(max_workers=min(concurrency, len(items))) as ex:\n",
    "        for row in ex.map(_score_one, items):\n",
    "            rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows).sort_values(\"score\", ascending=False).reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa337bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_grok_pairwise, path_grok_pairwise = run_query_full_pairwise_openai_like(\n",
    "    QUERIES,\n",
    "    client=client_oa,\n",
    "    model=OPENAI_MODEL_ID,\n",
    "    model_tag=\"gpt-4o__pairwise\",\n",
    "    concurrency=2,\n",
    "    debug_first_n=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0cbe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_grok_pairwise, path_grok_pairwise = run_query_full_pairwise_openai_like(\n",
    "    QUERIES,\n",
    "    client=client_grok,               \n",
    "    model=GROK_MODEL_ID,              \n",
    "    model_tag=\"grok-4-fast\",\n",
    "    concurrency=6,\n",
    "    debug_first_n=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d91337e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_grok_pairwise, path_grok_pairwise = run_query_full_pairwise_openai_like(\n",
    "    QUERIES,\n",
    "    client=client_ds,               \n",
    "    model=\"deepseek-chat\",              \n",
    "    model_tag=\"deepseek-chat__pairwise\",\n",
    "    concurrency=6,\n",
    "    debug_first_n=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fc0c12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2952dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde77fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b430935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b316725a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "08b659fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b0dee641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures as cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ac383553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_single_ds(query: str, title: str) -> list[dict]:\n",
    "    rubric = (\n",
    "        \"You are a recruiter scoring job-title similarity to the query.\\n\"\n",
    "        \"Return EXACTLY one integer 0–100 on a single line.\\n\"\n",
    "        \"Digits only. No words. No punctuation. No explanation.\\n\"\n",
    "        \"\\n\"\n",
    "        \"Scale:\\n\"\n",
    "        \"  90–100 = exact/near-exact role match\\n\"\n",
    "        \"  70–89  = very similar, same discipline\\n\"\n",
    "        \"  40–69  = related/adjacent\\n\"\n",
    "        \"  10–39  = mostly unrelated\\n\"\n",
    "        \"  0–9    = unrelated or not a real job title\\n\"\n",
    "        \"\\n\"\n",
    "        \"Guidelines:\\n\"\n",
    "        \"  • For technical queries (data scientist, machine learning engineer, backend developer),\\n\"\n",
    "        \"    HR/People/Recruiting/Education roles are 0–10.\\n\"\n",
    "        \"  • If it looks like a slogan/sentence/company/org (not a job title), score 0–10.\\n\"\n",
    "        \"  • If title includes Student/Intern/Aspiring, subtract ~20 (min 0) unless it directly matches the role.\\n\"\n",
    "        \"  • Use the full scale. Do NOT default to 5; use 0 when clearly unrelated.\\n\"\n",
    "        \"\\n\"\n",
    "        \"Examples:\\n\"\n",
    "        \"  Query: \\\"data scientist\\\"         | Candidate: Senior Data Scientist           → 95\\n\"\n",
    "        \"  Query: \\\"data scientist\\\"         | Candidate: Undergraduate Research Assistant → 55\\n\"\n",
    "        \"  Query: \\\"data scientist\\\"         | Candidate: HR Coordinator                  → 0\\n\"\n",
    "        \"  Query: \\\"backend developer\\\"      | Candidate: Junior Backend Engineer         → 85\\n\"\n",
    "        \"  Query: \\\"product manager\\\"        | Candidate: Technical Product Manager       → 90\\n\"\n",
    "        \"  Query: \\\"product manager\\\"        | Candidate: Retail Store Manager            → 35\\n\"\n",
    "    )\n",
    "    user = f'Query: \"{query}\"\\nCandidate: {title}\\nScore:'\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": rubric},\n",
    "        {\"role\": \"user\", \"content\": user},\n",
    "    ]\n",
    "\t\n",
    "build_prompt_single_pairwise = build_prompt_single_ds\n",
    "_parse_one_int = parse_one_int\n",
    "\n",
    "\n",
    "# Generic pairwise scorer for ANY OpenAI-compatible client\n",
    "def score_titles_pairwise_openai_like(\n",
    "    query: str,\n",
    "    all_titles: list[str],\n",
    "    *,\n",
    "    client,\n",
    "    model: str,\n",
    "    build_prompt_fn=build_prompt_single_pairwise,\n",
    "    max_new_tokens: int = 4,      # ↓ smaller; we only need one int\n",
    "    temperature: float = 0.0,     # ↓ deterministic & cheaper sampling\n",
    "    top_p: float = 1.0,\n",
    "    concurrency: int = 2,         # keep low to respect TPM\n",
    "    debug_first_n: int = 0,\n",
    "    _pace_seconds: float = 0.05    # tiny stagger to avoid bursts\n",
    "):\n",
    "    def _call_with_retries(messages):\n",
    "        for attempt in range(6):\n",
    "            try:\n",
    "                return client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    messages=messages,\n",
    "                    temperature=temperature,\n",
    "                    top_p=top_p,\n",
    "                    max_tokens=max_new_tokens,\n",
    "                )\n",
    "            except (RateLimitError, APITimeoutError, APIConnectionError, APIStatusError) as e:\n",
    "                # Parse \"try again in 489ms\" if present; else exponential backoff\n",
    "                m = re.search(r\"try again in\\s+(\\d+)ms\", str(e), re.I)\n",
    "                wait = (int(m.group(1))/1000.0) if m else (0.5 * (2 ** attempt))\n",
    "                time.sleep(min(wait + random.uniform(0, 0.2), 8.0))\n",
    "\n",
    "    def _score_one(i_title):\n",
    "        i, title = i_title\n",
    "        msgs = build_prompt_fn(query, title)\n",
    "        resp = _call_with_retries(msgs)\n",
    "        raw = (resp.choices[0].message.content or \"\").strip()\n",
    "        score = _parse_one_int(raw)\n",
    "        if i < debug_first_n:\n",
    "            print(f\"\\n[debug] idx={i}\\nPROMPT:\\n{msgs}\\nRAW:\\n{raw}\\nPARSED={score}\\n\")\n",
    "        # tiny pacing to smooth bursts across threads\n",
    "        if _pace_seconds:\n",
    "            time.sleep(_pace_seconds)\n",
    "        return {\"idx\": i, \"score\": score, \"job_titles\": title}\n",
    "\n",
    "    rows = []\n",
    "    items = list(enumerate(all_titles))\n",
    "    with cf.ThreadPoolExecutor(max_workers=min(concurrency, len(items))) as ex:\n",
    "        for row in ex.map(_score_one, items):\n",
    "            rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows).sort_values(\"score\", ascending=False).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Generic runner that writes the same CSV artifact\n",
    "\n",
    "def run_query_full_pairwise_openai_like(\n",
    "    queries: list[str],\n",
    "    *,\n",
    "    client,\n",
    "    model: str,\n",
    "    model_tag: str,\n",
    "    top_k: int = 10,\n",
    "    concurrency: int = 6,\n",
    "    debug_first_n: int = 3\n",
    "):\n",
    "    out_dir = os.path.join(OUT_DIR, \"llm\"); os.makedirs(out_dir, exist_ok=True)\n",
    "    top10_blocks = []\n",
    "    for q in queries:\n",
    "        df_rank = score_titles_pairwise_openai_like(\n",
    "            q, titles,\n",
    "            client=client,\n",
    "            model=model,\n",
    "            build_prompt_fn=build_prompt_single_pairwise,\n",
    "            concurrency=concurrency,\n",
    "            debug_first_n=debug_first_n\n",
    "        )\n",
    "        print_ranking(q, df_rank, top_k=top_k)  # <- the existing pretty-printer\n",
    "        df_q = df_rank.head(top_k)[[\"score\", \"job_titles\"]].copy()\n",
    "        df_q.insert(0, \"query\", q)\n",
    "        top10_blocks.append(df_q)\n",
    "\n",
    "    top10 = pd.concat(top10_blocks, ignore_index=True)\n",
    "    path = os.path.join(out_dir, f\"llm_top10__{model_tag}__pairwise__all_queries.csv\")\n",
    "    top10.to_csv(path, index=False)\n",
    "    print(\"Saved:\", path)\n",
    "    return top10, path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "92008f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[debug] idx=0\n",
      "PROMPT:\n",
      "[{'role': 'system', 'content': 'You are a recruiter scoring job-title similarity to the query.\\nReturn EXACTLY one integer 0–100 on a single line.\\nDigits only. No words. No punctuation. No explanation.\\n\\nScale:\\n  90–100 = exact/near-exact role match\\n  70–89  = very similar, same discipline\\n  40–69  = related/adjacent\\n  10–39  = mostly unrelated\\n  0–9    = unrelated or not a real job title\\n\\nGuidelines:\\n  • For technical queries (data scientist, machine learning engineer, backend developer),\\n    HR/People/Recruiting/Education roles are 0–10.\\n  • If it looks like a slogan/sentence/company/org (not a job title), score 0–10.\\n  • If title includes Student/Intern/Aspiring, subtract ~20 (min 0) unless it directly matches the role.\\n  • Use the full scale. Do NOT default to 5; use 0 when clearly unrelated.\\n\\nExamples:\\n  Query: \"data scientist\"         | Candidate: Senior Data Scientist           → 95\\n  Query: \"data scientist\"         | Candidate: Undergraduate Research Assistant → 55\\n  Query: \"data scientist\"         | Candidate: HR Coordinator                  → 0\\n  Query: \"backend developer\"      | Candidate: Junior Backend Engineer         → 85\\n  Query: \"product manager\"        | Candidate: Technical Product Manager       → 90\\n  Query: \"product manager\"        | Candidate: Retail Store Manager            → 35\\n'}, {'role': 'user', 'content': 'Query: \"data scientist\"\\nCandidate: 2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\\nScore:'}]\n",
      "RAW:\n",
      "10\n",
      "PARSED=10\n",
      "\n",
      "\n",
      "Query: data scientist\n",
      "    0.600  Business Intelligence and Analytics at Travelers\n",
      "    0.550  Undergraduate Research Assistant at Styczynski Lab\n",
      "    0.400  Junior MES Engineer| Information Systems\n",
      "    0.400  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.300  Student at Indiana University Kokomo - Business Management - \n",
      "Retail Manager at Delphi Hardware and Paint\n",
      "    0.100  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.100  Advisory Board Member at Celal Bayar University\n",
      "    0.100  Advisory Board Member at Celal Bayar University\n",
      "    0.100  Lead Official at Western Illinois University\n",
      "    0.100  Student\n",
      "\n",
      "[debug] idx=0\n",
      "PROMPT:\n",
      "[{'role': 'system', 'content': 'You are a recruiter scoring job-title similarity to the query.\\nReturn EXACTLY one integer 0–100 on a single line.\\nDigits only. No words. No punctuation. No explanation.\\n\\nScale:\\n  90–100 = exact/near-exact role match\\n  70–89  = very similar, same discipline\\n  40–69  = related/adjacent\\n  10–39  = mostly unrelated\\n  0–9    = unrelated or not a real job title\\n\\nGuidelines:\\n  • For technical queries (data scientist, machine learning engineer, backend developer),\\n    HR/People/Recruiting/Education roles are 0–10.\\n  • If it looks like a slogan/sentence/company/org (not a job title), score 0–10.\\n  • If title includes Student/Intern/Aspiring, subtract ~20 (min 0) unless it directly matches the role.\\n  • Use the full scale. Do NOT default to 5; use 0 when clearly unrelated.\\n\\nExamples:\\n  Query: \"data scientist\"         | Candidate: Senior Data Scientist           → 95\\n  Query: \"data scientist\"         | Candidate: Undergraduate Research Assistant → 55\\n  Query: \"data scientist\"         | Candidate: HR Coordinator                  → 0\\n  Query: \"backend developer\"      | Candidate: Junior Backend Engineer         → 85\\n  Query: \"product manager\"        | Candidate: Technical Product Manager       → 90\\n  Query: \"product manager\"        | Candidate: Retail Store Manager            → 35\\n'}, {'role': 'user', 'content': 'Query: \"machine learning engineer\"\\nCandidate: 2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\\nScore:'}]\n",
      "RAW:\n",
      "0\n",
      "PARSED=0\n",
      "\n",
      "\n",
      "Query: machine learning engineer\n",
      "    0.550  Undergraduate Research Assistant at Styczynski Lab\n",
      "    0.400  Business Intelligence and Analytics at Travelers\n",
      "    0.400  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.400  Junior MES Engineer| Information Systems\n",
      "    0.100  Advisory Board Member at Celal Bayar University\n",
      "    0.100  Student at Chapman University\n",
      "    0.100  Advisory Board Member at Celal Bayar University\n",
      "    0.100  Student at Chapman University\n",
      "    0.100  Student at Chapman University\n",
      "    0.100  Student at Chapman University\n",
      "\n",
      "[debug] idx=0\n",
      "PROMPT:\n",
      "[{'role': 'system', 'content': 'You are a recruiter scoring job-title similarity to the query.\\nReturn EXACTLY one integer 0–100 on a single line.\\nDigits only. No words. No punctuation. No explanation.\\n\\nScale:\\n  90–100 = exact/near-exact role match\\n  70–89  = very similar, same discipline\\n  40–69  = related/adjacent\\n  10–39  = mostly unrelated\\n  0–9    = unrelated or not a real job title\\n\\nGuidelines:\\n  • For technical queries (data scientist, machine learning engineer, backend developer),\\n    HR/People/Recruiting/Education roles are 0–10.\\n  • If it looks like a slogan/sentence/company/org (not a job title), score 0–10.\\n  • If title includes Student/Intern/Aspiring, subtract ~20 (min 0) unless it directly matches the role.\\n  • Use the full scale. Do NOT default to 5; use 0 when clearly unrelated.\\n\\nExamples:\\n  Query: \"data scientist\"         | Candidate: Senior Data Scientist           → 95\\n  Query: \"data scientist\"         | Candidate: Undergraduate Research Assistant → 55\\n  Query: \"data scientist\"         | Candidate: HR Coordinator                  → 0\\n  Query: \"backend developer\"      | Candidate: Junior Backend Engineer         → 85\\n  Query: \"product manager\"        | Candidate: Technical Product Manager       → 90\\n  Query: \"product manager\"        | Candidate: Retail Store Manager            → 35\\n'}, {'role': 'user', 'content': 'Query: \"backend developer\"\\nCandidate: 2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\\nScore:'}]\n",
      "RAW:\n",
      "0\n",
      "PARSED=0\n",
      "\n",
      "\n",
      "Query: backend developer\n",
      "    0.500  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.400  Business Intelligence and Analytics at Travelers\n",
      "    0.400  Undergraduate Research Assistant at Styczynski Lab\n",
      "    0.400  Junior MES Engineer| Information Systems\n",
      "    0.100  Advisory Board Member at Celal Bayar University\n",
      "    0.100  Student at Chapman University\n",
      "    0.100  Student at Chapman University\n",
      "    0.100  Student at Chapman University\n",
      "    0.100  Student at Indiana University Kokomo - Business Management - \n",
      "Retail Manager at Delphi Hardware and Paint\n",
      "    0.100  Student at Chapman University\n",
      "\n",
      "[debug] idx=0\n",
      "PROMPT:\n",
      "[{'role': 'system', 'content': 'You are a recruiter scoring job-title similarity to the query.\\nReturn EXACTLY one integer 0–100 on a single line.\\nDigits only. No words. No punctuation. No explanation.\\n\\nScale:\\n  90–100 = exact/near-exact role match\\n  70–89  = very similar, same discipline\\n  40–69  = related/adjacent\\n  10–39  = mostly unrelated\\n  0–9    = unrelated or not a real job title\\n\\nGuidelines:\\n  • For technical queries (data scientist, machine learning engineer, backend developer),\\n    HR/People/Recruiting/Education roles are 0–10.\\n  • If it looks like a slogan/sentence/company/org (not a job title), score 0–10.\\n  • If title includes Student/Intern/Aspiring, subtract ~20 (min 0) unless it directly matches the role.\\n  • Use the full scale. Do NOT default to 5; use 0 when clearly unrelated.\\n\\nExamples:\\n  Query: \"data scientist\"         | Candidate: Senior Data Scientist           → 95\\n  Query: \"data scientist\"         | Candidate: Undergraduate Research Assistant → 55\\n  Query: \"data scientist\"         | Candidate: HR Coordinator                  → 0\\n  Query: \"backend developer\"      | Candidate: Junior Backend Engineer         → 85\\n  Query: \"product manager\"        | Candidate: Technical Product Manager       → 90\\n  Query: \"product manager\"        | Candidate: Retail Store Manager            → 35\\n'}, {'role': 'user', 'content': 'Query: \"product manager\"\\nCandidate: 2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\\nScore:'}]\n",
      "RAW:\n",
      "10\n",
      "PARSED=10\n",
      "\n",
      "\n",
      "Query: product manager\n",
      "    0.600  Business Intelligence and Analytics at Travelers\n",
      "    0.400  Undergraduate Research Assistant at Styczynski Lab\n",
      "    0.400  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.400  Junior MES Engineer| Information Systems\n",
      "    0.350  RRP Brand Portfolio Executive at JTI (Japan Tobacco International)\n",
      "    0.300  Experienced Retail Manager and aspiring Human Resources Professional\n",
      "    0.300  Student at Indiana University Kokomo - Business Management - \n",
      "Retail Manager at Delphi Hardware and Paint\n",
      "    0.200  Director Of Administration at Excellence Logging\n",
      "    0.100  Seeking Human Resources HRIS and Generalist Positions\n",
      "    0.100  Student at Humber College and Aspiring Human Resources Generalist\n",
      "Saved: outputs\\llm\\llm_top10__gpt-4o__pairwise__pairwise__all_queries.csv\n"
     ]
    }
   ],
   "source": [
    "top10_grok_pairwise, path_grok_pairwise = run_query_full_pairwise_openai_like(\n",
    "    QUERIES,\n",
    "    client=client_oa,\n",
    "    model=OPENAI_MODEL_ID,\n",
    "    model_tag=\"gpt-4o__pairwise\",\n",
    "    concurrency=2,\n",
    "    debug_first_n=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dab66ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: data scientist\n",
      "    0.700  Business Intelligence and Analytics at Travelers\n",
      "    0.550  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.550  Undergraduate Research Assistant at Styczynski Lab\n",
      "    0.300  Junior MES Engineer| Information Systems\n",
      "    0.050  Student at Indiana University Kokomo - Business Management - \n",
      "Retail Manager at Delphi Hardware and Paint\n",
      "    0.000  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.000  Aspiring Human Resources Professional\n",
      "    0.000  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.000  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.000  Seeking Human Resources HRIS and Generalist Positions\n",
      "\n",
      "Query: machine learning engineer\n",
      "    0.550  Undergraduate Research Assistant at Styczynski Lab\n",
      "    0.500  Business Intelligence and Analytics at Travelers\n",
      "    0.450  Junior MES Engineer| Information Systems\n",
      "    0.200  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.050  Advisory Board Member at Celal Bayar University\n",
      "    0.000  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.000  Aspiring Human Resources Professional\n",
      "    0.000  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.000  HR Senior Specialist\n",
      "    0.000  Student at Humber College and Aspiring Human Resources Generalist\n",
      "\n",
      "Query: backend developer\n",
      "    0.750  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.450  Junior MES Engineer| Information Systems\n",
      "    0.450  Business Intelligence and Analytics at Travelers\n",
      "    0.200  Undergraduate Research Assistant at Styczynski Lab\n",
      "    0.000  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.000  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.000  Aspiring Human Resources Professional\n",
      "    0.000  People Development Coordinator at Ryan\n",
      "    0.000  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.000  Seeking Human Resources HRIS and Generalist Positions\n",
      "\n",
      "Query: product manager\n",
      "    0.800  RRP Brand Portfolio Executive at JTI (Japan Tobacco International)\n",
      "    0.500  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.450  Business Intelligence and Analytics at Travelers\n",
      "    0.350  Director Of Administration at Excellence Logging\n",
      "    0.300  Undergraduate Research Assistant at Styczynski Lab\n",
      "    0.250  Junior MES Engineer| Information Systems\n",
      "    0.200  HR Manager at Endemol Shine North America\n",
      "    0.150  Experienced Retail Manager and aspiring Human Resources Professional\n",
      "    0.150  Business Management Major and Aspiring Human Resources Manager\n",
      "    0.150  Student at Indiana University Kokomo - Business Management - \n",
      "Retail Manager at Delphi Hardware and Paint\n",
      "Saved: outputs\\llm\\llm_top10__grok-4-fast__pairwise__all_queries.csv\n"
     ]
    }
   ],
   "source": [
    "top10_grok_pairwise, path_grok_pairwise = run_query_full_pairwise_openai_like(\n",
    "    QUERIES,\n",
    "    client=client_grok,               \n",
    "    model=GROK_MODEL_ID,              \n",
    "    model_tag=\"grok-4-fast\",\n",
    "    concurrency=6,\n",
    "    debug_first_n=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1acb57b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: data scientist\n",
      "    0.700  Business Intelligence and Analytics at Travelers\n",
      "    0.550  Undergraduate Research Assistant at Styczynski Lab\n",
      "    0.300  Junior MES Engineer| Information Systems\n",
      "    0.100  Student\n",
      "    0.000  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.000  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.000  Aspiring Human Resources Professional\n",
      "    0.000  People Development Coordinator at Ryan\n",
      "    0.000  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.000  Seeking Human Resources HRIS and Generalist Positions\n",
      "\n",
      "Query: machine learning engineer\n",
      "    0.550  Undergraduate Research Assistant at Styczynski Lab\n",
      "    0.400  Junior MES Engineer| Information Systems\n",
      "    0.400  Business Intelligence and Analytics at Travelers\n",
      "    0.100  Student\n",
      "    0.000  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.000  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.000  Aspiring Human Resources Professional\n",
      "    0.000  People Development Coordinator at Ryan\n",
      "    0.000  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.000  Seeking Human Resources HRIS and Generalist Positions\n",
      "\n",
      "Query: backend developer\n",
      "    0.700  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.550  Undergraduate Research Assistant at Styczynski Lab\n",
      "    0.400  Junior MES Engineer| Information Systems\n",
      "    0.100  Student\n",
      "    0.100  Business Intelligence and Analytics at Travelers\n",
      "    0.000  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.000  Aspiring Human Resources Professional\n",
      "    0.000  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.000  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.000  Seeking Human Resources HRIS and Generalist Positions\n",
      "\n",
      "Query: product manager\n",
      "    0.400  RRP Brand Portfolio Executive at JTI (Japan Tobacco International)\n",
      "    0.400  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.400  Business Intelligence and Analytics at Travelers\n",
      "    0.400  Undergraduate Research Assistant at Styczynski Lab\n",
      "    0.350  Student at Indiana University Kokomo - Business Management - \n",
      "Retail Manager at Delphi Hardware and Paint\n",
      "    0.200  Junior MES Engineer| Information Systems\n",
      "    0.100  Aspiring Human Resources Specialist\n",
      "    0.100  Advisory Board Member at Celal Bayar University\n",
      "    0.100  Aspiring Human Resources Specialist\n",
      "    0.100  Advisory Board Member at Celal Bayar University\n",
      "Saved: outputs\\llm\\llm_top10__deepseek-chat__pairwise__pairwise__all_queries.csv\n"
     ]
    }
   ],
   "source": [
    "top10_grok_pairwise, path_grok_pairwise = run_query_full_pairwise_openai_like(\n",
    "    QUERIES,\n",
    "    client=client_ds,               \n",
    "    model=\"deepseek-chat\",              \n",
    "    model_tag=\"deepseek-chat__pairwise\",\n",
    "    concurrency=6,\n",
    "    debug_first_n=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61889e84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pot_Tals_LLM_Env",
   "language": "python",
   "name": "pot-tals_llm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
