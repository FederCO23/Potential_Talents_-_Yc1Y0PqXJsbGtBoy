{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b22c4196",
   "metadata": {},
   "source": [
    "## Potential Talents - Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2956a14e",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716b8abb",
   "metadata": {},
   "source": [
    "# Job Title Similarity using LLMs-as-Rankers\n",
    "\n",
    "### Objective\n",
    "Given a query, ask a small LLM to score **all 104 job titles at once** (0–100, one score per line, same order), then rank the scores to compare the **top-10** with other results (from embeddings + cosine or other LLMs results)\n",
    "\n",
    "### Constraints\n",
    "- Local GPU: **GTX 1080 Ti**.\n",
    "- **Deterministic** generation: `do_sample=False`, `num_beams=1`.\n",
    "\n",
    "### Models (initial)\n",
    "- **1:** `microsoft/phi-3-mini-4k-instruct` (4k context, small & GPU-friendly).\n",
    "- **2:** `google/gemma-2-2b-it` (8k context, very small).\n",
    "- **3:** `qwen2.5-3B-instruct` (32k context, ~3B params, list-style outputs).\n",
    "- (After some tests we will avoid FLAN-T5 here due to the ~512 token input limit.)\n",
    "\n",
    "### Method\n",
    "1) Load SBERT top-10 baseline (from Part 3).  \n",
    "2) Load a small **causal LM**.  \n",
    "3) Build a prompt that lists all **104** titles (numbered).  \n",
    "4) Generate **104 lines of integers**; parse → rank; print top-10; save top-10 CSV (`query,score,job_titles`).  \n",
    "5) Repeat for the 4 queries; later compute nDCG@10 and compare.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e935cd",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b387d87",
   "metadata": {},
   "source": [
    "### Step 0 - Imports, config, folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21ce1f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# core\n",
    "import os, json, math, re, random, time, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# HF\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2188f07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproducibility\n",
    "SEED = 23\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "# paths\n",
    "DATA_DIR = \"data\"\n",
    "OUT_DIR  = \"outputs\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "QUERIES = [\"data scientist\", \"machine learning engineer\", \"backend developer\", \"product manager\"]  # same queries from Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d545eb",
   "metadata": {},
   "source": [
    "### Step 1 - Load titles and make a clean field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d845f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_DIR, \"potential_talents.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85b98037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104,\n",
       " ['2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional',\n",
       "  'Native English Teacher at EPIK (English Program in Korea)',\n",
       "  'Aspiring Human Resources Professional',\n",
       "  'People Development Coordinator at Ryan',\n",
       "  'Advisory Board Member at Celal Bayar University'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = df[\"job_title\"].astype(str).tolist()\n",
    "len(titles), titles[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870c7ee5",
   "metadata": {},
   "source": [
    "### Step 2 - Load SBERT top-10 baseline (as-is, from the previous project part 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfb96aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            query     score                                         job_titles\n",
      "0  data scientist  0.595830  Information Systems Specialist and Programmer ...\n",
      "1  data scientist  0.494619                       Human Resources Professional\n",
      "2  data scientist  0.456588           Junior MES Engineer| Information Systems\n",
      "Queries in baseline: ['data scientist' 'machine learning engineer' 'backend developer'\n",
      " 'product manager']\n"
     ]
    }
   ],
   "source": [
    "# Load your SBERT baseline as produced in Part 3 (no changes to schema)\n",
    "BASELINE_TOP10_CSV = os.path.join(OUT_DIR, \"sbert_ranking_output.csv\")\n",
    "base = pd.read_csv(BASELINE_TOP10_CSV)\n",
    "\n",
    "print(base.head(3))\n",
    "print(\"Queries in baseline:\", base[\"query\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6546e899",
   "metadata": {},
   "source": [
    "### Step 3 - Pretty printer (same style as Part 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2643cbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ranking(query, rows_df, score_col=\"score\", title_col=\"job_titles\", top_k=10):\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    for _, r in rows_df.head(top_k).iterrows():\n",
    "        print(f\"   {r[score_col]: .3f}  {r[title_col]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8800280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: data scientist\n",
      "    0.596  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.495  Human Resources Professional\n",
      "    0.457  Junior MES Engineer| Information Systems\n",
      "    0.450  Aspiring Human Resources Specialist\n",
      "    0.449  Human Resources professional for the world leader in GIS software\n",
      "    0.441  HR Senior Specialist\n",
      "    0.433  Human Resources Generalist at ScottMadden, Inc.\n",
      "    0.416  Liberal Arts Major. Aspiring Human Resources Analyst.\n",
      "    0.410  Student\n",
      "    0.403  Human Resources Specialist at Luxottica\n",
      "\n",
      "Query: machine learning engineer\n",
      "    0.596  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.495  Human Resources Professional\n",
      "    0.457  Junior MES Engineer| Information Systems\n",
      "    0.450  Aspiring Human Resources Specialist\n",
      "    0.449  Human Resources professional for the world leader in GIS software\n",
      "    0.441  HR Senior Specialist\n",
      "    0.433  Human Resources Generalist at ScottMadden, Inc.\n",
      "    0.416  Liberal Arts Major. Aspiring Human Resources Analyst.\n",
      "    0.410  Student\n",
      "    0.403  Human Resources Specialist at Luxottica\n",
      "\n",
      "Query: backend developer\n",
      "    0.596  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.495  Human Resources Professional\n",
      "    0.457  Junior MES Engineer| Information Systems\n",
      "    0.450  Aspiring Human Resources Specialist\n",
      "    0.449  Human Resources professional for the world leader in GIS software\n",
      "    0.441  HR Senior Specialist\n",
      "    0.433  Human Resources Generalist at ScottMadden, Inc.\n",
      "    0.416  Liberal Arts Major. Aspiring Human Resources Analyst.\n",
      "    0.410  Student\n",
      "    0.403  Human Resources Specialist at Luxottica\n",
      "\n",
      "Query: product manager\n",
      "    0.596  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "    0.495  Human Resources Professional\n",
      "    0.457  Junior MES Engineer| Information Systems\n",
      "    0.450  Aspiring Human Resources Specialist\n",
      "    0.449  Human Resources professional for the world leader in GIS software\n",
      "    0.441  HR Senior Specialist\n",
      "    0.433  Human Resources Generalist at ScottMadden, Inc.\n",
      "    0.416  Liberal Arts Major. Aspiring Human Resources Analyst.\n",
      "    0.410  Student\n",
      "    0.403  Human Resources Specialist at Luxottica\n"
     ]
    }
   ],
   "source": [
    "for query in QUERIES:\n",
    "    print_ranking(query, base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db80fed",
   "metadata": {},
   "source": [
    "### Step 4 - Load a small LLM (Phi-3-mini from Microsoft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e5c1958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.6.0+cu124\n",
      "built with CUDA: 12.4\n",
      "cuda available: True\n",
      "gpu: NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "print(\"torch:\", torch.__version__)\n",
    "print(\"built with CUDA:\", torch.version.cuda)\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"gpu:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ef92698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b46f681200e466e83e04ba8a630d615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_ID = \"microsoft/phi-3-mini-4k-instruct\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
    "mdl = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    dtype=torch.float16 if torch.cuda.is_available() else None,\n",
    ").to(\"cuda\" if torch.cuda.is_available() else \"cpu\").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "394583c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a proper chat prompt\n",
    "msgs = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a calculator. Reply with digits only.\"},\n",
    "    {\"role\": \"user\",   \"content\": \"Return the number 7.\"}\n",
    "]\n",
    "prompt = tok.apply_chat_template(msgs, tokenize=False, add_generation_prompt=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ca4e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode & generate (greedy)\n",
    "inputs = tok(prompt, return_tensors=\"pt\").to(mdl.device)\n",
    "eos = [tok.eos_token_id]\n",
    "try:\n",
    "    eos.append(tok.convert_tokens_to_ids(\"<|end|>\"))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82e8d1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = mdl.generate(\n",
    "    **inputs,\n",
    "    do_sample=False,\n",
    "    num_beams=1,\n",
    "    max_new_tokens=3,\n",
    "    eos_token_id=eos,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27e410f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "out = tok.decode(gen[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True).strip()\n",
    "print(out)  # -> 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699f9861",
   "metadata": {},
   "source": [
    "### Step 5 — turn LLM into a job title ranker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e8837f",
   "metadata": {},
   "source": [
    "We will turn the LLM into a ranker by asking it to assign an integer score (0–100) to each raw job title for a given query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e07e1c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_all_chat_phi(query: str, titles: list[str]) -> str:\n",
    "    lines = \"\\n\".join(f\"{i+1}) {t}\" for i, t in enumerate(titles))\n",
    "    rubric = (\n",
    "        \"You are a recruiter scoring job-title similarity to the query.\\n\"\n",
    "        \"Rate each candidate with an integer 0–100 using the FULL scale:\\n\"\n",
    "        \" • 90–100 = exact/near-exact role match\\n\"\n",
    "        \" • 70–89  = same discipline or very similar role\\n\"\n",
    "        \" • 40–69  = related/adjacent\\n\"\n",
    "        \" • 10–39  = mostly unrelated\\n\"\n",
    "        \" • 0–9    = completely unrelated\\n\"\n",
    "        \"Use diverse scores; do NOT give 0 or 100 to many candidates.\\n\"\n",
    "        \"Ignore employer names, locations, programs.\\n\"\n",
    "        \"Output EXACTLY one integer per line, in the SAME ORDER as the candidates. No words, no punctuation.\"\n",
    "    )\n",
    "    # Non-extreme example\n",
    "    example = \"Example for 3 candidates:\\n82\\n41\\n7\"\n",
    "    user = f'Query: \"{query}\"\\n\\nCandidates:\\n{lines}\\n\\n{example}'\n",
    "    msgs = [{\"role\": \"system\", \"content\": rubric},\n",
    "            {\"role\": \"user\",   \"content\": user}]\n",
    "    return tok.apply_chat_template(msgs, tokenize=False, add_generation_prompt=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fd5fca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_scores_n(out: str, n: int) -> list[int]:\n",
    "    # prefer last int per non-empty line; fallback to last N ints in whole text\n",
    "    lines = [l.strip() for l in out.splitlines() if l.strip()]\n",
    "    scores = []\n",
    "    \n",
    "    for line in lines:\n",
    "        ints = re.findall(r\"-?\\d+\", line)\n",
    "        if ints:\n",
    "            scores.append(int(ints[-1]))\n",
    "        if len(scores) >= n:\n",
    "            break\n",
    "        \n",
    "    if len(scores) < n:\n",
    "        all_ints = [int(x) for x in re.findall(r\"-?\\d+\", out)]\n",
    "        scores = all_ints[-n:]\n",
    "        \n",
    "    scores = [max(0, min(100, int(s))) for s in scores]\n",
    "    \n",
    "    # if still short, add a padding\n",
    "    if len(scores) < n:  \n",
    "        scores += [0] * (n - len(scores))\n",
    "    return scores[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b170f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_all_titles_once(query: str,\n",
    "                          titles: list[str],\n",
    "                          max_new_tokens: int = 300,\n",
    "                          build_fn=None):\n",
    "    build_fn = build_fn or build_prompt_all_chat_phi\n",
    "    prompt = build_fn(query, titles)\n",
    "    print(\"Prompt tokens:\", len(tok(prompt)[\"input_ids\"]))\n",
    "    inputs = tok(prompt, return_tensors=\"pt\").to(mdl.device)\n",
    "    gen = mdl.generate(\n",
    "        **inputs,\n",
    "        do_sample=False,\n",
    "        num_beams=1,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        eos_token_id=[tok.eos_token_id],\n",
    "        min_new_tokens=min(len(titles), max_new_tokens-1),\n",
    "    )\n",
    "    out_text = tok.decode(gen[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True)\n",
    "    scores = parse_scores_n(out_text, len(titles))\n",
    "    df = pd.DataFrame({\"idx\": range(len(titles)), \"score\": scores})\n",
    "    df[\"job_titles\"] = [titles[i] for i in df[\"idx\"]]\n",
    "    df = df.sort_values(\"score\", ascending=False).reset_index(drop=True)\n",
    "    return df, out_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8ee9d3",
   "metadata": {},
   "source": [
    "Test **build_prompt_all_chat**, **parse_scores_n** and **score_all_tittles_once**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e1c94d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DEMO PROMPT (first 30 lines) ===\n",
      "<|system|>\n",
      "You are a recruiter scoring job-title similarity to the query.\n",
      "Rate each candidate with an integer 0–100 using the FULL scale:\n",
      " • 90–100 = exact/near-exact role match\n",
      " • 70–89  = same discipline or very similar role\n",
      " • 40–69  = related/adjacent\n",
      " • 10–39  = mostly unrelated\n",
      " • 0–9    = completely unrelated\n",
      "Use diverse scores; do NOT give 0 or 100 to many candidates.\n",
      "Ignore employer names, locations, programs.\n",
      "Output EXACTLY one integer per line, in the SAME ORDER as the candidates. No words, no punctuation.<|end|>\n",
      "<|user|>\n",
      "Query: \"data scientist\"\n",
      "\n",
      "Candidates:\n",
      "1) 2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "2) Native English Teacher at EPIK (English Program in Korea)\n",
      "3) Aspiring Human Resources Professional\n",
      "4) People Development Coordinator at Ryan\n",
      "5) Advisory Board Member at Celal Bayar University\n",
      "\n",
      "Example for 3 candidates:\n",
      "82\n",
      "41\n",
      "7<|end|>\n",
      "<|assistant|>\n",
      "Token count (subset): 279\n"
     ]
    }
   ],
   "source": [
    "test_query = \"data scientist\"\n",
    "\n",
    "# A Tiny subset to inspect everything\n",
    "subset = titles[:5]\n",
    "\n",
    "demo_prompt = build_prompt_all_chat_phi(test_query, subset)\n",
    "print(\"=== DEMO PROMPT (first 30 lines) ===\")\n",
    "print(\"\\n\".join(demo_prompt.splitlines()[:30]))\n",
    "print(\"Token count (subset):\", len(tok(demo_prompt)[\"input_ids\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0dd40f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt tokens: 279\n",
      "\n",
      "=== RAW MODEL OUTPUT (subset) ===\n",
      "0\n",
      "0\n",
      "7\n",
      "41\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df_sub, raw_sub = score_all_titles_once(test_query, subset, max_new_tokens=60)\n",
    "print(\"\\n=== RAW MODEL OUTPUT (subset) ===\")\n",
    "print(raw_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5738ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parsed scores (subset): [0, 0, 7, 41, 0]\n",
      "\n",
      "Paired (score, title) in ranked order:\n",
      " 41  People Development Coordinator at Ryan\n",
      "  7  Aspiring Human Resources Professional\n",
      "  0  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "  0  Native English Teacher at EPIK (English Program in Korea)\n",
      "  0  Advisory Board Member at Celal Bayar University\n"
     ]
    }
   ],
   "source": [
    "scores_sub = parse_scores_n(raw_sub, len(subset))\n",
    "print(\"\\nParsed scores (subset):\", scores_sub)\n",
    "print(\"\\nPaired (score, title) in ranked order:\")\n",
    "# the output DataFrame from `socre_all_titles_once`, df_sub, is sorted in not ascending order\n",
    "for _, r in df_sub.iterrows():\n",
    "    print(f\"{r['score']:>3}  {r['job_titles']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89bafef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Token count (full): 1928\n"
     ]
    }
   ],
   "source": [
    "# B) One full run (preview only; avoids flooding output)\n",
    "full_prompt = build_prompt_all_chat_phi(test_query, titles)\n",
    "print(\"\\nToken count (full):\", len(tok(full_prompt)[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2197f9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncation of long strings\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.width\", 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d261d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt tokens: 1928\n",
      "\n",
      "Full run: got 104 scores.\n",
      "Top-3 preview:\n",
      "   score                                                                                                job_titles\n",
      "0    100                                         Student at Humber College and Aspiring Human Resources Generalist\n",
      "1    100                                                           Advisory Board Member at Celal Bayar University\n",
      "2    100                                                                     Aspiring Human Resources Professional\n",
      "3     90                                                                       Aspiring Human Resources Specialist\n",
      "4     89                                         Student at Humber College and Aspiring Human Resources Generalist\n",
      "5     74                                                                     Aspiring Human Resources Professional\n",
      "6     72                                                 Native English Teacher at EPIK (English Program in Korea)\n",
      "7     70  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "8     70                                                                                      HR Senior Specialist\n",
      "9     69                                                                             Student at Chapman University\n"
     ]
    }
   ],
   "source": [
    "df_full, raw_full = score_all_titles_once(test_query, titles, max_new_tokens=300)\n",
    "print(\"\\nFull run: got\", len(df_full), \"scores.\")\n",
    "print(\"Top-3 preview:\")\n",
    "print(df_full.head(10)[[\"score\", \"job_titles\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ce5f589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ranking(query, rows_df, top_k=10):\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    for _, r in rows_df.head(top_k).iterrows():\n",
    "        print(f\"   {r['score']/100: .3f}  {r['job_titles']}\")\n",
    "\n",
    "def run_query_full(queries: list[str],\n",
    "                   model_tag: str = \"phi3_mini_4k\",\n",
    "                   build_prompt_fn=None):\n",
    "    out_dir = os.path.join(OUT_DIR, \"llm\"); os.makedirs(out_dir, exist_ok=True)\n",
    "    top10_blocks = []\n",
    "    for query in queries:\n",
    "        df_rank, raw = score_all_titles_once(query, titles, build_fn=build_prompt_fn)\n",
    "        print_ranking(query, df_rank, top_k=10)\n",
    "        df_q = df_rank.head(10)[[\"score\", \"job_titles\"]].copy()\n",
    "        df_q.insert(0, \"query\", query)\n",
    "        top10_blocks.append(df_q)\n",
    "    top10 = pd.concat(top10_blocks, ignore_index=True)\n",
    "    path = os.path.join(out_dir, f\"llm_top10__{model_tag}__all_queries.csv\")\n",
    "    top10.to_csv(path, index=False)\n",
    "    print(\"Saved:\", path)\n",
    "    return top10, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8de3570e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt tokens: 1928\n",
      "\n",
      "Query: data scientist\n",
      "    1.000  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    1.000  Advisory Board Member at Celal Bayar University\n",
      "    1.000  Aspiring Human Resources Professional\n",
      "    0.900  Aspiring Human Resources Specialist\n",
      "    0.890  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.740  Aspiring Human Resources Professional\n",
      "    0.720  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.700  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.700  HR Senior Specialist\n",
      "    0.690  Student at Chapman University\n",
      "Prompt tokens: 1928\n",
      "\n",
      "Query: machine learning engineer\n",
      "    1.000  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    1.000  Advisory Board Member at Celal Bayar University\n",
      "    1.000  Aspiring Human Resources Professional\n",
      "    0.900  Aspiring Human Resources Specialist\n",
      "    0.890  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.740  Aspiring Human Resources Professional\n",
      "    0.720  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.700  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.700  HR Senior Specialist\n",
      "    0.690  Student at Chapman University\n",
      "Prompt tokens: 1927\n",
      "\n",
      "Query: backend developer\n",
      "    1.000  Advisory Board Member at Celal Bayar University\n",
      "    0.750  Aspiring Human Resources Specialist\n",
      "    0.700  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.700  Aspiring Human Resources Professional\n",
      "    0.700  People Development Coordinator at Ryan\n",
      "    0.700  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.700  SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR\n",
      "    0.700  Seeking Human Resources HRIS and Generalist Positions\n",
      "    0.700  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.700  People Development Coordinator at Ryan\n",
      "Prompt tokens: 1927\n",
      "\n",
      "Query: product manager\n",
      "    1.000  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    1.000  Advisory Board Member at Celal Bayar University\n",
      "    1.000  Aspiring Human Resources Professional\n",
      "    0.900  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.900  Aspiring Human Resources Specialist\n",
      "    0.900  Aspiring Human Resources Professional\n",
      "    0.890  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.700  HR Senior Specialist\n",
      "    0.690  Student at Chapman University\n",
      "    0.410  Native English Teacher at EPIK (English Program in Korea)\n",
      "Saved: outputs\\llm\\llm_top10__phi3_mini_4k__all_queries.csv\n"
     ]
    }
   ],
   "source": [
    "top10_phi, path_phi = run_query_full(\n",
    "    QUERIES,\n",
    "    model_tag=\"phi3_mini_4k\",\n",
    "    build_prompt_fn=build_prompt_all_chat_phi\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86751029",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c030c12",
   "metadata": {},
   "source": [
    "### Step 6 - Experience with another small LLM: **Gemma-2-2b-it from Google**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75339a6d",
   "metadata": {},
   "source": [
    "Free some GPU allocated memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d273108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measure memory usage before and after freeing it\n",
      "\n",
      "Before:\n",
      "allocated: 7296.5 MiB | reserved: 8596.0 MiB | total: 11,264 MiB\n",
      "\n",
      "After:\n",
      "allocated: 8.1 MiB | reserved: 20.0 MiB | total: 11,264 MiB\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "def print_vram(prefix=\"\"):\n",
    "    if not torch.cuda.is_available():\n",
    "        print(prefix + \"CUDA not available\")\n",
    "        return\n",
    "    torch.cuda.synchronize()\n",
    "    alloc = torch.cuda.memory_allocated() / (1024**2)      # MiB\n",
    "    reserv = torch.cuda.memory_reserved() / (1024**2)      # MiB\n",
    "    total = torch.cuda.get_device_properties(0).total_memory / (1024**2)\n",
    "    print(f\"\\n{prefix}allocated: {alloc:.1f} MiB | reserved: {reserv:.1f} MiB | total: {total:,.0f} MiB\")\n",
    "\n",
    "# Print memory allocation before freeing it\n",
    "print(\"Measure memory usage before and after freeing it\")\n",
    "print_vram(\"Before:\\n\")\n",
    "\n",
    "# move model to CPU + delete big refs\n",
    "try: mdl.to(\"cpu\")\n",
    "except: pass\n",
    "# free memory\n",
    "for name in (\"pipe\",\"mdl\",\"tok\",\"inputs\",\"gen\"):\n",
    "    if name in globals(): del globals()[name]\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n",
    "print_vram(\"After:\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32ee0d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f2aaf3897543bdafa2c18320f3604f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "MODEL_ID = \"google/gemma-2-2b-it\"\n",
    "HF_TOKEN = os.getenv(\"llm_gemma\")\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
    "mdl = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    dtype=torch.float16 if device.type==\"cuda\" else None,\n",
    "    token=HF_TOKEN\n",
    ").to(device).eval()\n",
    "\n",
    "if tok.pad_token_id is None:\n",
    "    tok.pad_token = tok.eos_token\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=mdl, tokenizer=tok, device=0 if device.type==\"cuda\" else -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d27f0eb",
   "metadata": {},
   "source": [
    "Define a newer **prompt builder** function with a one-shot prompt and being more specific with the matching job titles. Also it drops the `system role` options that we used with Phi-3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ccf6aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_prompt_all_chat_gemma(query: str, titles: list[str]) -> str:\n",
    "    lines = \"\\n\".join(f\"{i+1}) {t}\" for i, t in enumerate(titles))\n",
    "    rubric = (\n",
    "        \"You are a recruiter scoring job-title similarity to the query.\\n\"\n",
    "        \"Rate each candidate with an integer between zero and one hundred using the full scale.\\n\"\n",
    "        \"Use diverse scores; avoid giving many zeros or many hundreds.\\n\"\n",
    "        \"Ignore employer names, locations, and programs.\\n\"\n",
    "        \"Return EXACTLY one integer per line in the SAME ORDER as the candidates.\\n\"\n",
    "        \"No words, no punctuation, no numbering.\\n\"\n",
    "    )\n",
    "    user_text = f'Query: \"{query}\"\\n\\nCandidates:\\n{lines}\\n\\nSCORES:'\n",
    "    # Gemma’s template may not support a system role → fold rubric into the user turn\n",
    "    msgs = [{\"role\": \"user\", \"content\": rubric + \"\\n\\n\" + user_text}]\n",
    "    return tok.apply_chat_template(msgs, tokenize=False, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8ee904a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt tokens: 1583\n",
      "\n",
      "Query: data scientist\n",
      "    0.200  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.100  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.100  Aspiring Human Resources Professional\n",
      "    0.100  People Development Coordinator at Ryan\n",
      "    0.100  Advisory Board Member at Celal Bayar University\n",
      "    0.100  Aspiring Human Resources Specialist\n",
      "    0.100  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.100  HR Senior Specialist\n",
      "    0.100  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.100  Seeking Human Resources HRIS and Generalist Positions\n",
      "Prompt tokens: 1584\n",
      "\n",
      "Query: machine learning engineer\n",
      "    0.200  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.100  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.100  Aspiring Human Resources Professional\n",
      "    0.100  People Development Coordinator at Ryan\n",
      "    0.100  Advisory Board Member at Celal Bayar University\n",
      "    0.100  Aspiring Human Resources Specialist\n",
      "    0.100  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.100  HR Senior Specialist\n",
      "    0.100  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.100  Seeking Human Resources HRIS and Generalist Positions\n",
      "Prompt tokens: 1583\n",
      "\n",
      "Query: backend developer\n",
      "    0.200  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.100  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.100  Aspiring Human Resources Professional\n",
      "    0.100  People Development Coordinator at Ryan\n",
      "    0.100  Advisory Board Member at Celal Bayar University\n",
      "    0.100  Aspiring Human Resources Specialist\n",
      "    0.100  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.100  HR Senior Specialist\n",
      "    0.100  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.100  Seeking Human Resources HRIS and Generalist Positions\n",
      "Prompt tokens: 1583\n",
      "\n",
      "Query: product manager\n",
      "    0.300  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.250  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.250  People Development Coordinator at Ryan\n",
      "    0.250  Aspiring Human Resources Specialist\n",
      "    0.200  Aspiring Human Resources Professional\n",
      "    0.200  Advisory Board Member at Celal Bayar University\n",
      "    0.200  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.200  HR Senior Specialist\n",
      "    0.200  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.200  Seeking Human Resources HRIS and Generalist Positions\n",
      "Saved: outputs\\llm\\llm_top10__gemma-2-2b-it__all_queries.csv\n"
     ]
    }
   ],
   "source": [
    "top10_gemma, path_gemma = run_query_full(\n",
    "    QUERIES,\n",
    "    model_tag=\"gemma-2-2b-it\",\n",
    "    build_prompt_fn=build_prompt_all_chat_gemma\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faf58ee",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff2edcb",
   "metadata": {},
   "source": [
    "### Step 7 - Experience with another small LLM: **Qwen2.5-3B-Instruct from Qwen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a40cf0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measure memory usage before and after freeing it\n",
      "\n",
      "Before:\n",
      "allocated: 4995.6 MiB | reserved: 5710.0 MiB | total: 11,264 MiB\n",
      "\n",
      "After:\n",
      "allocated: 8.1 MiB | reserved: 20.0 MiB | total: 11,264 MiB\n"
     ]
    }
   ],
   "source": [
    "# Print memory allocation before freeing it\n",
    "print(\"Measure memory usage before and after freeing it\")\n",
    "print_vram(\"Before:\\n\")\n",
    "\n",
    "# move model to CPU + delete big refs\n",
    "try: mdl.to(\"cpu\")\n",
    "except: pass\n",
    "# free memory\n",
    "for name in (\"pipe\",\"mdl\",\"tok\",\"inputs\",\"gen\"):\n",
    "    if name in globals(): del globals()[name]\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n",
    "print_vram(\"After:\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "552fa1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e091d4ad98487f8b56354fa87c4060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_ID = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
    "mdl = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    dtype=torch.float16 if torch.cuda.is_available() else None,\n",
    ").to(\"cuda\" if torch.cuda.is_available() else \"cpu\").eval()\n",
    "\n",
    "if tok.pad_token_id is None:\n",
    "    tok.pad_token = tok.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "079e660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qwen-specific prompt builder (ChatML-friendly, explicit N, hard stop)\n",
    "def build_prompt_all_chat_qwen(query: str, titles: list[str]) -> str:\n",
    "    n = len(titles)\n",
    "    lines = \"\\n\".join(f\"{i}) {t}\" for i, t in enumerate(titles, start=1))\n",
    "\n",
    "    rubric = (\n",
    "        \"You are a recruiter scoring job-title similarity to the query.\\n\"\n",
    "        \"Score each candidate with an integer 0–100 using the FULL scale:\\n\"\n",
    "        \"  90–100 = exact/near-exact role match\\n\"\n",
    "        \"  70–89  = same discipline or very similar role\\n\"\n",
    "        \"  40–69  = related/adjacent\\n\"\n",
    "        \"  20–39  = mostly unrelated\\n\"\n",
    "        \"  0–19   = completely unrelated\\n\"\n",
    "        \"Rules:\\n\"\n",
    "        \" - Prefer same functional domain as the query.\\n\"\n",
    "        \" - If the query is technical (data/ML/backend), HR/People titles are mostly unrelated.\\n\"\n",
    "        \" - Titles with 'Student' or 'Aspiring' get lower scores unless they explicitly match the role.\\n\"\n",
    "        f\"Output EXACTLY {n} integers, one per line, in the SAME ORDER as the candidates.\\n\"\n",
    "        \"No words, no commas, no numbering, no punctuation.\\n\"\n",
    "        f\"After the {n}th line, output the token <END> and stop.\"\n",
    "    )\n",
    "\n",
    "    # very small one-shot to demonstrate format (3 lines + <END>)\n",
    "    # keep it generic so it transfers across queries\n",
    "    example = (\n",
    "        \"Example (3 candidates):\\n\"\n",
    "        \"Candidates:\\n\"\n",
    "        \"1) Senior Data Scientist\\n\"\n",
    "        \"2) HR Coordinator\\n\"\n",
    "        \"3) Retail Cashier\\n\"\n",
    "        \"Expected output:\\n\"\n",
    "        \"95\\n\"\n",
    "        \"20\\n\"\n",
    "        \"0\\n\"\n",
    "        \"<END>\"\n",
    "    )\n",
    "\n",
    "    user_text = (\n",
    "        f\"{rubric}\\n\\n\"\n",
    "        f'Query: \"{query}\"\\n\\n'\n",
    "        f\"Candidates:\\n{lines}\\n\\n\"\n",
    "        f\"{example}\"\n",
    "    )\n",
    "\n",
    "    # Qwen supports system; if anything fails, fall back to user-only.\n",
    "    msgs_sys = [\n",
    "        {\"role\": \"system\", \"content\": \"You are precise and output only the requested numbers.\"},\n",
    "        {\"role\": \"user\",   \"content\": user_text},\n",
    "    ]\n",
    "    msgs_user = [{\"role\": \"user\", \"content\": user_text}]  # fallback\n",
    "\n",
    "    try:\n",
    "        return tok.apply_chat_template(msgs_sys, tokenize=False, add_generation_prompt=True)\n",
    "    except Exception:\n",
    "        return tok.apply_chat_template(msgs_user, tokenize=False, add_generation_prompt=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23b2a4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt tokens: 1774\n",
      "\n",
      "Query: data scientist\n",
      "    0.900  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.900  People Development Coordinator at Ryan\n",
      "    0.900  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.900  People Development Coordinator at Ryan\n",
      "    0.900  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.900  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.900  Human Resources Coordinator at InterContinental Buckhead Atlanta\n",
      "    0.900  Seeking Human Resources HRIS and Generalist Positions\n",
      "    0.900  People Development Coordinator at Ryan\n",
      "    0.900  Student at Humber College and Aspiring Human Resources Generalist\n",
      "Prompt tokens: 1775\n",
      "\n",
      "Query: machine learning engineer\n",
      "    0.900  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.400  People Development Coordinator at Ryan\n",
      "    0.000  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.000  Aspiring Human Resources Professional\n",
      "    0.000  Advisory Board Member at Celal Bayar University\n",
      "    0.000  Aspiring Human Resources Specialist\n",
      "    0.000  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.000  HR Senior Specialist\n",
      "    0.000  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.000  Seeking Human Resources HRIS and Generalist Positions\n",
      "Prompt tokens: 1774\n",
      "\n",
      "Query: backend developer\n",
      "    0.900  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.900  People Development Coordinator at Ryan\n",
      "    0.900  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.900  People Development Coordinator at Ryan\n",
      "    0.900  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.900  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.900  Human Resources Coordinator at InterContinental Buckhead Atlanta\n",
      "    0.900  Seeking Human Resources HRIS and Generalist Positions\n",
      "    0.900  People Development Coordinator at Ryan\n",
      "    0.900  Student at Humber College and Aspiring Human Resources Generalist\n",
      "Prompt tokens: 1774\n",
      "\n",
      "Query: product manager\n",
      "    0.900  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.900  People Development Coordinator at Ryan\n",
      "    0.900  Student at Humber College and Aspiring Human Resources Generalist\n",
      "    0.900  People Development Coordinator at Ryan\n",
      "    0.900  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "    0.900  Native English Teacher at EPIK (English Program in Korea)\n",
      "    0.900  Human Resources Coordinator at InterContinental Buckhead Atlanta\n",
      "    0.900  Seeking Human Resources HRIS and Generalist Positions\n",
      "    0.900  People Development Coordinator at Ryan\n",
      "    0.900  Student at Humber College and Aspiring Human Resources Generalist\n",
      "Saved: outputs\\llm\\llm_top10__qwen2.5-3b-instruct__all_queries.csv\n"
     ]
    }
   ],
   "source": [
    "top10_qwen, path_qwen = run_query_full(\n",
    "    QUERIES,\n",
    "    model_tag=\"qwen2.5-3b-instruct\",\n",
    "    build_prompt_fn=build_prompt_all_chat_qwen\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4f46ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39fba51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pot_Tals_LLM_Env",
   "language": "python",
   "name": "pot-tals_llm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
