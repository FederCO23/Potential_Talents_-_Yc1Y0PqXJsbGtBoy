{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b22c4196",
   "metadata": {},
   "source": [
    "## Potential Talents - Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2956a14e",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716b8abb",
   "metadata": {},
   "source": [
    "### Objectives:\n",
    "\n",
    "Retrieve the most similar job titles to a query using several embedding families, and compare their rankings.\n",
    "\n",
    "### Summary:\n",
    "\n",
    "   0) Setup & Data\n",
    "   1) Load custom SGNS embeddings (from Part 2, mini-Word2Vec)\n",
    "   2) Tokenization for titles (keep it simple & consistent)\n",
    "   3) Custom mini-Word2Vec (my SGNS from part 2)\n",
    "   4) Word2Vec (Google)\n",
    "   5) GloVe (Stanford)\n",
    "   6) FastText (Meta)\n",
    "   7) BERT (Google; mean/CLS pooling)\n",
    "   8) Sentece-BERT (SBERT; sentence-level embeddings)\n",
    "   9) Ranking & side-by-side comparison (qualitative / quantitative)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e935cd",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13000046",
   "metadata": {},
   "source": [
    "## 0. Setup & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2569f4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9c2184b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: e:\\Devs\\pyEnv-1\\venvs\\Pot-Tals_3_env\\Scripts\\python.exe\n",
      "torch file: e:\\Devs\\pyEnv-1\\venvs\\Pot-Tals_3_env\\Lib\\site-packages\\torch\\__init__.py\n",
      "torch version: 2.6.0+cu124\n",
      "torch.version.cuda: 12.4\n",
      "cuda available: True\n"
     ]
    }
   ],
   "source": [
    "print(\"python:\", sys.executable)\n",
    "print(\"torch file:\", torch.__file__)\n",
    "print(\"torch version:\", torch.__version__)\n",
    "print(\"torch.version.cuda:\", torch.version.cuda)\n",
    "print(\"cuda available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "880ab4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 23\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b55d5b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104,\n",
       " ['2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional',\n",
       "  'Native English Teacher at EPIK (English Program in Korea)',\n",
       "  'Aspiring Human Resources Professional',\n",
       "  'People Development Coordinator at Ryan',\n",
       "  'Advisory Board Member at Celal Bayar University'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/potential_talents.csv\")\n",
    "titles = df[\"job_title\"].astype(str).tolist()\n",
    "len(titles), titles[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004ca327",
   "metadata": {},
   "source": [
    "## 1. Custom SGNS embeddings (from Part 2, mini-Word2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afffda27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SGNS checkpoint (from Part 2)\n",
    "ckpt_path = \"checkpoints/sgns_text8.pt\"\n",
    "ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39debf4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model_state', 'itos', 'config'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "497a75aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embed_dim': 300}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt['config'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91765b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'aa', 'aaa', 'aaaa', 'aaai', 'aaas', 'aac', 'aachen', 'aafc', 'aage']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt['itos'][:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90d2d9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'collections.OrderedDict'>\n",
      "odict_keys(['emb_in.weight', 'emb_out.weight'])\n"
     ]
    }
   ],
   "source": [
    "print(type(ckpt['model_state']))\n",
    "print(ckpt['model_state'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "639e306d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([71290, 300])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos = ckpt[\"itos\"]\n",
    "stoi = {w:i for i,w in enumerate(itos)}\n",
    "\n",
    "E_in  = ckpt[\"model_state\"][\"emb_in.weight\"].detach().float()   # [|V|, D]\n",
    "E_out = ckpt[\"model_state\"][\"emb_out.weight\"].detach().float()  # [|V|, D]\n",
    "\n",
    "# as in Part2, use the avg \n",
    "E_comb = 0.5 * (E_in + E_out)\n",
    "E_comb = E_comb / (E_comb.norm(dim=1, keepdim=True) + 1e-12)\n",
    "\n",
    "E_comb.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae81898e",
   "metadata": {},
   "source": [
    "## 2) Tokenization for titles (keep it simple & consistent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91696596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, unicodedata\n",
    "import nltk\n",
    "_ = nltk.download('punkt', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52c6718a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex for separator chars to normalize/split title delimiters\n",
    "SEP_RE = re.compile(r\"[|/\\\\•·–—\\-]+\")      \n",
    "\n",
    "def canonicalize_title(s: str, strip_org_tail: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Light canonicalization (cleaning) that preserves full sentence content:\n",
    "    - Unicode NFKC normalization, trim, lowercase\n",
    "    - Normalize separators (& -> 'and')\n",
    "    - Collapse whitespace\n",
    "    Input: string → Output: cleaned string.\n",
    "    \"\"\"\n",
    "    \n",
    "    # if the input isn’t a string, return an empty string\n",
    "    if not isinstance(s, str): \n",
    "        return \"\"\n",
    "    \n",
    "    # Unicode normalization form NFKC + strip + lowercase\n",
    "    s = unicodedata.normalize(\"NFKC\", s).strip().lower()\n",
    "    s = SEP_RE.sub(\" \", s)                 # “hr manager | engie” -> “hr manager  engie”\n",
    "    s = s.replace(\"&\", \" and \")\n",
    "        \n",
    "    # collapses any run of whitespace (spaces, tabs) to a single space\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efb7b6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple, stable regex tokenizer: keep a–z sequences (no stopword/org stripping)\n",
    "TOKEN_RE = re.compile(r\"[a-z]+\")\n",
    "\n",
    "def tokenize_title(s: str, drop_org_like=True) -> list[str]:\n",
    "    \"\"\"\n",
    "    Canonicalize, then regex-tokenize. No stopword/org filtering.\n",
    "    Input: string → Output: list of tokens.\n",
    "    \"\"\" \n",
    "    s = canonicalize_title(s)\n",
    "    # every sequence of [a-z]+ becomes one token\n",
    "    toks = TOKEN_RE.findall(s)\n",
    "    \n",
    "    return toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a318007e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>title_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>2019 c.t. bauer college of business graduate (...</td>\n",
       "      <td>[c, t, bauer, college, of, business, graduate,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>native english teacher at epik (english progra...</td>\n",
       "      <td>[native, english, teacher, at, epik, english, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>aspiring human resources professional</td>\n",
       "      <td>[aspiring, human, resources, professional]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>people development coordinator at ryan</td>\n",
       "      <td>[people, development, coordinator, at, ryan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>advisory board member at celal bayar university</td>\n",
       "      <td>[advisory, board, member, at, celal, bayar, un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>aspiring human resources specialist</td>\n",
       "      <td>[aspiring, human, resources, specialist]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Student at Humber College and Aspiring Human R...</td>\n",
       "      <td>student at humber college and aspiring human r...</td>\n",
       "      <td>[student, at, humber, college, and, aspiring, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HR Senior Specialist</td>\n",
       "      <td>hr senior specialist</td>\n",
       "      <td>[hr, senior, specialist]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Student at Humber College and Aspiring Human R...</td>\n",
       "      <td>student at humber college and aspiring human r...</td>\n",
       "      <td>[student, at, humber, college, and, aspiring, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Seeking Human Resources HRIS and Generalist Po...</td>\n",
       "      <td>seeking human resources hris and generalist po...</td>\n",
       "      <td>[seeking, human, resources, hris, and, general...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0  2019 C.T. Bauer College of Business Graduate (...   \n",
       "1  Native English Teacher at EPIK (English Progra...   \n",
       "2              Aspiring Human Resources Professional   \n",
       "3             People Development Coordinator at Ryan   \n",
       "4    Advisory Board Member at Celal Bayar University   \n",
       "5                Aspiring Human Resources Specialist   \n",
       "6  Student at Humber College and Aspiring Human R...   \n",
       "7                               HR Senior Specialist   \n",
       "8  Student at Humber College and Aspiring Human R...   \n",
       "9  Seeking Human Resources HRIS and Generalist Po...   \n",
       "\n",
       "                                          title_text  \\\n",
       "0  2019 c.t. bauer college of business graduate (...   \n",
       "1  native english teacher at epik (english progra...   \n",
       "2              aspiring human resources professional   \n",
       "3             people development coordinator at ryan   \n",
       "4    advisory board member at celal bayar university   \n",
       "5                aspiring human resources specialist   \n",
       "6  student at humber college and aspiring human r...   \n",
       "7                               hr senior specialist   \n",
       "8  student at humber college and aspiring human r...   \n",
       "9  seeking human resources hris and generalist po...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [c, t, bauer, college, of, business, graduate,...  \n",
       "1  [native, english, teacher, at, epik, english, ...  \n",
       "2         [aspiring, human, resources, professional]  \n",
       "3       [people, development, coordinator, at, ryan]  \n",
       "4  [advisory, board, member, at, celal, bayar, un...  \n",
       "5           [aspiring, human, resources, specialist]  \n",
       "6  [student, at, humber, college, and, aspiring, ...  \n",
       "7                           [hr, senior, specialist]  \n",
       "8  [student, at, humber, college, and, aspiring, ...  \n",
       "9  [seeking, human, resources, hris, and, general...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build shared columns (used by ALL embedding families)\n",
    "df[\"title_text\"] = df[\"job_title\"].apply(canonicalize_title)   # full sentence, orgs kept\n",
    "df[\"tokens\"]     = df[\"title_text\"].apply(tokenize_title)      # tokens, same for every embedding family\n",
    "\n",
    "# Peek\n",
    "df[[\"job_title\", \"title_text\", \"tokens\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451437b3",
   "metadata": {},
   "source": [
    "## 3) Custom mini-Word2Vec: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2eb592",
   "metadata": {},
   "source": [
    "This implementation follows **Skip-Gram with Negative Sampling** in PyTorch with two embedding tables: $E_{\\text{in}}$ (centers) and $E_{\\text{out}}$ (contexts). For each (center, positive) pair, it samples $K$ negatives and optimizes the SGNS objective above. To form final word vectors, it uses the **average** of the two tables,\n",
    "$$\n",
    "E_{\\text{comb}}=\\tfrac{1}{2}\\big(E_{\\text{in}}+E_{\\text{out}}\\big),\n",
    "$$\n",
    "then encodes a title by averaging its in-vocab word vectors and searches via **cosine similarity**. This keeps training and inference lightweight while capturing useful semantic structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed40e2f",
   "metadata": {},
   "source": [
    "### 3.1) Encode a title as the mean of its word vectorsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed440d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = E_comb\n",
    "\n",
    "@torch.no_grad()\n",
    "def encode_tokens_mean(tokens: list[str], E: torch.Tensor, stoi: dict) -> torch.Tensor | None:\n",
    "    idxs = [stoi[t] for t in tokens if t in stoi]\n",
    "    if not idxs:\n",
    "        return None\n",
    "    v = E[idxs].mean(dim=0)                 # [D]\n",
    "    return v / (v.norm() + 1e-12)\n",
    "\n",
    "@torch.no_grad()\n",
    "def encode_title_mean(text: str, E: torch.Tensor, stoi: dict) -> torch.Tensor | None:\n",
    "    return encode_tokens_mean(tokenize_title(text), E, stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64e75448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded titles: torch.Size([104, 300]) kept rows: 104 of 104\n"
     ]
    }
   ],
   "source": [
    "# Rebuild title matrix using df[\"tokens\"] (shared preprocessing)\n",
    "vecs, keep_idx = [], []\n",
    "for i, toks in enumerate(df[\"tokens\"]):\n",
    "    v = encode_tokens_mean(toks, E, stoi)\n",
    "    if v is not None:\n",
    "        vecs.append(v); keep_idx.append(i)\n",
    "\n",
    "X_sgns_mean = torch.stack(vecs)  # [N_kept, D], rows are L2-normalized\n",
    "print(\"encoded titles:\", X_sgns_mean.shape, \"kept rows:\", len(keep_idx), \"of\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d79775b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0102, -0.0397,  0.0605, -0.0698, -0.0451, -0.0469,  0.0385, -0.0740,\n",
       "         0.0400, -0.0557, -0.0359,  0.0659,  0.0657, -0.0421, -0.0308,  0.0900,\n",
       "         0.0729,  0.0266,  0.0625, -0.0746,  0.0684, -0.0777, -0.0475, -0.0569,\n",
       "        -0.0385, -0.0662,  0.0363, -0.0352,  0.0336, -0.0520, -0.0362, -0.0415,\n",
       "        -0.0313, -0.0825,  0.0237, -0.0868,  0.0350, -0.0584, -0.0503, -0.0151,\n",
       "        -0.0609,  0.0724, -0.0663, -0.0268,  0.0566, -0.0289, -0.0805,  0.0526,\n",
       "         0.0408, -0.0282,  0.0904,  0.0533, -0.0580, -0.0389,  0.0214,  0.0406,\n",
       "         0.0169, -0.0786,  0.0762,  0.0449,  0.0346,  0.0671, -0.1035,  0.0652,\n",
       "         0.0573, -0.0475, -0.0698,  0.0104,  0.0614, -0.0513,  0.0431, -0.0888,\n",
       "        -0.0016,  0.0719,  0.0592,  0.0448,  0.0400,  0.0439,  0.0604, -0.0345,\n",
       "         0.0523, -0.0517, -0.0570, -0.0236,  0.0325, -0.0366, -0.0302, -0.0621,\n",
       "        -0.0702, -0.0622, -0.0323, -0.0287,  0.0569,  0.0271,  0.0420,  0.0780,\n",
       "        -0.0658,  0.0758,  0.0521,  0.0426,  0.0299,  0.0597, -0.0786,  0.0804,\n",
       "        -0.0748, -0.0275,  0.0472,  0.0487,  0.0699, -0.0314, -0.0345, -0.0626,\n",
       "        -0.0345,  0.0687, -0.0885,  0.0468,  0.0726,  0.0732, -0.0620,  0.0432,\n",
       "         0.0266, -0.0394, -0.0282, -0.0687,  0.0406, -0.0722,  0.0515, -0.0379,\n",
       "         0.0252, -0.1001, -0.0929,  0.0705, -0.0277, -0.0819, -0.0234, -0.0412,\n",
       "        -0.0918,  0.1023,  0.0338,  0.0710, -0.0534,  0.0870, -0.0699, -0.0730,\n",
       "         0.0661,  0.0364,  0.0306, -0.0689,  0.0892, -0.0422, -0.0093,  0.0844,\n",
       "         0.0496,  0.0579, -0.0266, -0.0688,  0.0444,  0.0728, -0.0776, -0.0894,\n",
       "         0.0387,  0.0743, -0.0809, -0.0457, -0.0650, -0.0772,  0.0247,  0.0790,\n",
       "         0.0506, -0.0308,  0.0349, -0.0362,  0.0348, -0.0693, -0.0389,  0.0465,\n",
       "         0.0470, -0.0586, -0.0598,  0.0473,  0.0758, -0.0720,  0.0289,  0.0392,\n",
       "        -0.0378,  0.0597,  0.0788,  0.0751,  0.0214,  0.0608, -0.0691,  0.0214,\n",
       "         0.0455, -0.0320,  0.0493,  0.0341, -0.0379,  0.1041, -0.0424,  0.0161,\n",
       "         0.0492,  0.0637,  0.0597,  0.0620, -0.0434, -0.0236,  0.0477, -0.0237,\n",
       "        -0.0682,  0.0452,  0.0442, -0.0725,  0.0342, -0.0523, -0.0533,  0.0629,\n",
       "        -0.0446, -0.0480,  0.0883, -0.0760,  0.0700, -0.0612, -0.0141,  0.0758,\n",
       "         0.0797, -0.0482, -0.0304,  0.0853,  0.0326, -0.0833, -0.0420, -0.0892,\n",
       "        -0.0463,  0.0208,  0.0674,  0.0386,  0.0497, -0.0689,  0.0261,  0.0595,\n",
       "        -0.0399,  0.0814,  0.0603,  0.0140,  0.0383,  0.0463,  0.0544, -0.0668,\n",
       "        -0.0356, -0.0514, -0.0791,  0.0438,  0.0260,  0.0501, -0.0596,  0.0181,\n",
       "        -0.1052,  0.0537,  0.0424, -0.0368,  0.0720,  0.0241,  0.0703, -0.0546,\n",
       "         0.0471, -0.0681, -0.0577,  0.0319,  0.0740, -0.0880,  0.0383, -0.0841,\n",
       "        -0.0774,  0.0646, -0.0643,  0.0415, -0.0445, -0.0687,  0.0398,  0.0274,\n",
       "         0.0769, -0.0564, -0.0798,  0.0925,  0.0698, -0.0779,  0.0599, -0.0763,\n",
       "         0.0881, -0.0406, -0.0684, -0.0583, -0.0676,  0.0593, -0.0615, -0.0429,\n",
       "         0.0058,  0.0361, -0.0552,  0.0895])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sgns_mean[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1571ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bed2898a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(300), X_sgns_mean[0], color='skyblue', edgecolor='black')\n",
    "plt.title(\"custom mini-word2vec - vector values\")\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"values\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8808fea8",
   "metadata": {},
   "source": [
    "### 3.2) Cosine search over titles (dot product of normalized vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03f2da4",
   "metadata": {},
   "source": [
    "Cosine search over titles: one function we can reuse for SGNS(mini-Word2Vec)/GloVe/FastText by swapping E, stoi, X, keep_idx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a534e6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search using cosine similarity\n",
    "@torch.no_grad()\n",
    "def search_titles(query: str,\n",
    "                  X: torch.Tensor,\n",
    "                  E: torch.Tensor,\n",
    "                  stoi: dict,\n",
    "                  keep_idx: list[int],\n",
    "                  df: pd.DataFrame,\n",
    "                  topk: int = 10,\n",
    "                  dedupe: bool = True):\n",
    "    \n",
    "    # encode query with the SAME tokenizer\n",
    "    q_tokens = tokenize_title(query)\n",
    "    q = encode_tokens_mean(q_tokens, E, stoi)\n",
    "    if q is None:\n",
    "        return [], \"Query has no in-vocab tokens.\"\n",
    "\n",
    "    sims = (X @ q)                                      # cosine = dot (rows normalized)\n",
    "    top = torch.topk(sims, k=min(topk*3, sims.numel())) # oversample if deduping\n",
    "\n",
    "    rows = []\n",
    "    seen = set()\n",
    "    for idx in top.indices.tolist():\n",
    "        row_id = keep_idx[idx]\n",
    "        title_str = df.loc[row_id, \"job_title\"]            # <-- key used for dedupe\n",
    "        if dedupe:\n",
    "            if title_str in seen:                          # <-- duplicates dropped\n",
    "                continue\n",
    "            seen.add(title_str)\n",
    "        rows.append((title_str, float(sims[idx].item())))\n",
    "        if len(rows) == topk:\n",
    "            break\n",
    "    return rows, None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d94e738e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: data scientist\n",
      "   0.793  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "   0.748  Junior MES Engineer| Information Systems\n",
      "   0.731  SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR\n",
      "   0.729  Human Resources professional for the world leader in GIS software\n",
      "   0.727  Business Intelligence and Analytics at Travelers\n",
      "   0.714  Aspiring Human Resources Manager | Graduating May 2020 | Seeking an Entry-Level Human Resources Position in St. Louis\n",
      "   0.706  Undergraduate Research Assistant at Styczynski Lab\n",
      "   0.706  Student at Indiana University Kokomo - Business Management - \n",
      "Retail Manager at Delphi Hardware and Paint\n",
      "   0.702  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "   0.701  Business Management Major and Aspiring Human Resources Manager\n",
      "\n",
      "Query: machine learning engineer\n",
      "   0.825  Junior MES Engineer| Information Systems\n",
      "   0.791  Student at Indiana University Kokomo - Business Management - \n",
      "Retail Manager at Delphi Hardware and Paint\n",
      "   0.790  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "   0.784  Business Intelligence and Analytics at Travelers\n",
      "   0.778  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "   0.773  Human Resources professional for the world leader in GIS software\n",
      "   0.762  Aspiring Human Resources Professional | Passionate about helping to create an inclusive and engaging work environment\n",
      "   0.759  Aspiring Human Resources Management student seeking an internship\n",
      "   0.758  Undergraduate Research Assistant at Styczynski Lab\n",
      "   0.757  Native English Teacher at EPIK (English Program in Korea)\n",
      "\n",
      "Query: backend developer\n",
      "   0.781  Student at Indiana University Kokomo - Business Management - \n",
      "Retail Manager at Delphi Hardware and Paint\n",
      "   0.753  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "   0.753  Business Management Major and Aspiring Human Resources Manager\n",
      "   0.752  Junior MES Engineer| Information Systems\n",
      "   0.752  Human Resources professional for the world leader in GIS software\n",
      "   0.747  Experienced Retail Manager and aspiring Human Resources Professional\n",
      "   0.734  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional\n",
      "   0.729  HR Senior Specialist\n",
      "   0.727  People Development Coordinator at Ryan\n",
      "   0.721  Aspiring Human Resources Manager | Graduating May 2020 | Seeking an Entry-Level Human Resources Position in St. Louis\n",
      "\n",
      "Query: product manager\n",
      "   0.747  Business Management Major and Aspiring Human Resources Manager\n",
      "   0.736  Experienced Retail Manager and aspiring Human Resources Professional\n",
      "   0.731  Student at Indiana University Kokomo - Business Management - \n",
      "Retail Manager at Delphi Hardware and Paint\n",
      "   0.711  People Development Coordinator at Ryan\n",
      "   0.709  SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR\n",
      "   0.709  RRP Brand Portfolio Executive at JTI (Japan Tobacco International)\n",
      "   0.707  Aspiring Human Resources Manager | Graduating May 2020 | Seeking an Entry-Level Human Resources Position in St. Louis\n",
      "   0.702  Human Resources professional for the world leader in GIS software\n",
      "   0.701  HR Manager at Endemol Shine North America\n",
      "   0.700  Information Systems Specialist and Programmer with a love for data and organization.\n"
     ]
    }
   ],
   "source": [
    "# quick test\n",
    "for q in [\"data scientist\", \"machine learning engineer\", \"backend developer\", \"product manager\"]:\n",
    "    res, err = search_titles(q, X_sgns_mean, E, stoi, keep_idx, df, topk=10, dedupe=True)\n",
    "    print(f\"\\nQuery: {q}\")\n",
    "    if err: print(\"  \", err)\n",
    "    else:\n",
    "        for t, s in res:\n",
    "            print(f\"  {s: .3f}  {t}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fc185b",
   "metadata": {},
   "source": [
    "## 4) Experiment with the GoogleNews Word2Vec vectors (Google, 2013)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee950f0",
   "metadata": {},
   "source": [
    "Word2Vec learns dense vectors so that words sharing contexts have nearby embeddings. In the **skip-gram** view, for a center word $w_t$ it predicts surrounding words $w_{t+j}$. Training usually uses **negative sampling** to replace the full softmax with a small binary task per pair. The classic per-example objective is\n",
    "$$\n",
    "\\log \\sigma(u_{w_t}^\\top v_{w_{t+j}})\\;+\\;\\sum_{k=1}^{K}\\log \\sigma\\!\\left(-\\,u_{w_t}^\\top v_{n_k}\\right),\n",
    "$$\n",
    "where $u$ is the input (center) embedding, $v$ the output (context) embedding, and $n_k$ are sampled “negative” words. The GoogleNews model provides pretrained 300-d vectors trained on a very large corpus.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94077d1",
   "metadata": {},
   "source": [
    "A) Using Gensim’s downloader (auto-download, ~1.6GB):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0077b0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "366ee482",
   "metadata": {},
   "outputs": [],
   "source": [
    "W2V_PATH = r\"./data/GoogleNews-vectors-negative300.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "252c51c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2v vocab: 3000000 dim: 300\n"
     ]
    }
   ],
   "source": [
    "# Load the binary GoogleNews KeyedVectors\n",
    "w2v = KeyedVectors.load_word2vec_format(W2V_PATH, binary=True)\n",
    "print(\"w2v vocab:\", len(w2v), \"dim:\", w2v.vector_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416e2d3b",
   "metadata": {},
   "source": [
    "### 4.1) Encode tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59646ffe",
   "metadata": {},
   "source": [
    "Keep the same functions (encode_tokens_mean, encode_title_mean, search_titles) and the same flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e32ef1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "needed tokens in w2v: 174\n"
     ]
    }
   ],
   "source": [
    "# 1) Collect the words we actually need from the dataset\n",
    "needed = sorted({t for toks in df[\"tokens\"] for t in toks if t in w2v.key_to_index})\n",
    "needed_not_in_w2v = sorted({t for toks in df[\"tokens\"] for t in toks if t not in w2v.key_to_index})\n",
    "print(\"needed tokens in w2v:\", len(needed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ced472e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Build stoi and E (normalized rows) for just those words\n",
    "stoi_w2v = w2v.key_to_index\n",
    "E_w2v = torch.from_numpy(w2v.vectors)              # shares memory\n",
    "E_w2v = E_w2v / (E_w2v.norm(dim=1, keepdim=True)+1e-12)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "76cda7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3000000, 300]) 3000000\n"
     ]
    }
   ],
   "source": [
    "# E_w2v (torch) + stoi_w2v (dict) match the previous SGNS interface\n",
    "print(E_w2v.shape, len(stoi_w2v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86e41f9",
   "metadata": {},
   "source": [
    "Encode tokens per title and then calculate the mean value for the title embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a207157a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2v encoded titles: torch.Size([104, 300])\n"
     ]
    }
   ],
   "source": [
    "vecs_w2v, keep_idx_w2v = [], []\n",
    "for i, toks in enumerate(df[\"tokens\"]):\n",
    "    v = encode_tokens_mean(toks, E_w2v, stoi_w2v) \n",
    "    if v is not None:\n",
    "        vecs_w2v.append(v); keep_idx_w2v.append(i)\n",
    "\n",
    "X_w2v_mean = torch.stack(vecs_w2v)   # rows already normalized\n",
    "print(\"w2v encoded titles:\", X_w2v_mean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a7484cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: data scientist\n",
      "   0.516  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "   0.450  Undergraduate Research Assistant at Styczynski Lab\n",
      "   0.447  Junior MES Engineer| Information Systems\n",
      "   0.346  Human Resources Specialist at Luxottica\n",
      "   0.340  Business Intelligence and Analytics at Travelers\n",
      "   0.328  Aspiring Human Resources Specialist\n",
      "   0.318  Liberal Arts Major. Aspiring Human Resources Analyst.\n",
      "   0.314  Senior Human Resources Business Partner at Heil Environmental\n",
      "   0.313  SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR\n",
      "   0.305  Bachelor of Science in Biology from Victoria University of Wellington\n",
      "\n",
      "Query: machine learning engineer\n",
      "   0.524  Junior MES Engineer| Information Systems\n",
      "   0.492  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "   0.393  Aspiring Human Resources Professional | Passionate about helping to create an inclusive and engaging work environment\n",
      "   0.383  Human Resources professional for the world leader in GIS software\n",
      "   0.373  Aspiring Human Resources Management student seeking an internship\n",
      "   0.368  Aspiring Human Resources Professional | An energetic and Team-Focused Leader\n",
      "   0.365  Aspiring Human Resources Specialist\n",
      "   0.352  Aspiring Human Resources Manager, seeking internship in Human Resources.\n",
      "   0.350  Undergraduate Research Assistant at Styczynski Lab\n",
      "   0.345  Student at Indiana University Kokomo - Business Management - \n",
      "Retail Manager at Delphi Hardware and Paint\n",
      "\n",
      "Query: backend developer\n",
      "   0.370  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "   0.354  Student at Indiana University Kokomo - Business Management - \n",
      "Retail Manager at Delphi Hardware and Paint\n",
      "   0.349  Business Management Major and Aspiring Human Resources Manager\n",
      "   0.334  Junior MES Engineer| Information Systems\n",
      "   0.302  Experienced Retail Manager and aspiring Human Resources Professional\n",
      "   0.294  Business Intelligence and Analytics at Travelers\n",
      "   0.294  Human Resources professional for the world leader in GIS software\n",
      "   0.283  SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR\n",
      "   0.280  Human Resources Management Major\n",
      "   0.259  Human Resources|\n",
      "Conflict Management|\n",
      "Policies & Procedures|Talent Management|Benefits & Compensation\n",
      "\n",
      "Query: product manager\n",
      "   0.532  Business Management Major and Aspiring Human Resources Manager\n",
      "   0.492  Student at Indiana University Kokomo - Business Management - \n",
      "Retail Manager at Delphi Hardware and Paint\n",
      "   0.480  RRP Brand Portfolio Executive at JTI (Japan Tobacco International)\n",
      "   0.478  Experienced Retail Manager and aspiring Human Resources Professional\n",
      "   0.471  SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR\n",
      "   0.409  Senior Human Resources Business Partner at Heil Environmental\n",
      "   0.404  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "   0.379  People Development Coordinator at Ryan\n",
      "   0.378  Director Human Resources  at EY\n",
      "   0.376  Retired Army National Guard Recruiter, office manager,  seeking a position in Human Resources.\n"
     ]
    }
   ],
   "source": [
    "# quick test\n",
    "for q in [\"data scientist\", \"machine learning engineer\", \"backend developer\", \"product manager\"]:\n",
    "    res, err = search_titles(q, X_w2v_mean, E_w2v, stoi_w2v, keep_idx_w2v, df, topk=10, dedupe=True)\n",
    "    print(f\"\\nQuery: {q}\")\n",
    "    if err: print(\"  \", err)\n",
    "    else:\n",
    "        for t, s in res:\n",
    "            print(f\"  {s: .3f}  {t}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f3efcc",
   "metadata": {},
   "source": [
    "## 5) Experiment with the GloVE vectors (Stanford, 2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d02f00d",
   "metadata": {},
   "source": [
    "GloVe is a **global co-occurrence** method: it builds a word–word co-occurrence matrix $X_{ij}$ from a large corpus and learns embeddings by regressing the **log counts**. The weighted least-squares loss is\n",
    "$$\n",
    "J=\\sum_{i,j} f(X_{ij})\\Big(u_i^\\top v_j + b_i + \\tilde b_j - \\log X_{ij}\\Big)^2,\n",
    "$$\n",
    "where $f(\\cdot)$ down-weights rare and extremely frequent pairs. This blends global matrix-factorization flavor (like SVD) with the efficiency of local windowing, producing robust, widely used embeddings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42922dbb",
   "metadata": {},
   "source": [
    "#### 5.1) Collect the words we actually need (from the job titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "64efefa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words actually appearing in your dataset tokens (all lowercased already)\n",
    "needed_glove = sorted({t for toks in df[\"tokens\"] for t in toks})\n",
    "len(needed_glove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e7eba32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_DIR = \"./data/\"\n",
    "GLOVE_TXT = os.path.join(GLOVE_DIR, \"glove.6B.300d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6f11940a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded words: 191 dim: 300\n"
     ]
    }
   ],
   "source": [
    "vecs_glove_map = {}\n",
    "dim_glove = None\n",
    "\n",
    "with open(GLOVE_TXT, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        parts = line.rstrip().split(\" \")\n",
    "        w = parts[0]\n",
    "        if w in needed_glove:\n",
    "            v = np.asarray(parts[1:], dtype=np.float32)\n",
    "            if dim_glove is None:\n",
    "                dim_glove = v.size\n",
    "            vecs_glove_map[w] = v\n",
    "\n",
    "print(\"loaded words:\", len(vecs_glove_map), \"dim:\", dim_glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25c4b6e",
   "metadata": {},
   "source": [
    "#### 5.2) Build `stoi_glove` and `E_glove` (row-normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b467ef3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([191, 300]) 191\n"
     ]
    }
   ],
   "source": [
    "words_glove = sorted(vecs_glove_map.keys())\n",
    "stoi_glove = {w: i for i, w in enumerate(words_glove)}\n",
    "\n",
    "E_glove = torch.from_numpy(np.stack([vecs_glove_map[w] for w in words_glove])).float()\n",
    "E_glove = E_glove / (E_glove.norm(dim=1, keepdim=True) + 1e-12)\n",
    "\n",
    "print(E_glove.shape, len(stoi_glove))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfcd41f",
   "metadata": {},
   "source": [
    "#### 5.3) Encode titles (mean of word vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1ee43ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove encoded titles: torch.Size([104, 300]) kept: 104\n"
     ]
    }
   ],
   "source": [
    "vecs_glove, keep_idx_glove = [], []\n",
    "for i, toks in enumerate(df[\"tokens\"]):\n",
    "    v = encode_tokens_mean(toks, E_glove, stoi_glove)\n",
    "    if v is not None:\n",
    "        vecs_glove.append(v); keep_idx_glove.append(i)\n",
    "\n",
    "X_glove_mean = torch.stack(vecs_glove)   # rows already normalized\n",
    "print(\"glove encoded titles:\", X_glove_mean.shape, \"kept:\", len(keep_idx_glove))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b75d417",
   "metadata": {},
   "source": [
    "#### 5.4) Quick test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5636ba87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: data scientist\n",
      "   0.579  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "   0.506  Seeking employment opportunities within Customer Service or Patient Care\n",
      "   0.478  Junior MES Engineer| Information Systems\n",
      "   0.477  Human Resources professional for the world leader in GIS software\n",
      "   0.470  Business Intelligence and Analytics at Travelers\n",
      "   0.460  Nortia Staffing is seeking Human Resources, Payroll & Administrative Professionals!!  (408) 709-2621\n",
      "   0.455  Human Resources|\n",
      "Conflict Management|\n",
      "Policies & Procedures|Talent Management|Benefits & Compensation\n",
      "   0.451  Human Resources Management Major\n",
      "   0.427  Business Management Major and Aspiring Human Resources Manager\n",
      "   0.420  Aspiring Human Resources Manager | Graduating May 2020 | Seeking an Entry-Level Human Resources Position in St. Louis\n",
      "\n",
      "Query: machine learning engineer\n",
      "   0.586  Junior MES Engineer| Information Systems\n",
      "   0.382  Retired Army National Guard Recruiter, office manager,  seeking a position in Human Resources.\n",
      "   0.376  Undergraduate Research Assistant at Styczynski Lab\n",
      "   0.372  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "   0.351  Experienced Retail Manager and aspiring Human Resources Professional\n",
      "   0.336  Business Management Major and Aspiring Human Resources Manager\n",
      "   0.327  Aspiring Human Resources Professional | An energetic and Team-Focused Leader\n",
      "   0.326  HR Senior Specialist\n",
      "   0.323  Student at Indiana University Kokomo - Business Management - \n",
      "Retail Manager at Delphi Hardware and Paint\n",
      "   0.322  Aspiring Human Resources Manager | Graduating May 2020 | Seeking an Entry-Level Human Resources Position in St. Louis\n",
      "\n",
      "Query: backend developer\n",
      "   Query has no in-vocab tokens.\n",
      "\n",
      "Query: product manager\n",
      "   0.567  Business Management Major and Aspiring Human Resources Manager\n",
      "   0.544  Experienced Retail Manager and aspiring Human Resources Professional\n",
      "   0.526  Student at Indiana University Kokomo - Business Management - \n",
      "Retail Manager at Delphi Hardware and Paint\n",
      "   0.526  HR Manager at Endemol Shine North America\n",
      "   0.486  Retired Army National Guard Recruiter, office manager,  seeking a position in Human Resources.\n",
      "   0.467  People Development Coordinator at Ryan\n",
      "   0.434  RRP Brand Portfolio Executive at JTI (Japan Tobacco International)\n",
      "   0.428  Aspiring Human Resources Manager | Graduating May 2020 | Seeking an Entry-Level Human Resources Position in St. Louis\n",
      "   0.414  Director Human Resources  at EY\n",
      "   0.413  Human Resources Coordinator at InterContinental Buckhead Atlanta\n"
     ]
    }
   ],
   "source": [
    "for q in [\"data scientist\", \"machine learning engineer\", \"backend developer\", \"product manager\"]:\n",
    "    rows, err = search_titles(q, X_glove_mean, E_glove, stoi_glove, keep_idx_glove, df, topk=10, dedupe=True)\n",
    "    print(f\"\\nQuery: {q}\")\n",
    "    if err: \n",
    "        print(\"  \", err)\n",
    "    else:\n",
    "        for t, s in rows:\n",
    "            print(f\"  {s: .3f}  {t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eb69d0",
   "metadata": {},
   "source": [
    "## 6) Experiment with fastText (Meta, 2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead583a0",
   "metadata": {},
   "source": [
    "FastText extends Word2Vec with **subword (character n-gram) embeddings**. A word’s vector is the sum of its n-gram vectors, which gives:\n",
    "- robust representations for rare words, and\n",
    "- the ability to **synthesize vectors for OOV words** (e.g., typos, inflections).\n",
    "\n",
    "We’ll load pre-trained English FastText vectors and use the same pipeline as before:\n",
    "tokenize → average word vectors per title → cosine search.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e09111",
   "metadata": {},
   "source": [
    "#### 6.1) Load & encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "20c0b68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import load_facebook_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a66b253d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastText vocab (known): 2000000 dim: 300\n"
     ]
    }
   ],
   "source": [
    "# Facebook binary with subword support\n",
    "FASTTEXT_PATH = r\"./data/cc.en.300.bin\"\n",
    "ft = load_facebook_vectors(FASTTEXT_PATH)\n",
    "\n",
    "print(\"fastText vocab (known):\", len(ft), \"dim:\", ft.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ad2491a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_ft: torch.Size([199, 300]) stoi_ft: 199\n"
     ]
    }
   ],
   "source": [
    "# Build stoi/E for just the tokens in our dataset (keeps memory down)\n",
    "needed_ft = sorted({t for toks in df[\"tokens\"] for t in toks})\n",
    "stoi_ft = {w: i for i, w in enumerate(needed_ft)}\n",
    "\n",
    "E_ft = torch.from_numpy(\n",
    "    np.stack([ft.get_vector(w) for w in needed_ft]).astype(np.float32)\n",
    ")\n",
    "E_ft = E_ft / (E_ft.norm(dim=1, keepdim=True) + 1e-12)\n",
    "print(\"E_ft:\", E_ft.shape, \"stoi_ft:\", len(stoi_ft))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ab8219d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastText encoded titles: torch.Size([104, 300]) kept: 104\n"
     ]
    }
   ],
   "source": [
    "# Encode titles (mean of word vectors), same helper as before\n",
    "vecs_ft, keep_idx_ft = [], []\n",
    "for i, toks in enumerate(df[\"tokens\"]):\n",
    "    v = encode_tokens_mean(toks, E_ft, stoi_ft)\n",
    "    if v is not None:\n",
    "        vecs_ft.append(v); keep_idx_ft.append(i)\n",
    "\n",
    "X_ft_mean = torch.stack(vecs_ft)  # rows normalized already\n",
    "print(\"fastText encoded titles:\", X_ft_mean.shape, \"kept:\", len(keep_idx_ft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3bfc5a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: data scientist\n",
      "   0.475  Information Systems Specialist and Programmer with a love for data and organization.\n",
      "   0.436  Junior MES Engineer| Information Systems\n",
      "   0.413  Business Intelligence and Analytics at Travelers\n",
      "   0.386  Human Resources|\n",
      "Conflict Management|\n",
      "Policies & Procedures|Talent Management|Benefits & Compensation\n",
      "   0.351  Human Resources Management Major\n",
      "   0.351  Nortia Staffing is seeking Human Resources, Payroll & Administrative Professionals!!  (408) 709-2621\n",
      "   0.337  SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR\n",
      "   0.333  Seeking employment opportunities within Customer Service or Patient Care\n",
      "   0.327  Human Resources professional for the world leader in GIS software\n",
      "   0.313  Business Management Major and Aspiring Human Resources Manager\n",
      "\n",
      "Query: machine learning engineer\n",
      "   0.606  Junior MES Engineer| Information Systems\n",
      "   0.453  HR Senior Specialist\n",
      "   0.422  Retired Army National Guard Recruiter, office manager,  seeking a position in Human Resources.\n",
      "   0.421  Experienced Retail Manager and aspiring Human Resources Professional\n",
      "   0.415  SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR\n",
      "   0.407  Undergraduate Research Assistant at Styczynski Lab\n",
      "   0.400  Aspiring Human Resources Professional | An energetic and Team-Focused Leader\n",
      "   0.393  Aspiring Human Resources Management student seeking an internship\n",
      "   0.392  Business Management Major and Aspiring Human Resources Manager\n",
      "   0.380  Aspiring Human Resources Specialist\n",
      "\n",
      "Query: backend developer\n",
      "   Query has no in-vocab tokens.\n",
      "\n",
      "Query: product manager\n",
      "   0.584  Business Management Major and Aspiring Human Resources Manager\n",
      "   0.545  Experienced Retail Manager and aspiring Human Resources Professional\n",
      "   0.537  Retired Army National Guard Recruiter, office manager,  seeking a position in Human Resources.\n",
      "   0.530  Student at Indiana University Kokomo - Business Management - \n",
      "Retail Manager at Delphi Hardware and Paint\n",
      "   0.465  HR Senior Specialist\n",
      "   0.455  HR Manager at Endemol Shine North America\n",
      "   0.452  People Development Coordinator at Ryan\n",
      "   0.437  Director Of Administration at Excellence Logging\n",
      "   0.415  Aspiring Human Resources Professional | An energetic and Team-Focused Leader\n",
      "   0.410  Senior Human Resources Business Partner at Heil Environmental\n"
     ]
    }
   ],
   "source": [
    "for q in [\"data scientist\", \"machine learning engineer\", \"backend developer\", \"product manager\"]:\n",
    "    rows, err = search_titles(q, X_ft_mean, E_ft, stoi_ft, keep_idx_ft, df, topk=10, dedupe=True)\n",
    "    print(f\"\\nQuery: {q}\")\n",
    "    if err:\n",
    "        print(\"  \", err)\n",
    "    else:\n",
    "        for t, s in rows:\n",
    "            print(f\"  {s: .3f}  {t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2fbc71",
   "metadata": {},
   "source": [
    "## 7) Experiment with BERT (Google, 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1eb19fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3390f7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_NAME = \"bert-base-uncased\"\n",
    "tok_bert  = AutoTokenizer.from_pretrained(BERT_NAME)\n",
    "mdl_bert  = AutoModel.from_pretrained(BERT_NAME).to(device).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39e7a28",
   "metadata": {},
   "source": [
    "#### Why no “embeddings file” like GloVe/word2vec/fastText?\n",
    "\n",
    "**Static vs contextual**. GloVe/word2vec/fastText ship a static matrix: one vector per token, stored in a big text/bin file you load directly.\n",
    "\n",
    "**BERT is a full neural model**. It still has an embedding table inside (token + position + segment embeddings), but its outputs are contextual, The vector for “bank” changes with the sentence. So you don’t download a plain .txt of vectors, we download the entire model weights (a .bin file via Hugging Face) and then run the model to get embeddings for a sentence or token sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "85d61ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30522, 768])\n"
     ]
    }
   ],
   "source": [
    "# token embedding table (WordPiece-level), shape [vocab_size, hidden_size]\n",
    "E_bert = mdl_bert.get_input_embeddings().weight.detach().cpu()\n",
    "print(E_bert.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c5367f",
   "metadata": {},
   "source": [
    "…but this is subword-level (WordPiece like “##ing”, “bank”, “[UNK]”), and using it as static word vectors misses BERT’s main advantage:  **contextualization**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe88f6e8",
   "metadata": {},
   "source": [
    "#### 7.1) Mean/CLS pooling helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99105c79",
   "metadata": {},
   "source": [
    "**Goal:** turn a sequence of token embeddings from BERT into a single fixed-size vector for similarity/search.\n",
    "\n",
    "---\n",
    "\n",
    "#### Mean Pooling (masked average)\n",
    "Compute the average of the last-layer token embeddings, ignoring padding:\n",
    "$$\n",
    "\\mathbf{e}_{\\text{mean}}\n",
    "=\\frac{1}{\\sum_t m_t}\\sum_{t=1}^{T} m_t\\,\\mathbf{h}_t,\n",
    "$$\n",
    "where $\\mathbf{h}_t\\in\\mathbb{R}^H$ is the hidden state at token $t$ and $m_t\\in\\{0,1\\}$ is the attention mask (1 = real token).\n",
    "\n",
    "**Pros**\n",
    "- Uses **all** tokens; robust for short, noisy text.\n",
    "- Stable without fine-tuning; common for retrieval with base BERT.\n",
    "\n",
    "**Cons**\n",
    "- Can **dilute** key words (generic terms dominate if not IDF-weighted).\n",
    "- Treats all tokens equally unless we add weights.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### `[CLS]` Pooling (use the first token)\n",
    "Take the hidden state at the special `[CLS]` position:\n",
    "$$\n",
    "\\mathbf{e}_{\\text{CLS}}=\\mathbf{h}_{\\text{[CLS]}}.\n",
    "$$\n",
    "\n",
    "**Pros**\n",
    "- Often **sharper** for short texts; designed as a sequence-level summary in many fine-tuned classifiers.\n",
    "- Single vector without averaging.\n",
    "\n",
    "**Cons**\n",
    "- In **base** BERT (no fine-tuning), `[CLS]` is **not** optimized for similarity; may be less reliable than mean for retrieval.\n",
    "- Sensitive to model fine-tuning objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "97552f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "32afb7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CLS = False  # set True to use [CLS] pooling instead of mean\n",
    "\n",
    "@torch.no_grad()\n",
    "def encode_bert_batch(texts, pooling='mean', normalize=True):\n",
    "    \"\"\"\n",
    "    texts: list[str] -> tensor [B, H] (L2-normalized)\n",
    "    \"\"\"\n",
    "    enc = tok_bert(\n",
    "        list(texts), \n",
    "        padding=True, \n",
    "        truncation=True, \n",
    "        max_length=max_length, \n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    out = mdl_bert(**enc)  # last_hidden_state: [B, T, H]\n",
    "    H = out.last_hidden_state\n",
    "    \n",
    "    if pooling == \"mean\":\n",
    "        mask = enc[\"attention_mask\"].unsqueeze(-1)   # [B, T, 1]\n",
    "        v = (H * mask).sum(dim=1) / mask.sum(dim=1).clamp_min(1e-123)\n",
    "    elif pooling == \"cls\":\n",
    "        v = H[:,0,:]  # first token CLS\n",
    "    else:\n",
    "        raise ValueError(\"pooling must be 'mean' or 'cls'\")\n",
    "    \n",
    "    if normalize:\n",
    "        v = v / (v.norm(dim=1, keepdim=True) + 1e-12)\n",
    "    return v\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf592abd",
   "metadata": {},
   "source": [
    "#### 7.2) Build title embeddings (batched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c5a21349",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'max_length' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[87]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m X_bert = torch.cat([\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mencode_bert_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtitle_text\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpooling\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df), \u001b[32m64\u001b[39m)], dim=\u001b[32m0\u001b[39m)\n\u001b[32m      6\u001b[39m keep_idx_bert = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df)))                   \u001b[38;5;66;03m# 1:1 rows with df\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBERT encoded titles:\u001b[39m\u001b[33m\"\u001b[39m, X_bert.shape, \u001b[33m\"\u001b[39m\u001b[33mkept:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(keep_idx_bert))\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Devs\\pyEnv-1\\venvs\\Pot-Tals_3_env\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[83]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mencode_bert_batch\u001b[39m\u001b[34m(texts, pooling, normalize)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;129m@torch\u001b[39m.no_grad()\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mencode_bert_batch\u001b[39m(texts, pooling=\u001b[33m'\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m'\u001b[39m, normalize=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m      5\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33;03m    texts: list[str] -> tensor [B, H] (L2-normalized)\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m      8\u001b[39m     enc = tok_bert(\n\u001b[32m      9\u001b[39m         \u001b[38;5;28mlist\u001b[39m(texts), \n\u001b[32m     10\u001b[39m         padding=\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[32m     11\u001b[39m         truncation=\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m         max_length=\u001b[43mmax_length\u001b[49m, \n\u001b[32m     13\u001b[39m         return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     14\u001b[39m     ).to(device)\n\u001b[32m     15\u001b[39m     out = mdl_bert(**enc)  \u001b[38;5;66;03m# last_hidden_state: [B, T, H]\u001b[39;00m\n\u001b[32m     16\u001b[39m     H = out.last_hidden_state\n",
      "\u001b[31mNameError\u001b[39m: name 'max_length' is not defined"
     ]
    }
   ],
   "source": [
    "X_bert = torch.cat([\n",
    "    encode_bert_batch(df['title_text'].iloc[i:i+64],\n",
    "    pooling=\"mean\",\n",
    "    normalize=True) for i in range(0, len(df), 64)], dim=0)\n",
    "    \n",
    "keep_idx_bert = list(range(len(df)))                   # 1:1 rows with df\n",
    "print(\"BERT encoded titles:\", X_bert.shape, \"kept:\", len(keep_idx_bert))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b0fcf5",
   "metadata": {},
   "source": [
    "#### 7.3) Cosine search over titles with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "36bbf35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def search_titles_bert(query: str,\n",
    "                       X: torch.Tensor,\n",
    "                       df: pd.DataFrame,\n",
    "                       topk: int = 10,\n",
    "                       dedupe: bool = True):\n",
    "    q = encode_bert_batch(\n",
    "        [canonicalize_title(query)],\n",
    "        pooling=\"mean\",\n",
    "        normalize=True)  # [1, H]\n",
    "    sims = (X @ q[0])                                    # [N]\n",
    "    top = torch.topk(sims, k=min(topk*3, sims.numel()))  # oversample if deduping\n",
    "\n",
    "    rows, seen = [], set()\n",
    "    for idx in top.indices.tolist():\n",
    "        title_str = df.loc[idx, \"job_title\"]\n",
    "        if dedupe and title_str in seen:\n",
    "            continue\n",
    "        seen.add(title_str)\n",
    "        rows.append((title_str, float(sims[idx].item())))\n",
    "        if len(rows) == topk:\n",
    "            break\n",
    "    return rows, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3a38db48",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'max_length' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[89]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# quick test (same queries as other families)\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mdata scientist\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmachine learning engineer\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mbackend developer\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mproduct manager\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     rows, err = \u001b[43msearch_titles_bert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_bert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopk\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdedupe\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mQuery: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m err: \n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Devs\\pyEnv-1\\venvs\\Pot-Tals_3_env\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[88]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36msearch_titles_bert\u001b[39m\u001b[34m(query, X, df, topk, dedupe)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;129m@torch\u001b[39m.no_grad()\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msearch_titles_bert\u001b[39m(query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m      3\u001b[39m                        X: torch.Tensor,\n\u001b[32m      4\u001b[39m                        df: pd.DataFrame,\n\u001b[32m      5\u001b[39m                        topk: \u001b[38;5;28mint\u001b[39m = \u001b[32m10\u001b[39m,\n\u001b[32m      6\u001b[39m                        dedupe: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     q = \u001b[43mencode_bert_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcanonicalize_title\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpooling\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [1, H]\u001b[39;00m\n\u001b[32m     11\u001b[39m     sims = (X @ q[\u001b[32m0\u001b[39m])                                    \u001b[38;5;66;03m# [N]\u001b[39;00m\n\u001b[32m     12\u001b[39m     top = torch.topk(sims, k=\u001b[38;5;28mmin\u001b[39m(topk*\u001b[32m3\u001b[39m, sims.numel()))  \u001b[38;5;66;03m# oversample if deduping\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Devs\\pyEnv-1\\venvs\\Pot-Tals_3_env\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[83]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mencode_bert_batch\u001b[39m\u001b[34m(texts, pooling, normalize)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;129m@torch\u001b[39m.no_grad()\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mencode_bert_batch\u001b[39m(texts, pooling=\u001b[33m'\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m'\u001b[39m, normalize=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m      5\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33;03m    texts: list[str] -> tensor [B, H] (L2-normalized)\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m      8\u001b[39m     enc = tok_bert(\n\u001b[32m      9\u001b[39m         \u001b[38;5;28mlist\u001b[39m(texts), \n\u001b[32m     10\u001b[39m         padding=\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[32m     11\u001b[39m         truncation=\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m         max_length=\u001b[43mmax_length\u001b[49m, \n\u001b[32m     13\u001b[39m         return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     14\u001b[39m     ).to(device)\n\u001b[32m     15\u001b[39m     out = mdl_bert(**enc)  \u001b[38;5;66;03m# last_hidden_state: [B, T, H]\u001b[39;00m\n\u001b[32m     16\u001b[39m     H = out.last_hidden_state\n",
      "\u001b[31mNameError\u001b[39m: name 'max_length' is not defined"
     ]
    }
   ],
   "source": [
    "# quick test (same queries as other families)\n",
    "for q in [\"data scientist\", \"machine learning engineer\", \"backend developer\", \"product manager\"]:\n",
    "    rows, err = search_titles_bert(q, X_bert, df, topk=10, dedupe=True)\n",
    "    print(f\"\\nQuery: {q}\")\n",
    "    if err: \n",
    "        print(\"  \", err)\n",
    "    else:\n",
    "        for t, s in rows:\n",
    "            print(f\"  {s: .3f}  {t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cae2fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99adb8dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5861df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468bd9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1b42a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9307ee67",
   "metadata": {},
   "source": [
    "Collecting results for later comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "608dfb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored top-k results in results_topk[family][query].\n"
     ]
    }
   ],
   "source": [
    "# Embedding Families and the results\n",
    "FAMILIES = {\n",
    "    \"SGNS\": (X_sgns_mean, E_comb, stoi,      keep_idx),\n",
    "    \"W2V\" : (X_w2v_mean,  E_w2v,  stoi_w2v,  keep_idx_w2v),\n",
    "    }\n",
    "\n",
    "queries = [\"data scientist\", \"machine learning engineer\", \"backend developer\", \"product manager\"]\n",
    "K = 10\n",
    "\n",
    "# Store top-k *titles* (strings) for each family & query\n",
    "results_topk = {fam: {} for fam in FAMILIES}\n",
    "\n",
    "for fam, (X, E, stoi_f, keep_idx_f) in FAMILIES.items():\n",
    "    for q in queries:\n",
    "        rows, err = search_titles(q, X, E, stoi_f, keep_idx_f, df, topk=K, dedupe=True)\n",
    "        results_topk[fam][q] = [title for (title, _score) in rows] if not err else []\n",
    "\n",
    "print(\"Stored top-k results in results_topk[family][query].\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4f93da92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== data scientist ===\n",
      "Overlap@10:\n",
      "       SGNS  W2V\n",
      "SGNS   1.0  0.5\n",
      "W2V    0.5  1.0\n",
      "\n",
      "Jaccard@10:\n",
      "           SGNS       W2V\n",
      "SGNS  1.000000  0.333333\n",
      "W2V   0.333333  1.000000\n",
      "\n",
      "=== machine learning engineer ===\n",
      "Overlap@10:\n",
      "       SGNS  W2V\n",
      "SGNS   1.0  0.7\n",
      "W2V    0.7  1.0\n",
      "\n",
      "Jaccard@10:\n",
      "           SGNS       W2V\n",
      "SGNS  1.000000  0.538462\n",
      "W2V   0.538462  1.000000\n",
      "\n",
      "=== backend developer ===\n",
      "Overlap@10:\n",
      "       SGNS  W2V\n",
      "SGNS   1.0  0.6\n",
      "W2V    0.6  1.0\n",
      "\n",
      "Jaccard@10:\n",
      "           SGNS       W2V\n",
      "SGNS  1.000000  0.428571\n",
      "W2V   0.428571  1.000000\n",
      "\n",
      "=== product manager ===\n",
      "Overlap@10:\n",
      "       SGNS  W2V\n",
      "SGNS   1.0  0.7\n",
      "W2V    0.7  1.0\n",
      "\n",
      "Jaccard@10:\n",
      "           SGNS       W2V\n",
      "SGNS  1.000000  0.538462\n",
      "W2V   0.538462  1.000000\n"
     ]
    }
   ],
   "source": [
    "def overlap_at_k(list_a, list_b, k=10):\n",
    "    A, B = set(list_a[:k]), set(list_b[:k])\n",
    "    denom = max(1, min(k, len(A), len(B)))\n",
    "    return len(A & B) / denom\n",
    "\n",
    "def jaccard_at_k(list_a, list_b, k=10):\n",
    "    A, B = set(list_a[:k]), set(list_b[:k])\n",
    "    union = len(A | B)\n",
    "    return (len(A & B) / union) if union else 0.0\n",
    "\n",
    "import itertools\n",
    "\n",
    "family_names = list(FAMILIES.keys())\n",
    "\n",
    "for q in queries:\n",
    "    print(f\"\\n=== {q} ===\")\n",
    "    # Build symmetric matrices\n",
    "    O = np.zeros((len(family_names), len(family_names)))\n",
    "    J = np.zeros_like(O)\n",
    "    for i, a in enumerate(family_names):\n",
    "        for j, b in enumerate(family_names):\n",
    "            O[i, j] = overlap_at_k(results_topk[a][q], results_topk[b][q], k=K)\n",
    "            J[i, j] = jaccard_at_k(results_topk[a][q], results_topk[b][q], k=K)\n",
    "    print(\"Overlap@{}:\\n\".format(K), pd.DataFrame(O, index=family_names, columns=family_names))\n",
    "    print(\"\\nJaccard@{}:\\n\".format(K), pd.DataFrame(J, index=family_names, columns=family_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "85db958f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the family to your registry so later matrices (Overlap@k / Jaccard@k) include it\n",
    "FAMILIES[\"GloVe\"] = (X_glove_mean, E_glove, stoi_glove, keep_idx_glove)\n",
    "\n",
    "# store top-k per query for later cross-family comparison\n",
    "results_topk[\"GloVe\"] = {}\n",
    "K = 10\n",
    "for q in [\"data scientist\", \"machine learning engineer\", \"backend developer\", \"product manager\"]:\n",
    "    rows, err = search_titles(q, X_glove_mean, E_glove, stoi_glove, keep_idx_glove, df, topk=K, dedupe=True)\n",
    "    results_topk[\"GloVe\"][q] = [title for (title, _score) in rows] if not err else []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb46c695",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANKS = RANKS if \"RANKS\" in globals() else {}\n",
    "RANKS.setdefault(\"bert\", {})\n",
    "\n",
    "def top_indices_bert(query, X, k=10):\n",
    "    q = encode_bert_batch([canonicalize_title(query)])\n",
    "    sims = (X @ q[0])\n",
    "    return torch.topk(sims, k=min(k, sims.numel())).indices.tolist()\n",
    "\n",
    "for q in [\"data scientist\", \"machine learning engineer\", \"backend developer\", \"product manager\"]:\n",
    "    RANKS[\"bert\"][q] = top_indices_bert(q, X_bert, k=10)\n",
    "\n",
    "# RANKS now also contains \"bert\" to compare with SGNS/GloVe/fastText later\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pot-Tals_3_env",
   "language": "python",
   "name": "pot-tals_3_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
